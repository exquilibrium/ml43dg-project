{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation\n",
    "\n",
    "**Presentation**: Wednesday, July 24th 16:54\n",
    "\n",
    "**Report and Code**: August 14th, 23:55\n",
    "\n",
    "Dataset:\n",
    "- Objectverse (https://objaverse.allenai.org)\n",
    "\n",
    "Modifications:\n",
    "- Explore various ways of improving the generalization ability across different categories, e.g., adding class embedding, and text feature descriptors.\n",
    "- Adding additional test-time optimization loss for better shape fitting especially for objects with thin structure\n",
    "- Add color code to shape latent code, also learn view-independant color field given colored-mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Running this notebook\n",
    "We recommend running this notebook on a CUDA compatible local gpu. You can also run training on cpu, it will just take longer.\n",
    "\n",
    "You have three options for running this exercise on a GPU, choose one of them and start the exercise below in section \"Imports\":\n",
    "1. Locally on your own GPU\n",
    "2. On our dedicated compute cluster\n",
    "3. On Google Colab\n",
    "\n",
    "We describe every option in more detail below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### (a) Local Execution\n",
    "\n",
    "If you run this notebook locally, you have to first install the python dependiencies again. They are the same as for exercise 1 so you can re-use the environment you used last time. If you use [poetry](https://python-poetry.org), you can also simply re-install everything (`poetry install`) and then run this notebook via `poetry run jupyter notebook`.\n",
    "\n",
    "In case you are working with a RTX 3000-series GPU, you need to install a patched version of pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Compute Cluster\n",
    "\n",
    "We provide access to a small compute cluster for the exercises and projects, consisting of a login node and 4 compute nodes with one dedicated RTX 3090 GPU each.\n",
    "Please send us a short email with your name and preferred username so we can add you as a user.\n",
    "\n",
    "We uploaded a PDF to Moodle with detailed information on how to access and use the cluster.\n",
    "\n",
    "Since the cluster contains RTX 3000-series GPUs, you will need to install a patched version of pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Google Colab\n",
    "\n",
    "If you don't have access to a GPU and don't want to use our cluster, you can also use Google Colab. However, we experienced the issue that inline visualization of shapes or inline images didn't work on colab, so just keep that in mind.\n",
    "What you can also do is only train networks on colab, download the checkpoint, and visualize inference locally.\n",
    "\n",
    "In case you're using Google Colab, you can upload the exercise folder (containing `exercise_2.ipynb`, directory `exercise_2` and the file `requirements.txt`) as `3d-machine-learning` to google drive (make sure you don't upload extracted datasets files).\n",
    "Additionally you'd need to open the notebook `exercise_2.ipynb` in Colab using `File > Open Notebook > Upload`.\n",
    "\n",
    "Next you'll need to run these two cells for setting up the environment. Before you do that make sure your instance has a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# We assume you uploaded the exercise folder in root Google Drive folder\n",
    "\n",
    "#!cp -r /content/drive/MyDrive/3d-machine-learning 3d-machine-learning/\n",
    "#os.chdir('/content/3d-machine-learning/')\n",
    "#print('Installing requirements')\n",
    "#%pip install -r requirements.txt\n",
    "\n",
    "# Make sure you restart runtime when directed by Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell after restarting your colab runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#import sys\n",
    "#import torch\n",
    "#os.chdir('/content/3d-machine-learning/')\n",
    "#sys.path.insert(1, \"/content/3d-machine-learning/\")\n",
    "#print('CUDA availability:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The following imports should work regardless of whether you are using Colab or local execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:04:20.689329400Z",
     "start_time": "2024-07-23T18:04:02.831691900Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet objaverse\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import k3d\n",
    "import trimesh\n",
    "import torch\n",
    "import skimage\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import objaverse\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next cell to test whether a GPU was detected by pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 DeepSDF\n",
    "\n",
    "\n",
    "Here, we will take a look at 3D-reconstruction using [DeepSDF](https://arxiv.org/abs/1901.05103). We recommend reading the paper before attempting the exercise.\n",
    "\n",
    "DeepSDF is an auto-decoder based approach that learns a continuous SDF representation for a class of shapes. Once trained, it can be used for shape representation, interpolation and shape completion. We'll look at each of these\n",
    "applications.\n",
    "\n",
    "<img src=\"exercise_3/images/deepsdf_teaser.png\" alt=\"deepsdf_teaser\" style=\"width: 800px;\"/>\n",
    "\n",
    "During training, the autodecoder optimizes both the network parameters and the latent codes representing each of the training shapes. Once trained, to reconstruct a shape given its SDF observations, a latent code is\n",
    "optimized keeping the network parameters fixed, such that the optimized latent code gives the lowest error with observed SDF values.\n",
    "\n",
    "An advantage that implicit representations have over voxel/grid based approaches is that they are not tied to a particular grid resolution, and can be evaluated at any resolution once trained.\n",
    "\n",
    "Similar to previous exercise, we'll first download the processed dataset, look at the implementation of the dataset, the model and the trainer, try out overfitting and generalization over the entire dataset, and finally inference on unseen samples.\n",
    "\n",
    "### (a) Downloading the data\n",
    "\n",
    "Whereas volumetric models output entire 3d shape representations, implicit models like DeepSDF work on per point basis. The network takes in a 3D-coordinate (and additionally the latent vector) and outputs the SDF value at the queried point. To train such a model,\n",
    "we therefore need, for each of the training shapes, a bunch of points with their corresponding SDF values for supervision. Points are sampled more aggressively near the surface of the object as we want to capture a more detailed SDF near the surface. For those curious,\n",
    "data preparation is decribed in more detail in section 5 of the paper.\n",
    "\n",
    "We'll be using the Objaverse Chairs class for the experiments in this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = Path(\"./data/objaverse/\")\n",
    "\n",
    "lvis_annotations = objaverse.load_lvis_annotations()\n",
    "random.seed(42)\n",
    "chairs_uids = lvis_annotations['chair']\n",
    "chairs_uids = random.sample(chairs_uids, 100)\n",
    "\n",
    "objects = objaverse.load_objects(\n",
    "    uids=chairs_uids,\n",
    ")\n",
    "\n",
    "for objaverse_id, file_path in objects.items():\n",
    "    if not Path(download_path / \"chairs\" / objaverse_id).exists():\n",
    "        Path(download_path / \"chairs\").mkdir(parents=True, exist_ok=True)\n",
    "    shutil.move(file_path, download_path / \"chairs\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T19:57:21.163238400Z",
     "start_time": "2024-07-23T19:57:20.830548100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sofas\n",
      "Downloaded 1 / 80 objects\n",
      "Downloaded 2 / 80 objects\n",
      "Downloaded 3 / 80 objects\n",
      "Downloaded 4 / 80 objects\n",
      "Downloaded 5 / 80 objects\n",
      "Downloaded 6 / 80 objects\n",
      "Downloaded 7 / 80 objects\n",
      "Downloaded 8 / 80 objects\n",
      "Downloaded 9 / 80 objects\n",
      "Downloaded 10 / 80 objects\n",
      "Downloaded 11 / 80 objects\n",
      "Downloaded 12 / 80 objects\n",
      "Downloaded 13 / 80 objects\n",
      "Downloaded 14 / 80 objects\n",
      "Downloaded 15 / 80 objects\n",
      "Downloaded 16 / 80 objects\n",
      "Downloaded 17 / 80 objects\n",
      "Downloaded 18 / 80 objects\n",
      "Downloaded 19 / 80 objects\n",
      "Downloading sofas\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'objaverse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m class_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msofa\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtable\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvase\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m (class_name\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m----> 7\u001B[0m     lvis_annotations \u001B[38;5;241m=\u001B[39m objaverse\u001B[38;5;241m.\u001B[39mload_lvis_annotations()\n\u001B[0;32m      8\u001B[0m     random\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      9\u001B[0m     uids \u001B[38;5;241m=\u001B[39m lvis_annotations[class_name]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'objaverse' is not defined"
     ]
    }
   ],
   "source": [
    "# Downloading sofas, tables, and vases\n",
    "\n",
    "download_path = Path(\"./data/objaverse/\")\n",
    "\n",
    "for class_name in ['sofa', 'table', 'vase']:\n",
    "    print(\"Downloading \" + (class_name+\"s\"))\n",
    "    lvis_annotations = objaverse.load_lvis_annotations()\n",
    "    random.seed(42)\n",
    "    uids = lvis_annotations[class_name]\n",
    "\n",
    "    objects = objaverse.load_objects(\n",
    "        uids=uids,\n",
    "    )\n",
    "\n",
    "    for objaverse_id, file_path in objects.items():\n",
    "        if not Path(download_path / (class_name+\"s\") / objaverse_id).exists():\n",
    "            Path(download_path / (class_name+\"s\")).mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(file_path, download_path / (class_name+\"s\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each shape, the downloaded chair .glb will be converted into a coloured mesh and stored in the same directory with its corresponding sdf file:\n",
    "- `mesh.obj` representing the mesh representation of the shape\n",
    "- `sdf.npz` file containing large number of points sampled on and around the mesh and their sdf values; contains numpy arrays under keys \"pos\" and \"neg\", containing points with positive and negative sdf values respectively\n",
    "\n",
    "```\n",
    "# contents of exercise_3/data/sdf_sofas\n",
    "1faa4c299b93a3e5593ebeeedbff73b/                    # shape 0\n",
    "    ├── mesh.obj                                    # shape 0 mesh\n",
    "    ├── sdf.npz                                     # shape 0 sdf\n",
    "    ├── surface.obj                                 # shape 0 surface\n",
    "1fde48d83065ef5877a929f61fea4d0/                    # shape 1\n",
    "1fe1411b6c8097acf008d8a3590fb522/                   # shape 2\n",
    ":\n",
    "```\n",
    "The processing is performed in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:06:32.655134300Z",
     "start_time": "2024-07-23T18:06:31.716402100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karim\\PycharmProjects\\ml43dg-project\\DeepSDF-exercise\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:11:02.328355500Z",
     "start_time": "2024-07-23T18:09:39.261221700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"./ml43dg/data\")\n",
    "\n",
    "# Get the list of files in the sdf_chairs directory\n",
    "sdf_files = list((data_path / \"objaverse\"/ \"sdf_chairs\").iterdir())\n",
    "\n",
    "# For each file in data/objaverse/chairs, create a directory with the same name\n",
    "for file in (data_path / \"objaverse\"/ \"chairs\").iterdir():\n",
    "    if file.is_file():\n",
    "        file_name = file.stem\n",
    "        new_dir = data_path / \"chairs\" / file_name\n",
    "        new_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Then convert the .glb to a .obj mesh file\n",
    "        mesh = trimesh.load(file, force=\"mesh\")\n",
    "        _ = mesh.export(new_dir / f\"{file_name}.obj\")\n",
    "\n",
    "        # Remove the original .glb file\n",
    "        file.unlink()\n",
    "\n",
    "        # Finally, move the corresponding sdf file from data/objaverse/sdf_chairs to the same directory\n",
    "        sdf_file = next(f for f in sdf_files if f.stem == file_name)\n",
    "        shutil.move(sdf_file, new_dir / sdf_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:11:44.231062Z",
     "start_time": "2024-07-23T18:11:43.829958600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rename all the sdf files to sdf.npz and all the obj files to mesh.obj\n",
    "for chair_dir in (data_path / \"objaverse\"/ \"chairs\").iterdir():\n",
    "    for file in chair_dir.iterdir():\n",
    "        if file.suffix == \".obj\":\n",
    "            file.rename(chair_dir / \"mesh.obj\")\n",
    "        elif file.suffix == \".npz\":\n",
    "            file.rename(chair_dir / \"sdf.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Dataset\n",
    "\n",
    "We randomly generate train/test splits based on the ratio used in the exercise for ShapeNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:12:31.032424Z",
     "start_time": "2024-07-23T18:12:30.950909700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sofas in the ShapeNet training set: 1226\n",
      "Number of sofas in the ShapeNet test set: 137\n",
      "Number of sofas in the ShapeNet overfit set: 1\n",
      "val/train ratio: 10:90\n"
     ]
    }
   ],
   "source": [
    "# Generate random train/test/overfit splits modelled after the split ratios in the ShapeNet case\n",
    "with open(data_path / \"splits\" / \"sofas\" / \"train.txt\", \"r\") as f:\n",
    "    train_sofas = f.read().splitlines()\n",
    "print(f\"Number of sofas in the ShapeNet training set: {len(train_sofas)}\")\n",
    "\n",
    "# Read file splits/sofas/test.txt\n",
    "with open(data_path / \"splits\" / \"sofas\" / \"val.txt\", \"r\") as f:\n",
    "    test_sofas = f.read().splitlines()\n",
    "    print(f\"Number of sofas in the ShapeNet test set: {len(test_sofas)}\")\n",
    "\n",
    "with open(data_path / \"splits\" / \"sofas\" / \"overfit.txt\", \"r\") as f:\n",
    "    overfit_sofas = f.read().splitlines()\n",
    "print(f\"Number of sofas in the ShapeNet overfit set: {len(overfit_sofas)}\")\n",
    "\n",
    "print(f\"val/train ratio: {int(round(len(test_sofas) / (len(train_sofas) + len(test_sofas)),2)*100)}:{int(round(len(train_sofas) / (len(train_sofas) + len(test_sofas)),1)*100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:12:34.217485800Z",
     "start_time": "2024-07-23T18:12:34.142930600Z"
    }
   },
   "outputs": [],
   "source": [
    "# We want to emulate the ratio of the ShapeNet dataset\n",
    "val_ratio = int(round(len(test_sofas) / (len(train_sofas) + len(test_sofas)),2)*100)\n",
    "train_ratio = 100-val_ratio\n",
    "\n",
    "# Get a list of all chairs in the objaverse/chairs directory\n",
    "all_chairs = list((data_path / \"objaverse\"/ \"chairs\").iterdir())\n",
    "\n",
    "# Randomly shuffle the list\n",
    "random.shuffle(all_chairs)\n",
    "\n",
    "# Remove one chair to be used for overfitting\n",
    "overfit_chair = all_chairs.pop()\n",
    "\n",
    "# Split the list into training and validation sets\n",
    "train_chairs = all_chairs[:int(len(all_chairs) * (train_ratio / 100))]\n",
    "val_chairs = all_chairs[int(len(all_chairs) * (train_ratio / 100)):]\n",
    "\n",
    "# Store the names of the chairs in corresponding text files\n",
    "with open(data_path / \"splits\" / \"chairs\" / \"train.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([c.stem for c in train_chairs]))\n",
    "\n",
    "with open(data_path / \"splits\" / \"chairs\" / \"val.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([c.stem for c in val_chairs]))\n",
    "\n",
    "with open(data_path / \"splits\" / \"chairs\" / \"overfit.txt\", \"w\") as f:\n",
    "    f.write(overfit_chair.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:12:52.112225Z",
     "start_time": "2024-07-23T18:12:52.020062300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 406\n",
      "Length of val set: 46\n",
      "Length of overfit set: 1\n"
     ]
    }
   ],
   "source": [
    "from ml43dg.data.objaverse import Objaverse\n",
    "\n",
    "num_points_to_samples = 40000\n",
    "train_dataset = Objaverse(num_points_to_samples, \"train\")\n",
    "val_dataset = Objaverse(num_points_to_samples, \"val\")\n",
    "overfit_dataset = Objaverse(num_points_to_samples, \"overfit\")\n",
    "\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 1226\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of val set: {len(val_dataset)}')  # expected output: 137\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of overfit set: {len(overfit_dataset)}')  # expected output: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look at the points sampled for a particular shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:13:07.163868100Z",
     "start_time": "2024-07-23T18:13:07.037204Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ml43dg.util.visualization import visualize_mesh, visualize_pointcloud\n",
    "\n",
    "uid = train_dataset[0]['name']\n",
    "points = train_dataset[0]['points']\n",
    "sdf = train_dataset[0]['sdf']\n",
    "\n",
    "# sampled points inside the shape\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "\n",
    "# sampled points outside the shape\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mesh = Objaverse.get_mesh(uid)\n",
    "print('Mesh')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Sampled points with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Sampled points with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that more points are sampled close to the surface rather than away from the surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (c) Model\n",
    "\n",
    "The DeepSDF auto-decoder architecture is visualized below:\n",
    "\n",
    "<img src=\"exercise_3/images/deepsdf_architecture.png\" alt=\"deepsdf_arch\" style=\"width: 640px;\"/>\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- The network takes in the latent code for a shape concatenated with the query 3d coordinate, making up a 259 length vector (assuming latent code length is 256).\n",
    "- The network consist of a sequence of weight-normed linear layers, each followed by a ReLU and a dropout. For weight norming a layer, check out `torch.nn.utils.weight_norm`. Each of these linear layers outputs a 512 dimensional vector, except the 4th layer which outputs a 253 dimensional vector.\n",
    "- The output of the 4th layer is concatenated with the input, making the input to the 5th layer a 512 dimensional vector.\n",
    "- The final layer is a simple linear layer without any norm, dropout or non-linearity, with a single dimensional output representing the SDF value.\n",
    "\n",
    "Implement this architecture in file `exercise_3/model/deepsdf.py`.\n",
    "\n",
    "Here are some basic sanity tests once you're done with your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:13:22.232041Z",
     "start_time": "2024-07-23T18:13:22.063142200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name    | Type           | Params \n",
      "---------------------------------------------\n",
      "0  | wnll1   | Linear         | 133632 \n",
      "1  | wnll2   | Linear         | 263168 \n",
      "2  | wnll3   | Linear         | 263168 \n",
      "3  | wnll4   | Linear         | 130042 \n",
      "4  | wnll5   | Linear         | 263168 \n",
      "5  | wnll6   | Linear         | 263168 \n",
      "6  | wnll7   | Linear         | 263168 \n",
      "7  | wnll8   | Linear         | 263168 \n",
      "8  | fc      | Linear         | 513    \n",
      "9  | relu    | ReLU           | 0      \n",
      "10 | dropout | Dropout        | 0      \n",
      "11 | TOTAL   | DeepSDFDecoder | 1843195\n",
      "\n",
      "Output tensor shape:  torch.Size([4096, 1])\n",
      "\n",
      "Number of traininable params: 1.84M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karim\\anaconda3\\envs\\ML3D\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from ml43dg.model.deepsdf import DeepSDFDecoder\n",
    "from ml43dg.util.model import summarize_model\n",
    "\n",
    "deepsdf = DeepSDFDecoder(latent_size=256)\n",
    "print(summarize_model(deepsdf))\n",
    "\n",
    "# input to the network is a concatenation of point coordinates (3) and the latent code (256 in this example);\n",
    "# here we use a batch of 4096 points\n",
    "input_tensor = torch.randn(4096, 3 + 256)\n",
    "predictions = deepsdf(input_tensor)\n",
    "\n",
    "print('\\nOutput tensor shape: ', predictions.shape)  # expected output: 4096, 1\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in deepsdf.parameters() if p.requires_grad) / 1e6\n",
    "print(f'\\nNumber of traininable params: {num_trainable_params:.2f}M')  # expected output: ~1.8M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Training script and overfitting to a single shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:14:25.171606700Z",
     "start_time": "2024-07-23T18:14:18.875051600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karim\\anaconda3\\envs\\ML3D\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[049/00000] train_loss: 0.011282\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory exercise_3/runs/0_objaverse_deepsdf_overfit does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 19\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mml43dg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_deepsdf\n\u001B[0;32m      3\u001B[0m overfit_config \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexperiment_name\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0_objaverse_deepsdf_overfit\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# change this to cpu if you do not have a GPU\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvisualize_every_n\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m250\u001B[39m,\n\u001B[0;32m     17\u001B[0m }\n\u001B[1;32m---> 19\u001B[0m train_deepsdf\u001B[38;5;241m.\u001B[39mmain(overfit_config)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ml43dg-project\\DeepSDF-exercise\\ml43dg\\training\\train_deepsdf.py:168\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(config)\u001B[0m\n\u001B[0;32m    165\u001B[0m Path(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mml43dg/runs/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperiment_name\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmkdir(exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, parents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    167\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[1;32m--> 168\u001B[0m train(model, latent_vectors, train_dataloader, device, config)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ml43dg-project\\DeepSDF-exercise\\ml43dg\\training\\train_deepsdf.py:91\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, latent_vectors, train_dataloader, device, config)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;66;03m# save best train model and latent codes\u001B[39;00m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train_loss \u001B[38;5;241m<\u001B[39m best_loss:\n\u001B[1;32m---> 91\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexercise_3/runs/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperiment_name\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/model_best.ckpt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     92\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(latent_vectors\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexercise_3/runs/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperiment_name\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/latent_best.ckpt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     93\u001B[0m     best_loss \u001B[38;5;241m=\u001B[39m train_loss\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML3D\\Lib\\site-packages\\torch\\serialization.py:627\u001B[0m, in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001B[0m\n\u001B[0;32m    624\u001B[0m _check_save_filelike(f)\n\u001B[0;32m    626\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[1;32m--> 627\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _open_zipfile_writer(f) \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n\u001B[0;32m    628\u001B[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001B[0;32m    629\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML3D\\Lib\\site-packages\\torch\\serialization.py:501\u001B[0m, in \u001B[0;36m_open_zipfile_writer\u001B[1;34m(name_or_buffer)\u001B[0m\n\u001B[0;32m    499\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    500\u001B[0m     container \u001B[38;5;241m=\u001B[39m _open_zipfile_writer_buffer\n\u001B[1;32m--> 501\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m container(name_or_buffer)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML3D\\Lib\\site-packages\\torch\\serialization.py:472\u001B[0m, in \u001B[0;36m_open_zipfile_writer_file.__init__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    470\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mPyTorchFileWriter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_stream))\n\u001B[0;32m    471\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 472\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mPyTorchFileWriter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Parent directory exercise_3/runs/0_objaverse_deepsdf_overfit does not exist."
     ]
    }
   ],
   "source": [
    "from ml43dg.training import train_deepsdf\n",
    "\n",
    "overfit_config = {\n",
    "    'experiment_name': '0_objaverse_deepsdf_overfit',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'num_sample_points': 4096,\n",
    "    'latent_code_length': 256,\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.0005,\n",
    "    'learning_rate_code': 0.001,\n",
    "    'lambda_code_regularization': 0.0001,\n",
    "    'max_epochs': 2000,\n",
    "    'print_every_n': 50,\n",
    "    'visualize_every_n': 250,\n",
    "}\n",
    "\n",
    "train_deepsdf.main(overfit_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the overfitted shape reconstruction to check if it looks reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize GT mesh of the overfit sample\n",
    "gt_mesh = Objaverse.get_mesh('90dfb9e99ddd4b4ca414be7599ea6469')\n",
    "print('GT')\n",
    "visualize_mesh(gt_mesh.vertices, gt_mesh.faces, flip_axes=True)\n",
    "\n",
    "# Load and visualize reconstructed overfit sample; it's okay if they don't look visually exact, since we don't run\n",
    "# the training too long and have a learning rate decay while training\n",
    "mesh_path = \"ml43dg/runs/0_objaverse_deepsdf_overfit/meshes/01999_000.obj\"\n",
    "overfit_output = trimesh.load(mesh_path)\n",
    "print('Overfit')\n",
    "visualize_mesh(overfit_output.vertices, overfit_output.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Training over entire train set\n",
    "\n",
    "Once overfitting works, we can train on the entire train set.\n",
    "\n",
    "Note: This training will take a few hours on a GPU (took ~3 hrs for 500 epochs on our 2080Ti, which already gave decent results). Please make sure to start training early enough before the submission deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:57:20.830548100Z",
     "start_time": "2024-07-23T18:20:31.584304400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00049] train_loss: 0.012316\n",
      "[000/00099] train_loss: 0.007744\n",
      "[000/00149] train_loss: 0.006837\n",
      "[000/00199] train_loss: 0.006742\n",
      "[000/00249] train_loss: 0.006572\n",
      "[000/00299] train_loss: 0.006551\n",
      "[000/00349] train_loss: 0.006458\n",
      "[000/00399] train_loss: 0.006408\n",
      "[001/00043] train_loss: 0.006326\n",
      "[001/00093] train_loss: 0.006280\n",
      "[001/00143] train_loss: 0.006188\n",
      "[001/00193] train_loss: 0.006178\n",
      "[001/00243] train_loss: 0.006191\n",
      "[001/00293] train_loss: 0.006072\n",
      "[001/00343] train_loss: 0.006107\n",
      "[001/00393] train_loss: 0.006087\n",
      "[002/00037] train_loss: 0.006088\n",
      "[002/00087] train_loss: 0.006180\n",
      "[002/00137] train_loss: 0.006093\n",
      "[002/00187] train_loss: 0.006130\n",
      "[002/00237] train_loss: 0.006014\n",
      "[002/00287] train_loss: 0.006188\n",
      "[002/00337] train_loss: 0.006074\n",
      "[002/00387] train_loss: 0.006044\n",
      "[003/00031] train_loss: 0.006093\n",
      "[003/00081] train_loss: 0.006185\n",
      "[003/00131] train_loss: 0.005957\n",
      "[003/00181] train_loss: 0.006125\n",
      "[003/00231] train_loss: 0.006068\n",
      "[003/00281] train_loss: 0.006154\n",
      "[003/00331] train_loss: 0.006174\n",
      "[003/00381] train_loss: 0.006026\n",
      "[004/00025] train_loss: 0.006109\n",
      "[004/00075] train_loss: 0.006041\n",
      "[004/00125] train_loss: 0.007103\n",
      "[004/00175] train_loss: 0.006120\n",
      "[004/00225] train_loss: 0.006053\n",
      "[004/00275] train_loss: 0.006136\n",
      "[004/00325] train_loss: 0.006096\n",
      "[004/00375] train_loss: 0.006157\n",
      "[005/00019] train_loss: 0.006044\n",
      "[005/00069] train_loss: 0.006021\n",
      "[005/00119] train_loss: 0.006088\n",
      "[005/00169] train_loss: 0.006080\n",
      "[005/00219] train_loss: 0.005998\n",
      "[005/00269] train_loss: 0.006165\n",
      "[005/00319] train_loss: 0.006193\n",
      "[005/00369] train_loss: 0.005994\n",
      "[006/00013] train_loss: 0.006075\n",
      "[006/00063] train_loss: 0.006064\n",
      "[006/00113] train_loss: 0.006009\n",
      "[006/00163] train_loss: 0.006014\n",
      "[006/00213] train_loss: 0.006010\n",
      "[006/00263] train_loss: 0.006052\n",
      "[006/00313] train_loss: 0.006070\n",
      "[006/00363] train_loss: 0.006096\n",
      "[007/00007] train_loss: 0.006196\n",
      "[007/00057] train_loss: 0.006100\n",
      "[007/00107] train_loss: 0.006129\n",
      "[007/00157] train_loss: 0.006027\n",
      "[007/00207] train_loss: 0.006120\n",
      "[007/00257] train_loss: 0.006181\n",
      "[007/00307] train_loss: 0.006063\n",
      "[007/00357] train_loss: 0.006074\n",
      "[008/00001] train_loss: 0.006160\n",
      "[008/00051] train_loss: 0.006143\n",
      "[008/00101] train_loss: 0.006063\n",
      "[008/00151] train_loss: 0.006148\n",
      "[008/00201] train_loss: 0.006077\n",
      "[008/00251] train_loss: 0.006034\n",
      "[008/00301] train_loss: 0.006078\n",
      "[008/00351] train_loss: 0.006133\n",
      "[008/00401] train_loss: 0.006098\n",
      "[009/00045] train_loss: 0.006060\n",
      "[009/00095] train_loss: 0.005969\n",
      "[009/00145] train_loss: 0.006080\n",
      "[009/00195] train_loss: 0.006098\n",
      "[009/00245] train_loss: 0.006129\n",
      "[009/00295] train_loss: 0.006156\n",
      "[009/00345] train_loss: 0.006107\n",
      "[009/00395] train_loss: 0.006112\n",
      "[010/00039] train_loss: 0.006104\n",
      "[010/00089] train_loss: 0.006147\n",
      "[010/00139] train_loss: 0.006082\n",
      "[010/00189] train_loss: 0.006161\n",
      "[010/00239] train_loss: 0.005956\n",
      "[010/00289] train_loss: 0.006105\n",
      "[010/00339] train_loss: 0.006035\n",
      "[010/00389] train_loss: 0.006116\n",
      "[011/00033] train_loss: 0.006031\n",
      "[011/00083] train_loss: 0.006005\n",
      "[011/00133] train_loss: 0.006092\n",
      "[011/00183] train_loss: 0.006093\n",
      "[011/00233] train_loss: 0.006043\n",
      "[011/00283] train_loss: 0.006092\n",
      "[011/00333] train_loss: 0.006125\n",
      "[011/00383] train_loss: 0.006081\n",
      "[012/00027] train_loss: 0.006036\n",
      "[012/00077] train_loss: 0.006161\n",
      "[012/00127] train_loss: 0.006102\n",
      "[012/00177] train_loss: 0.006144\n",
      "[012/00227] train_loss: 0.006025\n",
      "[012/00277] train_loss: 0.006079\n",
      "[012/00327] train_loss: 0.006111\n",
      "[012/00377] train_loss: 0.006161\n",
      "[013/00021] train_loss: 0.006065\n",
      "[013/00071] train_loss: 0.006052\n",
      "[013/00121] train_loss: 0.006059\n",
      "[013/00171] train_loss: 0.006065\n",
      "[013/00221] train_loss: 0.006115\n",
      "[013/00271] train_loss: 0.006109\n",
      "[013/00321] train_loss: 0.006134\n",
      "[013/00371] train_loss: 0.006022\n",
      "[014/00015] train_loss: 0.006114\n",
      "[014/00065] train_loss: 0.006150\n",
      "[014/00115] train_loss: 0.006043\n",
      "[014/00165] train_loss: 0.006018\n",
      "[014/00215] train_loss: 0.006050\n",
      "[014/00265] train_loss: 0.006096\n",
      "[014/00315] train_loss: 0.006087\n",
      "[014/00365] train_loss: 0.006081\n",
      "[015/00009] train_loss: 0.006097\n",
      "[015/00059] train_loss: 0.006133\n",
      "[015/00109] train_loss: 0.006025\n",
      "[015/00159] train_loss: 0.006076\n",
      "[015/00209] train_loss: 0.006116\n",
      "[015/00259] train_loss: 0.006163\n",
      "[015/00309] train_loss: 0.006166\n",
      "[015/00359] train_loss: 0.006120\n",
      "[016/00003] train_loss: 0.006148\n",
      "[016/00053] train_loss: 0.006084\n",
      "[016/00103] train_loss: 0.006114\n",
      "[016/00153] train_loss: 0.006080\n",
      "[016/00203] train_loss: 0.006230\n",
      "[016/00253] train_loss: 0.006095\n",
      "[016/00303] train_loss: 0.006060\n",
      "[016/00353] train_loss: 0.006109\n",
      "[016/00403] train_loss: 0.006053\n",
      "[017/00047] train_loss: 0.006058\n",
      "[017/00097] train_loss: 0.006026\n",
      "[017/00147] train_loss: 0.006119\n",
      "[017/00197] train_loss: 0.006090\n",
      "[017/00247] train_loss: 0.006125\n",
      "[017/00297] train_loss: 0.006023\n",
      "[017/00347] train_loss: 0.006108\n",
      "[017/00397] train_loss: 0.006104\n",
      "[018/00041] train_loss: 0.006054\n",
      "[018/00091] train_loss: 0.006136\n",
      "[018/00141] train_loss: 0.006046\n",
      "[018/00191] train_loss: 0.006127\n",
      "[018/00241] train_loss: 0.006033\n",
      "[018/00291] train_loss: 0.006074\n",
      "[018/00341] train_loss: 0.006134\n",
      "[018/00391] train_loss: 0.006111\n",
      "[019/00035] train_loss: 0.006141\n",
      "[019/00085] train_loss: 0.006059\n",
      "[019/00135] train_loss: 0.006074\n",
      "[019/00185] train_loss: 0.006126\n",
      "[019/00235] train_loss: 0.006060\n",
      "[019/00285] train_loss: 0.006133\n",
      "[019/00335] train_loss: 0.006033\n",
      "[019/00385] train_loss: 0.006066\n",
      "[020/00029] train_loss: 0.006040\n",
      "[020/00079] train_loss: 0.006109\n",
      "[020/00129] train_loss: 0.006033\n",
      "[020/00179] train_loss: 0.006024\n",
      "[020/00229] train_loss: 0.006121\n",
      "[020/00279] train_loss: 0.006138\n",
      "[020/00329] train_loss: 0.006131\n",
      "[020/00379] train_loss: 0.006122\n",
      "[021/00023] train_loss: 0.006040\n",
      "[021/00073] train_loss: 0.005983\n",
      "[021/00123] train_loss: 0.006065\n",
      "[021/00173] train_loss: 0.006115\n",
      "[021/00223] train_loss: 0.006138\n",
      "[021/00273] train_loss: 0.006051\n",
      "[021/00323] train_loss: 0.006073\n",
      "[021/00373] train_loss: 0.006126\n",
      "[022/00017] train_loss: 0.006070\n",
      "[022/00067] train_loss: 0.006104\n",
      "[022/00117] train_loss: 0.006117\n",
      "[022/00167] train_loss: 0.006046\n",
      "[022/00217] train_loss: 0.006106\n",
      "[022/00267] train_loss: 0.006089\n",
      "[022/00317] train_loss: 0.006085\n",
      "[022/00367] train_loss: 0.006040\n",
      "[023/00011] train_loss: 0.006210\n",
      "[023/00061] train_loss: 0.006086\n",
      "[023/00111] train_loss: 0.006012\n",
      "[023/00161] train_loss: 0.006043\n",
      "[023/00211] train_loss: 0.006101\n",
      "[023/00261] train_loss: 0.006160\n",
      "[023/00311] train_loss: 0.006102\n",
      "[023/00361] train_loss: 0.006083\n",
      "[024/00005] train_loss: 0.006181\n",
      "[024/00055] train_loss: 0.006140\n",
      "[024/00105] train_loss: 0.006073\n",
      "[024/00155] train_loss: 0.006224\n",
      "[024/00205] train_loss: 0.006066\n",
      "[024/00255] train_loss: 0.006048\n",
      "[024/00305] train_loss: 0.006080\n",
      "[024/00355] train_loss: 0.006114\n",
      "[024/00405] train_loss: 0.006079\n",
      "[025/00049] train_loss: 0.006081\n",
      "[025/00099] train_loss: 0.006168\n",
      "[025/00149] train_loss: 0.006043\n",
      "[025/00199] train_loss: 0.006050\n",
      "[025/00249] train_loss: 0.006057\n",
      "[025/00299] train_loss: 0.006115\n",
      "[025/00349] train_loss: 0.006176\n",
      "[025/00399] train_loss: 0.006021\n",
      "[026/00043] train_loss: 0.005994\n",
      "[026/00093] train_loss: 0.006084\n",
      "[026/00143] train_loss: 0.006145\n",
      "[026/00193] train_loss: 0.006023\n",
      "[026/00243] train_loss: 0.006192\n",
      "[026/00293] train_loss: 0.006121\n",
      "[026/00343] train_loss: 0.006054\n",
      "[026/00393] train_loss: 0.006012\n",
      "[027/00037] train_loss: 0.006129\n",
      "[027/00087] train_loss: 0.006199\n",
      "[027/00137] train_loss: 0.006148\n",
      "[027/00187] train_loss: 0.006150\n",
      "[027/00237] train_loss: 0.006067\n",
      "[027/00287] train_loss: 0.006085\n",
      "[027/00337] train_loss: 0.006076\n",
      "[027/00387] train_loss: 0.006170\n",
      "[028/00031] train_loss: 0.006011\n",
      "[028/00081] train_loss: 0.006143\n",
      "[028/00131] train_loss: 0.005952\n",
      "[028/00181] train_loss: 0.006033\n",
      "[028/00231] train_loss: 0.006052\n",
      "[028/00281] train_loss: 0.006062\n",
      "[028/00331] train_loss: 0.006053\n",
      "[028/00381] train_loss: 0.006107\n",
      "[029/00025] train_loss: 0.006108\n",
      "[029/00075] train_loss: 0.006031\n",
      "[029/00125] train_loss: 0.006086\n",
      "[029/00175] train_loss: 0.006042\n",
      "[029/00225] train_loss: 0.006038\n",
      "[029/00275] train_loss: 0.006130\n",
      "[029/00325] train_loss: 0.006130\n",
      "[029/00375] train_loss: 0.006104\n",
      "[030/00019] train_loss: 0.006068\n",
      "[030/00069] train_loss: 0.006130\n",
      "[030/00119] train_loss: 0.006103\n",
      "[030/00169] train_loss: 0.006148\n",
      "[030/00219] train_loss: 0.006031\n",
      "[030/00269] train_loss: 0.006106\n",
      "[030/00319] train_loss: 0.006092\n",
      "[030/00369] train_loss: 0.006082\n",
      "[031/00013] train_loss: 0.006019\n",
      "[031/00063] train_loss: 0.005999\n",
      "[031/00113] train_loss: 0.006072\n",
      "[031/00163] train_loss: 0.006069\n",
      "[031/00213] train_loss: 0.006062\n",
      "[031/00263] train_loss: 0.006009\n",
      "[031/00313] train_loss: 0.006095\n",
      "[031/00363] train_loss: 0.006098\n",
      "[032/00007] train_loss: 0.006034\n",
      "[032/00057] train_loss: 0.005984\n",
      "[032/00107] train_loss: 0.006106\n",
      "[032/00157] train_loss: 0.006117\n",
      "[032/00207] train_loss: 0.006159\n",
      "[032/00257] train_loss: 0.006163\n",
      "[032/00307] train_loss: 0.006042\n",
      "[032/00357] train_loss: 0.006165\n",
      "[033/00001] train_loss: 0.006068\n",
      "[033/00051] train_loss: 0.006097\n",
      "[033/00101] train_loss: 0.006097\n",
      "[033/00151] train_loss: 0.006073\n",
      "[033/00201] train_loss: 0.006145\n",
      "[033/00251] train_loss: 0.006078\n",
      "[033/00301] train_loss: 0.006109\n",
      "[033/00351] train_loss: 0.006128\n",
      "[033/00401] train_loss: 0.006125\n",
      "[034/00045] train_loss: 0.006028\n",
      "[034/00095] train_loss: 0.006098\n",
      "[034/00145] train_loss: 0.006060\n",
      "[034/00195] train_loss: 0.005983\n",
      "[034/00245] train_loss: 0.006197\n",
      "[034/00295] train_loss: 0.005998\n",
      "[034/00345] train_loss: 0.006099\n",
      "[034/00395] train_loss: 0.006106\n",
      "[035/00039] train_loss: 0.006005\n",
      "[035/00089] train_loss: 0.006074\n",
      "[035/00139] train_loss: 0.006063\n",
      "[035/00189] train_loss: 0.006015\n",
      "[035/00239] train_loss: 0.006071\n",
      "[035/00289] train_loss: 0.006122\n",
      "[035/00339] train_loss: 0.006176\n",
      "[035/00389] train_loss: 0.006093\n",
      "[036/00033] train_loss: 0.006094\n",
      "[036/00083] train_loss: 0.006053\n",
      "[036/00133] train_loss: 0.006084\n",
      "[036/00183] train_loss: 0.006158\n",
      "[036/00233] train_loss: 0.006017\n",
      "[036/00283] train_loss: 0.006098\n",
      "[036/00333] train_loss: 0.006133\n",
      "[036/00383] train_loss: 0.006164\n",
      "[037/00027] train_loss: 0.005967\n",
      "[037/00077] train_loss: 0.006046\n",
      "[037/00127] train_loss: 0.006075\n",
      "[037/00177] train_loss: 0.006155\n",
      "[037/00227] train_loss: 0.006204\n",
      "[037/00277] train_loss: 0.006082\n",
      "[037/00327] train_loss: 0.006202\n",
      "[037/00377] train_loss: 0.006100\n",
      "[038/00021] train_loss: 0.006090\n",
      "[038/00071] train_loss: 0.006090\n",
      "[038/00121] train_loss: 0.006077\n",
      "[038/00171] train_loss: 0.006107\n",
      "[038/00221] train_loss: 0.006071\n",
      "[038/00271] train_loss: 0.006056\n",
      "[038/00321] train_loss: 0.006180\n",
      "[038/00371] train_loss: 0.006087\n",
      "[039/00015] train_loss: 0.006190\n",
      "[039/00065] train_loss: 0.006086\n",
      "[039/00115] train_loss: 0.006009\n",
      "[039/00165] train_loss: 0.006054\n",
      "[039/00215] train_loss: 0.006178\n",
      "[039/00265] train_loss: 0.006103\n",
      "[039/00315] train_loss: 0.006076\n",
      "[039/00365] train_loss: 0.006006\n",
      "[040/00009] train_loss: 0.006151\n",
      "[040/00059] train_loss: 0.006057\n",
      "[040/00109] train_loss: 0.006220\n",
      "[040/00159] train_loss: 0.006074\n",
      "[040/00209] train_loss: 0.006104\n",
      "[040/00259] train_loss: 0.006081\n",
      "[040/00309] train_loss: 0.006021\n",
      "[040/00359] train_loss: 0.006169\n",
      "[041/00003] train_loss: 0.006069\n",
      "[041/00053] train_loss: 0.006055\n",
      "[041/00103] train_loss: 0.006086\n",
      "[041/00153] train_loss: 0.006003\n",
      "[041/00203] train_loss: 0.006054\n",
      "[041/00253] train_loss: 0.006120\n",
      "[041/00303] train_loss: 0.006107\n",
      "[041/00353] train_loss: 0.006123\n",
      "[041/00403] train_loss: 0.006154\n",
      "[042/00047] train_loss: 0.006094\n",
      "[042/00097] train_loss: 0.006105\n",
      "[042/00147] train_loss: 0.006092\n",
      "[042/00197] train_loss: 0.006053\n",
      "[042/00247] train_loss: 0.005996\n",
      "[042/00297] train_loss: 0.006037\n",
      "[042/00347] train_loss: 0.006139\n",
      "[042/00397] train_loss: 0.006053\n",
      "[043/00041] train_loss: 0.006077\n",
      "[043/00091] train_loss: 0.006040\n",
      "[043/00141] train_loss: 0.006128\n",
      "[043/00191] train_loss: 0.006094\n",
      "[043/00241] train_loss: 0.006127\n",
      "[043/00291] train_loss: 0.006045\n",
      "[043/00341] train_loss: 0.006078\n",
      "[043/00391] train_loss: 0.006189\n",
      "[044/00035] train_loss: 0.006168\n",
      "[044/00085] train_loss: 0.006064\n",
      "[044/00135] train_loss: 0.006106\n",
      "[044/00185] train_loss: 0.006144\n",
      "[044/00235] train_loss: 0.006081\n",
      "[044/00285] train_loss: 0.006145\n",
      "[044/00335] train_loss: 0.006114\n",
      "[044/00385] train_loss: 0.006176\n",
      "[045/00029] train_loss: 0.006078\n",
      "[045/00079] train_loss: 0.005976\n",
      "[045/00129] train_loss: 0.006071\n",
      "[045/00179] train_loss: 0.006033\n",
      "[045/00229] train_loss: 0.006121\n",
      "[045/00279] train_loss: 0.006121\n",
      "[045/00329] train_loss: 0.006077\n",
      "[045/00379] train_loss: 0.006032\n",
      "[046/00023] train_loss: 0.006155\n",
      "[046/00073] train_loss: 0.006104\n",
      "[046/00123] train_loss: 0.006118\n",
      "[046/00173] train_loss: 0.006066\n",
      "[046/00223] train_loss: 0.006107\n",
      "[046/00273] train_loss: 0.006065\n",
      "[046/00323] train_loss: 0.006084\n",
      "[046/00373] train_loss: 0.006074\n",
      "[047/00017] train_loss: 0.006140\n",
      "[047/00067] train_loss: 0.006134\n",
      "[047/00117] train_loss: 0.006143\n",
      "[047/00167] train_loss: 0.006094\n",
      "[047/00217] train_loss: 0.006040\n",
      "[047/00267] train_loss: 0.006053\n",
      "[047/00317] train_loss: 0.006063\n",
      "[047/00367] train_loss: 0.006188\n",
      "[048/00011] train_loss: 0.006149\n",
      "[048/00061] train_loss: 0.006140\n",
      "[048/00111] train_loss: 0.005960\n",
      "[048/00161] train_loss: 0.006049\n",
      "[048/00211] train_loss: 0.006104\n",
      "[048/00261] train_loss: 0.006135\n",
      "[048/00311] train_loss: 0.006068\n",
      "[048/00361] train_loss: 0.006051\n",
      "[049/00005] train_loss: 0.006051\n",
      "[049/00055] train_loss: 0.006038\n",
      "[049/00105] train_loss: 0.006133\n",
      "[049/00155] train_loss: 0.006078\n",
      "[049/00205] train_loss: 0.005987\n",
      "[049/00255] train_loss: 0.006045\n",
      "[049/00305] train_loss: 0.006113\n",
      "[049/00355] train_loss: 0.006056\n",
      "[049/00405] train_loss: 0.006061\n",
      "[050/00049] train_loss: 0.006045\n",
      "[050/00099] train_loss: 0.006017\n",
      "[050/00149] train_loss: 0.006086\n",
      "[050/00199] train_loss: 0.006038\n",
      "[050/00249] train_loss: 0.006028\n",
      "[050/00299] train_loss: 0.006028\n",
      "[050/00349] train_loss: 0.005982\n",
      "[050/00399] train_loss: 0.006153\n",
      "[051/00043] train_loss: 0.006038\n",
      "[051/00093] train_loss: 0.006134\n",
      "[051/00143] train_loss: 0.006103\n",
      "[051/00193] train_loss: 0.006146\n",
      "[051/00243] train_loss: 0.006039\n",
      "[051/00293] train_loss: 0.006047\n",
      "[051/00343] train_loss: 0.006075\n",
      "[051/00393] train_loss: 0.006062\n",
      "[052/00037] train_loss: 0.006100\n",
      "[052/00087] train_loss: 0.006214\n",
      "[052/00137] train_loss: 0.006024\n",
      "[052/00187] train_loss: 0.006051\n",
      "[052/00237] train_loss: 0.006090\n",
      "[052/00287] train_loss: 0.006034\n",
      "[052/00337] train_loss: 0.006045\n",
      "[052/00387] train_loss: 0.006102\n",
      "[053/00031] train_loss: 0.006117\n",
      "[053/00081] train_loss: 0.006178\n",
      "[053/00131] train_loss: 0.006008\n",
      "[053/00181] train_loss: 0.006125\n",
      "[053/00231] train_loss: 0.006066\n",
      "[053/00281] train_loss: 0.006063\n",
      "[053/00331] train_loss: 0.006135\n",
      "[053/00381] train_loss: 0.006022\n",
      "[054/00025] train_loss: 0.006115\n",
      "[054/00075] train_loss: 0.006072\n",
      "[054/00125] train_loss: 0.006129\n",
      "[054/00175] train_loss: 0.006069\n",
      "[054/00225] train_loss: 0.006000\n",
      "[054/00275] train_loss: 0.006045\n",
      "[054/00325] train_loss: 0.006137\n",
      "[054/00375] train_loss: 0.006010\n",
      "[055/00019] train_loss: 0.006081\n",
      "[055/00069] train_loss: 0.006105\n",
      "[055/00119] train_loss: 0.006003\n",
      "[055/00169] train_loss: 0.006123\n",
      "[055/00219] train_loss: 0.006042\n",
      "[055/00269] train_loss: 0.006122\n",
      "[055/00319] train_loss: 0.006119\n",
      "[055/00369] train_loss: 0.006184\n",
      "[056/00013] train_loss: 0.006074\n",
      "[056/00063] train_loss: 0.006037\n",
      "[056/00113] train_loss: 0.006067\n",
      "[056/00163] train_loss: 0.006066\n",
      "[056/00213] train_loss: 0.005986\n",
      "[056/00263] train_loss: 0.006064\n",
      "[056/00313] train_loss: 0.006014\n",
      "[056/00363] train_loss: 0.006036\n",
      "[057/00007] train_loss: 0.006115\n",
      "[057/00057] train_loss: 0.006087\n",
      "[057/00107] train_loss: 0.006067\n",
      "[057/00157] train_loss: 0.006109\n",
      "[057/00207] train_loss: 0.006040\n",
      "[057/00257] train_loss: 0.006061\n",
      "[057/00307] train_loss: 0.006035\n",
      "[057/00357] train_loss: 0.006036\n",
      "[058/00001] train_loss: 0.006046\n",
      "[058/00051] train_loss: 0.006096\n",
      "[058/00101] train_loss: 0.006116\n",
      "[058/00151] train_loss: 0.006094\n",
      "[058/00201] train_loss: 0.006135\n",
      "[058/00251] train_loss: 0.006100\n",
      "[058/00301] train_loss: 0.006038\n",
      "[058/00351] train_loss: 0.006088\n",
      "[058/00401] train_loss: 0.006083\n",
      "[059/00045] train_loss: 0.006079\n",
      "[059/00095] train_loss: 0.006128\n",
      "[059/00145] train_loss: 0.006087\n",
      "[059/00195] train_loss: 0.006160\n",
      "[059/00245] train_loss: 0.006066\n",
      "[059/00295] train_loss: 0.006022\n",
      "[059/00345] train_loss: 0.006149\n",
      "[059/00395] train_loss: 0.006092\n",
      "[060/00039] train_loss: 0.006062\n",
      "[060/00089] train_loss: 0.006141\n",
      "[060/00139] train_loss: 0.006091\n",
      "[060/00189] train_loss: 0.006076\n",
      "[060/00239] train_loss: 0.006049\n",
      "[060/00289] train_loss: 0.006115\n",
      "[060/00339] train_loss: 0.006119\n",
      "[060/00389] train_loss: 0.006090\n",
      "[061/00033] train_loss: 0.006134\n",
      "[061/00083] train_loss: 0.006077\n",
      "[061/00133] train_loss: 0.006072\n",
      "[061/00183] train_loss: 0.006078\n",
      "[061/00233] train_loss: 0.006109\n",
      "[061/00283] train_loss: 0.006093\n",
      "[061/00333] train_loss: 0.006032\n",
      "[061/00383] train_loss: 0.006123\n",
      "[062/00027] train_loss: 0.006087\n",
      "[062/00077] train_loss: 0.005997\n",
      "[062/00127] train_loss: 0.006163\n",
      "[062/00177] train_loss: 0.006011\n",
      "[062/00227] train_loss: 0.005983\n",
      "[062/00277] train_loss: 0.006092\n",
      "[062/00327] train_loss: 0.006108\n",
      "[062/00377] train_loss: 0.006117\n",
      "[063/00021] train_loss: 0.006120\n",
      "[063/00071] train_loss: 0.006111\n",
      "[063/00121] train_loss: 0.006066\n",
      "[063/00171] train_loss: 0.006077\n",
      "[063/00221] train_loss: 0.006010\n",
      "[063/00271] train_loss: 0.006069\n",
      "[063/00321] train_loss: 0.006020\n",
      "[063/00371] train_loss: 0.006111\n",
      "[064/00015] train_loss: 0.006046\n",
      "[064/00065] train_loss: 0.006062\n",
      "[064/00115] train_loss: 0.006124\n",
      "[064/00165] train_loss: 0.006071\n",
      "[064/00215] train_loss: 0.006111\n",
      "[064/00265] train_loss: 0.006067\n",
      "[064/00315] train_loss: 0.006136\n",
      "[064/00365] train_loss: 0.006184\n",
      "[065/00009] train_loss: 0.006051\n",
      "[065/00059] train_loss: 0.006067\n",
      "[065/00109] train_loss: 0.006087\n",
      "[065/00159] train_loss: 0.006067\n",
      "[065/00209] train_loss: 0.006081\n",
      "[065/00259] train_loss: 0.006058\n",
      "[065/00309] train_loss: 0.006091\n",
      "[065/00359] train_loss: 0.006142\n",
      "[066/00003] train_loss: 0.006057\n",
      "[066/00053] train_loss: 0.006016\n",
      "[066/00103] train_loss: 0.006108\n",
      "[066/00153] train_loss: 0.006060\n",
      "[066/00203] train_loss: 0.006071\n",
      "[066/00253] train_loss: 0.006029\n",
      "[066/00303] train_loss: 0.006155\n",
      "[066/00353] train_loss: 0.006110\n",
      "[066/00403] train_loss: 0.006076\n",
      "[067/00047] train_loss: 0.006142\n",
      "[067/00097] train_loss: 0.006064\n",
      "[067/00147] train_loss: 0.006055\n",
      "[067/00197] train_loss: 0.006092\n",
      "[067/00247] train_loss: 0.006064\n",
      "[067/00297] train_loss: 0.006161\n",
      "[067/00347] train_loss: 0.006020\n",
      "[067/00397] train_loss: 0.006113\n",
      "[068/00041] train_loss: 0.006087\n",
      "[068/00091] train_loss: 0.006005\n",
      "[068/00141] train_loss: 0.006069\n",
      "[068/00191] train_loss: 0.006082\n",
      "[068/00241] train_loss: 0.006105\n",
      "[068/00291] train_loss: 0.006159\n",
      "[068/00341] train_loss: 0.006021\n",
      "[068/00391] train_loss: 0.006082\n",
      "[069/00035] train_loss: 0.006070\n",
      "[069/00085] train_loss: 0.006133\n",
      "[069/00135] train_loss: 0.006182\n",
      "[069/00185] train_loss: 0.006099\n",
      "[069/00235] train_loss: 0.006076\n",
      "[069/00285] train_loss: 0.006031\n",
      "[069/00335] train_loss: 0.006153\n",
      "[069/00385] train_loss: 0.006041\n",
      "[070/00029] train_loss: 0.006085\n",
      "[070/00079] train_loss: 0.006076\n",
      "[070/00129] train_loss: 0.006059\n",
      "[070/00179] train_loss: 0.006053\n",
      "[070/00229] train_loss: 0.006062\n",
      "[070/00279] train_loss: 0.006108\n",
      "[070/00329] train_loss: 0.006064\n",
      "[070/00379] train_loss: 0.006114\n",
      "[071/00023] train_loss: 0.006046\n",
      "[071/00073] train_loss: 0.006026\n",
      "[071/00123] train_loss: 0.006095\n",
      "[071/00173] train_loss: 0.006127\n",
      "[071/00223] train_loss: 0.006053\n",
      "[071/00273] train_loss: 0.006124\n",
      "[071/00323] train_loss: 0.006045\n",
      "[071/00373] train_loss: 0.006201\n",
      "[072/00017] train_loss: 0.006077\n",
      "[072/00067] train_loss: 0.006051\n",
      "[072/00117] train_loss: 0.006013\n",
      "[072/00167] train_loss: 0.006102\n",
      "[072/00217] train_loss: 0.006134\n",
      "[072/00267] train_loss: 0.006077\n",
      "[072/00317] train_loss: 0.006038\n",
      "[072/00367] train_loss: 0.006121\n",
      "[073/00011] train_loss: 0.006028\n",
      "[073/00061] train_loss: 0.006081\n",
      "[073/00111] train_loss: 0.006086\n",
      "[073/00161] train_loss: 0.006034\n",
      "[073/00211] train_loss: 0.005987\n",
      "[073/00261] train_loss: 0.006154\n",
      "[073/00311] train_loss: 0.006153\n",
      "[073/00361] train_loss: 0.006032\n",
      "[074/00005] train_loss: 0.005966\n",
      "[074/00055] train_loss: 0.006139\n",
      "[074/00105] train_loss: 0.006108\n",
      "[074/00155] train_loss: 0.006032\n",
      "[074/00205] train_loss: 0.006034\n",
      "[074/00255] train_loss: 0.006128\n",
      "[074/00305] train_loss: 0.006084\n",
      "[074/00355] train_loss: 0.006065\n",
      "[074/00405] train_loss: 0.006118\n",
      "[075/00049] train_loss: 0.006166\n",
      "[075/00099] train_loss: 0.006156\n",
      "[075/00149] train_loss: 0.006080\n",
      "[075/00199] train_loss: 0.006082\n",
      "[075/00249] train_loss: 0.006028\n",
      "[075/00299] train_loss: 0.006037\n",
      "[075/00349] train_loss: 0.006036\n",
      "[075/00399] train_loss: 0.006075\n",
      "[076/00043] train_loss: 0.006043\n",
      "[076/00093] train_loss: 0.006114\n",
      "[076/00143] train_loss: 0.006048\n",
      "[076/00193] train_loss: 0.006057\n",
      "[076/00243] train_loss: 0.006025\n",
      "[076/00293] train_loss: 0.006040\n",
      "[076/00343] train_loss: 0.006010\n",
      "[076/00393] train_loss: 0.006143\n",
      "[077/00037] train_loss: 0.006144\n",
      "[077/00087] train_loss: 0.006042\n",
      "[077/00137] train_loss: 0.006126\n",
      "[077/00187] train_loss: 0.006070\n",
      "[077/00237] train_loss: 0.005996\n",
      "[077/00287] train_loss: 0.006077\n",
      "[077/00337] train_loss: 0.006161\n",
      "[077/00387] train_loss: 0.006138\n",
      "[078/00031] train_loss: 0.006041\n",
      "[078/00081] train_loss: 0.006099\n",
      "[078/00131] train_loss: 0.005987\n",
      "[078/00181] train_loss: 0.005937\n",
      "[078/00231] train_loss: 0.006146\n",
      "[078/00281] train_loss: 0.006127\n",
      "[078/00331] train_loss: 0.006095\n",
      "[078/00381] train_loss: 0.006069\n",
      "[079/00025] train_loss: 0.006185\n",
      "[079/00075] train_loss: 0.006088\n",
      "[079/00125] train_loss: 0.006133\n",
      "[079/00175] train_loss: 0.006083\n",
      "[079/00225] train_loss: 0.006157\n",
      "[079/00275] train_loss: 0.005991\n",
      "[079/00325] train_loss: 0.006102\n",
      "[079/00375] train_loss: 0.006103\n",
      "[080/00019] train_loss: 0.006129\n",
      "[080/00069] train_loss: 0.006085\n",
      "[080/00119] train_loss: 0.006131\n",
      "[080/00169] train_loss: 0.006058\n",
      "[080/00219] train_loss: 0.006101\n",
      "[080/00269] train_loss: 0.006137\n",
      "[080/00319] train_loss: 0.006002\n",
      "[080/00369] train_loss: 0.006022\n",
      "[081/00013] train_loss: 0.006123\n",
      "[081/00063] train_loss: 0.006175\n",
      "[081/00113] train_loss: 0.006071\n",
      "[081/00163] train_loss: 0.006106\n",
      "[081/00213] train_loss: 0.006107\n",
      "[081/00263] train_loss: 0.006031\n",
      "[081/00313] train_loss: 0.006039\n",
      "[081/00363] train_loss: 0.006085\n",
      "[082/00007] train_loss: 0.006130\n",
      "[082/00057] train_loss: 0.006123\n",
      "[082/00107] train_loss: 0.006115\n",
      "[082/00157] train_loss: 0.006103\n",
      "[082/00207] train_loss: 0.006098\n",
      "[082/00257] train_loss: 0.006057\n",
      "[082/00307] train_loss: 0.006076\n",
      "[082/00357] train_loss: 0.006189\n",
      "[083/00001] train_loss: 0.006020\n",
      "[083/00051] train_loss: 0.006152\n",
      "[083/00101] train_loss: 0.006109\n",
      "[083/00151] train_loss: 0.006142\n",
      "[083/00201] train_loss: 0.006083\n",
      "[083/00251] train_loss: 0.006065\n",
      "[083/00301] train_loss: 0.006010\n",
      "[083/00351] train_loss: 0.006054\n",
      "[083/00401] train_loss: 0.006103\n",
      "[084/00045] train_loss: 0.006047\n",
      "[084/00095] train_loss: 0.006100\n",
      "[084/00145] train_loss: 0.006115\n",
      "[084/00195] train_loss: 0.006089\n",
      "[084/00245] train_loss: 0.006123\n",
      "[084/00295] train_loss: 0.006123\n",
      "[084/00345] train_loss: 0.006219\n",
      "[084/00395] train_loss: 0.006098\n",
      "[085/00039] train_loss: 0.006065\n",
      "[085/00089] train_loss: 0.006147\n",
      "[085/00139] train_loss: 0.006087\n",
      "[085/00189] train_loss: 0.006031\n",
      "[085/00239] train_loss: 0.006111\n",
      "[085/00289] train_loss: 0.006049\n",
      "[085/00339] train_loss: 0.006098\n",
      "[085/00389] train_loss: 0.006062\n",
      "[086/00033] train_loss: 0.006114\n",
      "[086/00083] train_loss: 0.006043\n",
      "[086/00133] train_loss: 0.006246\n",
      "[086/00183] train_loss: 0.006085\n",
      "[086/00233] train_loss: 0.006087\n",
      "[086/00283] train_loss: 0.006072\n",
      "[086/00333] train_loss: 0.006057\n",
      "[086/00383] train_loss: 0.006093\n",
      "[087/00027] train_loss: 0.006087\n",
      "[087/00077] train_loss: 0.006001\n",
      "[087/00127] train_loss: 0.006125\n",
      "[087/00177] train_loss: 0.006033\n",
      "[087/00227] train_loss: 0.006111\n",
      "[087/00277] train_loss: 0.006152\n",
      "[087/00327] train_loss: 0.006071\n",
      "[087/00377] train_loss: 0.006232\n",
      "[088/00021] train_loss: 0.006095\n",
      "[088/00071] train_loss: 0.006157\n",
      "[088/00121] train_loss: 0.006113\n",
      "[088/00171] train_loss: 0.006065\n",
      "[088/00221] train_loss: 0.006113\n",
      "[088/00271] train_loss: 0.006140\n",
      "[088/00321] train_loss: 0.006045\n",
      "[088/00371] train_loss: 0.006084\n",
      "[089/00015] train_loss: 0.006114\n",
      "[089/00065] train_loss: 0.006070\n",
      "[089/00115] train_loss: 0.006230\n",
      "[089/00165] train_loss: 0.006151\n",
      "[089/00215] train_loss: 0.006064\n",
      "[089/00265] train_loss: 0.006082\n",
      "[089/00315] train_loss: 0.006161\n",
      "[089/00365] train_loss: 0.006109\n",
      "[090/00009] train_loss: 0.006125\n",
      "[090/00059] train_loss: 0.006138\n",
      "[090/00109] train_loss: 0.006042\n",
      "[090/00159] train_loss: 0.006104\n",
      "[090/00209] train_loss: 0.006130\n",
      "[090/00259] train_loss: 0.005950\n",
      "[090/00309] train_loss: 0.006059\n",
      "[090/00359] train_loss: 0.006105\n",
      "[091/00003] train_loss: 0.006045\n",
      "[091/00053] train_loss: 0.006163\n",
      "[091/00103] train_loss: 0.006177\n",
      "[091/00153] train_loss: 0.006034\n",
      "[091/00203] train_loss: 0.006032\n",
      "[091/00253] train_loss: 0.006045\n",
      "[091/00303] train_loss: 0.006159\n",
      "[091/00353] train_loss: 0.006143\n",
      "[091/00403] train_loss: 0.006066\n",
      "[092/00047] train_loss: 0.006051\n",
      "[092/00097] train_loss: 0.006060\n",
      "[092/00147] train_loss: 0.006031\n",
      "[092/00197] train_loss: 0.006109\n",
      "[092/00247] train_loss: 0.006108\n",
      "[092/00297] train_loss: 0.006105\n",
      "[092/00347] train_loss: 0.006149\n",
      "[092/00397] train_loss: 0.006084\n",
      "[093/00041] train_loss: 0.006065\n",
      "[093/00091] train_loss: 0.006045\n",
      "[093/00141] train_loss: 0.006015\n",
      "[093/00191] train_loss: 0.006085\n",
      "[093/00241] train_loss: 0.006114\n",
      "[093/00291] train_loss: 0.006018\n",
      "[093/00341] train_loss: 0.006100\n",
      "[093/00391] train_loss: 0.006120\n",
      "[094/00035] train_loss: 0.006158\n",
      "[094/00085] train_loss: 0.006054\n",
      "[094/00135] train_loss: 0.005947\n",
      "[094/00185] train_loss: 0.006087\n",
      "[094/00235] train_loss: 0.006076\n",
      "[094/00285] train_loss: 0.006090\n",
      "[094/00335] train_loss: 0.006116\n",
      "[094/00385] train_loss: 0.006169\n",
      "[095/00029] train_loss: 0.006032\n",
      "[095/00079] train_loss: 0.006141\n",
      "[095/00129] train_loss: 0.006007\n",
      "[095/00179] train_loss: 0.006104\n",
      "[095/00229] train_loss: 0.006116\n",
      "[095/00279] train_loss: 0.006063\n",
      "[095/00329] train_loss: 0.006144\n",
      "[095/00379] train_loss: 0.006029\n",
      "[096/00023] train_loss: 0.006113\n",
      "[096/00073] train_loss: 0.006067\n",
      "[096/00123] train_loss: 0.006169\n",
      "[096/00173] train_loss: 0.005971\n",
      "[096/00223] train_loss: 0.006060\n",
      "[096/00273] train_loss: 0.005985\n",
      "[096/00323] train_loss: 0.006095\n",
      "[096/00373] train_loss: 0.006075\n",
      "[097/00017] train_loss: 0.006101\n",
      "[097/00067] train_loss: 0.006069\n",
      "[097/00117] train_loss: 0.006095\n",
      "[097/00167] train_loss: 0.005997\n",
      "[097/00217] train_loss: 0.006127\n",
      "[097/00267] train_loss: 0.006045\n",
      "[097/00317] train_loss: 0.006132\n",
      "[097/00367] train_loss: 0.006002\n",
      "[098/00011] train_loss: 0.006033\n",
      "[098/00061] train_loss: 0.006157\n",
      "[098/00111] train_loss: 0.006055\n",
      "[098/00161] train_loss: 0.006135\n",
      "[098/00211] train_loss: 0.006133\n",
      "[098/00261] train_loss: 0.006103\n",
      "[098/00311] train_loss: 0.005969\n",
      "[098/00361] train_loss: 0.006081\n",
      "[099/00005] train_loss: 0.006096\n",
      "[099/00055] train_loss: 0.006147\n",
      "[099/00105] train_loss: 0.006115\n",
      "[099/00155] train_loss: 0.006051\n",
      "[099/00205] train_loss: 0.006136\n",
      "[099/00255] train_loss: 0.005999\n",
      "[099/00305] train_loss: 0.006177\n",
      "[099/00355] train_loss: 0.006202\n",
      "[099/00405] train_loss: 0.006094\n",
      "[100/00049] train_loss: 0.006165\n",
      "[100/00099] train_loss: 0.006049\n",
      "[100/00149] train_loss: 0.006141\n",
      "[100/00199] train_loss: 0.006062\n",
      "[100/00249] train_loss: 0.006002\n",
      "[100/00299] train_loss: 0.006095\n",
      "[100/00349] train_loss: 0.006088\n",
      "[100/00399] train_loss: 0.006084\n",
      "[101/00043] train_loss: 0.006259\n",
      "[101/00093] train_loss: 0.006268\n",
      "[101/00143] train_loss: 0.006209\n",
      "[101/00193] train_loss: 0.006241\n",
      "[101/00243] train_loss: 0.006199\n",
      "[101/00293] train_loss: 0.006200\n",
      "[101/00343] train_loss: 0.006169\n",
      "[101/00393] train_loss: 0.006198\n",
      "[102/00037] train_loss: 0.006165\n",
      "[102/00087] train_loss: 0.006211\n",
      "[102/00137] train_loss: 0.006177\n",
      "[102/00187] train_loss: 0.006197\n",
      "[102/00237] train_loss: 0.006098\n",
      "[102/00287] train_loss: 0.006214\n",
      "[102/00337] train_loss: 0.006193\n",
      "[102/00387] train_loss: 0.006162\n",
      "[103/00031] train_loss: 0.006153\n",
      "[103/00081] train_loss: 0.006116\n",
      "[103/00131] train_loss: 0.006153\n",
      "[103/00181] train_loss: 0.006236\n",
      "[103/00231] train_loss: 0.006106\n",
      "[103/00281] train_loss: 0.006127\n",
      "[103/00331] train_loss: 0.006096\n",
      "[103/00381] train_loss: 0.006085\n",
      "[104/00025] train_loss: 0.006022\n",
      "[104/00075] train_loss: 0.006129\n",
      "[104/00125] train_loss: 0.006055\n",
      "[104/00175] train_loss: 0.006078\n",
      "[104/00225] train_loss: 0.006124\n",
      "[104/00275] train_loss: 0.006213\n",
      "[104/00325] train_loss: 0.006176\n",
      "[104/00375] train_loss: 0.006147\n",
      "[105/00019] train_loss: 0.006105\n",
      "[105/00069] train_loss: 0.006205\n",
      "[105/00119] train_loss: 0.006060\n",
      "[105/00169] train_loss: 0.006121\n",
      "[105/00219] train_loss: 0.006146\n",
      "[105/00269] train_loss: 0.006146\n",
      "[105/00319] train_loss: 0.006029\n",
      "[105/00369] train_loss: 0.006094\n",
      "[106/00013] train_loss: 0.006007\n",
      "[106/00063] train_loss: 0.006045\n",
      "[106/00113] train_loss: 0.006058\n",
      "[106/00163] train_loss: 0.006168\n",
      "[106/00213] train_loss: 0.006071\n",
      "[106/00263] train_loss: 0.006181\n",
      "[106/00313] train_loss: 0.006125\n",
      "[106/00363] train_loss: 0.006124\n",
      "[107/00007] train_loss: 0.006109\n",
      "[107/00057] train_loss: 0.006132\n",
      "[107/00107] train_loss: 0.006170\n",
      "[107/00157] train_loss: 0.006037\n",
      "[107/00207] train_loss: 0.006068\n",
      "[107/00257] train_loss: 0.006146\n",
      "[107/00307] train_loss: 0.006091\n",
      "[107/00357] train_loss: 0.005971\n",
      "[108/00001] train_loss: 0.006079\n",
      "[108/00051] train_loss: 0.006184\n",
      "[108/00101] train_loss: 0.006071\n",
      "[108/00151] train_loss: 0.006092\n",
      "[108/00201] train_loss: 0.006064\n",
      "[108/00251] train_loss: 0.006063\n",
      "[108/00301] train_loss: 0.006142\n",
      "[108/00351] train_loss: 0.006086\n",
      "[108/00401] train_loss: 0.006095\n",
      "[109/00045] train_loss: 0.006238\n",
      "[109/00095] train_loss: 0.005987\n",
      "[109/00145] train_loss: 0.006103\n",
      "[109/00195] train_loss: 0.006083\n",
      "[109/00245] train_loss: 0.006054\n",
      "[109/00295] train_loss: 0.006010\n",
      "[109/00345] train_loss: 0.006158\n",
      "[109/00395] train_loss: 0.006016\n",
      "[110/00039] train_loss: 0.006103\n",
      "[110/00089] train_loss: 0.006088\n",
      "[110/00139] train_loss: 0.006053\n",
      "[110/00189] train_loss: 0.006125\n",
      "[110/00239] train_loss: 0.006095\n",
      "[110/00289] train_loss: 0.006077\n",
      "[110/00339] train_loss: 0.006116\n",
      "[110/00389] train_loss: 0.006174\n",
      "[111/00033] train_loss: 0.006142\n",
      "[111/00083] train_loss: 0.006155\n",
      "[111/00133] train_loss: 0.006061\n",
      "[111/00183] train_loss: 0.006126\n",
      "[111/00233] train_loss: 0.006063\n",
      "[111/00283] train_loss: 0.006112\n",
      "[111/00333] train_loss: 0.006190\n",
      "[111/00383] train_loss: 0.006112\n",
      "[112/00027] train_loss: 0.006120\n",
      "[112/00077] train_loss: 0.006048\n",
      "[112/00127] train_loss: 0.006093\n",
      "[112/00177] train_loss: 0.006093\n",
      "[112/00227] train_loss: 0.006065\n",
      "[112/00277] train_loss: 0.006108\n",
      "[112/00327] train_loss: 0.006159\n",
      "[112/00377] train_loss: 0.006055\n",
      "[113/00021] train_loss: 0.006109\n",
      "[113/00071] train_loss: 0.006103\n",
      "[113/00121] train_loss: 0.006086\n",
      "[113/00171] train_loss: 0.006108\n",
      "[113/00221] train_loss: 0.006132\n",
      "[113/00271] train_loss: 0.006091\n",
      "[113/00321] train_loss: 0.006124\n",
      "[113/00371] train_loss: 0.006049\n",
      "[114/00015] train_loss: 0.006070\n",
      "[114/00065] train_loss: 0.006116\n",
      "[114/00115] train_loss: 0.006066\n",
      "[114/00165] train_loss: 0.006029\n",
      "[114/00215] train_loss: 0.006127\n",
      "[114/00265] train_loss: 0.006124\n",
      "[114/00315] train_loss: 0.006067\n",
      "[114/00365] train_loss: 0.006072\n",
      "[115/00009] train_loss: 0.006098\n",
      "[115/00059] train_loss: 0.006059\n",
      "[115/00109] train_loss: 0.006067\n",
      "[115/00159] train_loss: 0.006124\n",
      "[115/00209] train_loss: 0.006036\n",
      "[115/00259] train_loss: 0.006064\n",
      "[115/00309] train_loss: 0.006189\n",
      "[115/00359] train_loss: 0.006093\n",
      "[116/00003] train_loss: 0.006016\n",
      "[116/00053] train_loss: 0.006127\n",
      "[116/00103] train_loss: 0.006115\n",
      "[116/00153] train_loss: 0.006091\n",
      "[116/00203] train_loss: 0.006065\n",
      "[116/00253] train_loss: 0.006125\n",
      "[116/00303] train_loss: 0.006076\n",
      "[116/00353] train_loss: 0.006162\n",
      "[116/00403] train_loss: 0.006054\n",
      "[117/00047] train_loss: 0.005980\n",
      "[117/00097] train_loss: 0.006160\n",
      "[117/00147] train_loss: 0.006107\n",
      "[117/00197] train_loss: 0.006103\n",
      "[117/00247] train_loss: 0.006139\n",
      "[117/00297] train_loss: 0.006119\n",
      "[117/00347] train_loss: 0.006065\n",
      "[117/00397] train_loss: 0.006166\n",
      "[118/00041] train_loss: 0.006089\n",
      "[118/00091] train_loss: 0.006120\n",
      "[118/00141] train_loss: 0.006152\n",
      "[118/00191] train_loss: 0.006096\n",
      "[118/00241] train_loss: 0.006208\n",
      "[118/00291] train_loss: 0.006156\n",
      "[118/00341] train_loss: 0.006089\n",
      "[118/00391] train_loss: 0.006035\n",
      "[119/00035] train_loss: 0.006107\n",
      "[119/00085] train_loss: 0.006036\n",
      "[119/00135] train_loss: 0.006099\n",
      "[119/00185] train_loss: 0.006010\n",
      "[119/00235] train_loss: 0.006105\n",
      "[119/00285] train_loss: 0.006109\n",
      "[119/00335] train_loss: 0.006147\n",
      "[119/00385] train_loss: 0.006083\n",
      "[120/00029] train_loss: 0.006122\n",
      "[120/00079] train_loss: 0.006076\n",
      "[120/00129] train_loss: 0.006119\n",
      "[120/00179] train_loss: 0.006017\n",
      "[120/00229] train_loss: 0.006138\n",
      "[120/00279] train_loss: 0.006092\n",
      "[120/00329] train_loss: 0.006161\n",
      "[120/00379] train_loss: 0.006099\n",
      "[121/00023] train_loss: 0.006127\n",
      "[121/00073] train_loss: 0.006157\n",
      "[121/00123] train_loss: 0.006081\n",
      "[121/00173] train_loss: 0.006092\n",
      "[121/00223] train_loss: 0.006055\n",
      "[121/00273] train_loss: 0.006181\n",
      "[121/00323] train_loss: 0.006051\n",
      "[121/00373] train_loss: 0.006084\n",
      "[122/00017] train_loss: 0.006094\n",
      "[122/00067] train_loss: 0.006022\n",
      "[122/00117] train_loss: 0.006088\n",
      "[122/00167] train_loss: 0.006148\n",
      "[122/00217] train_loss: 0.006023\n",
      "[122/00267] train_loss: 0.006059\n",
      "[122/00317] train_loss: 0.006116\n",
      "[122/00367] train_loss: 0.006090\n",
      "[123/00011] train_loss: 0.006179\n",
      "[123/00061] train_loss: 0.006040\n",
      "[123/00111] train_loss: 0.006155\n",
      "[123/00161] train_loss: 0.006007\n",
      "[123/00211] train_loss: 0.006093\n",
      "[123/00261] train_loss: 0.006123\n",
      "[123/00311] train_loss: 0.006087\n",
      "[123/00361] train_loss: 0.006081\n",
      "[124/00005] train_loss: 0.006074\n",
      "[124/00055] train_loss: 0.006086\n",
      "[124/00105] train_loss: 0.006071\n",
      "[124/00155] train_loss: 0.006224\n",
      "[124/00205] train_loss: 0.006196\n",
      "[124/00255] train_loss: 0.006114\n",
      "[124/00305] train_loss: 0.005980\n",
      "[124/00355] train_loss: 0.006059\n",
      "[124/00405] train_loss: 0.006130\n",
      "[125/00049] train_loss: 0.006219\n",
      "[125/00099] train_loss: 0.006049\n",
      "[125/00149] train_loss: 0.006155\n",
      "[125/00199] train_loss: 0.006117\n",
      "[125/00249] train_loss: 0.006095\n",
      "[125/00299] train_loss: 0.006158\n",
      "[125/00349] train_loss: 0.006144\n",
      "[125/00399] train_loss: 0.006146\n",
      "[126/00043] train_loss: 0.006033\n",
      "[126/00093] train_loss: 0.006117\n",
      "[126/00143] train_loss: 0.006102\n",
      "[126/00193] train_loss: 0.006048\n",
      "[126/00243] train_loss: 0.006131\n",
      "[126/00293] train_loss: 0.006090\n",
      "[126/00343] train_loss: 0.006052\n",
      "[126/00393] train_loss: 0.006090\n",
      "[127/00037] train_loss: 0.006181\n",
      "[127/00087] train_loss: 0.006103\n",
      "[127/00137] train_loss: 0.006056\n",
      "[127/00187] train_loss: 0.006082\n",
      "[127/00237] train_loss: 0.006091\n",
      "[127/00287] train_loss: 0.006091\n",
      "[127/00337] train_loss: 0.006048\n",
      "[127/00387] train_loss: 0.006148\n",
      "[128/00031] train_loss: 0.006093\n",
      "[128/00081] train_loss: 0.006023\n",
      "[128/00131] train_loss: 0.006043\n",
      "[128/00181] train_loss: 0.006091\n",
      "[128/00231] train_loss: 0.006137\n",
      "[128/00281] train_loss: 0.006212\n",
      "[128/00331] train_loss: 0.006187\n",
      "[128/00381] train_loss: 0.006093\n",
      "[129/00025] train_loss: 0.006114\n",
      "[129/00075] train_loss: 0.006064\n",
      "[129/00125] train_loss: 0.006091\n",
      "[129/00175] train_loss: 0.006100\n",
      "[129/00225] train_loss: 0.006074\n",
      "[129/00275] train_loss: 0.006149\n",
      "[129/00325] train_loss: 0.006130\n",
      "[129/00375] train_loss: 0.006085\n",
      "[130/00019] train_loss: 0.006084\n",
      "[130/00069] train_loss: 0.006006\n",
      "[130/00119] train_loss: 0.006128\n",
      "[130/00169] train_loss: 0.006123\n",
      "[130/00219] train_loss: 0.006116\n",
      "[130/00269] train_loss: 0.006100\n",
      "[130/00319] train_loss: 0.006046\n",
      "[130/00369] train_loss: 0.006089\n",
      "[131/00013] train_loss: 0.006163\n",
      "[131/00063] train_loss: 0.006078\n",
      "[131/00113] train_loss: 0.006060\n",
      "[131/00163] train_loss: 0.006054\n",
      "[131/00213] train_loss: 0.006074\n",
      "[131/00263] train_loss: 0.006003\n",
      "[131/00313] train_loss: 0.006175\n",
      "[131/00363] train_loss: 0.006092\n",
      "[132/00007] train_loss: 0.006223\n",
      "[132/00057] train_loss: 0.006039\n",
      "[132/00107] train_loss: 0.006137\n",
      "[132/00157] train_loss: 0.006111\n",
      "[132/00207] train_loss: 0.006046\n",
      "[132/00257] train_loss: 0.006068\n",
      "[132/00307] train_loss: 0.006175\n",
      "[132/00357] train_loss: 0.006110\n",
      "[133/00001] train_loss: 0.006092\n",
      "[133/00051] train_loss: 0.006070\n",
      "[133/00101] train_loss: 0.006132\n",
      "[133/00151] train_loss: 0.006117\n",
      "[133/00201] train_loss: 0.006079\n",
      "[133/00251] train_loss: 0.006033\n",
      "[133/00301] train_loss: 0.006082\n",
      "[133/00351] train_loss: 0.006178\n",
      "[133/00401] train_loss: 0.006075\n",
      "[134/00045] train_loss: 0.006090\n",
      "[134/00095] train_loss: 0.006146\n",
      "[134/00145] train_loss: 0.006166\n",
      "[134/00195] train_loss: 0.006142\n",
      "[134/00245] train_loss: 0.006120\n",
      "[134/00295] train_loss: 0.006014\n",
      "[134/00345] train_loss: 0.006118\n",
      "[134/00395] train_loss: 0.006140\n",
      "[135/00039] train_loss: 0.006078\n",
      "[135/00089] train_loss: 0.006095\n",
      "[135/00139] train_loss: 0.006113\n",
      "[135/00189] train_loss: 0.006139\n",
      "[135/00239] train_loss: 0.006175\n",
      "[135/00289] train_loss: 0.006200\n",
      "[135/00339] train_loss: 0.006111\n",
      "[135/00389] train_loss: 0.006097\n",
      "[136/00033] train_loss: 0.006163\n",
      "[136/00083] train_loss: 0.006068\n",
      "[136/00133] train_loss: 0.006126\n",
      "[136/00183] train_loss: 0.006051\n",
      "[136/00233] train_loss: 0.006117\n",
      "[136/00283] train_loss: 0.006107\n",
      "[136/00333] train_loss: 0.006121\n",
      "[136/00383] train_loss: 0.006099\n",
      "[137/00027] train_loss: 0.006164\n",
      "[137/00077] train_loss: 0.006106\n",
      "[137/00127] train_loss: 0.006005\n",
      "[137/00177] train_loss: 0.006008\n",
      "[137/00227] train_loss: 0.006106\n",
      "[137/00277] train_loss: 0.006109\n",
      "[137/00327] train_loss: 0.006188\n",
      "[137/00377] train_loss: 0.006089\n",
      "[138/00021] train_loss: 0.006023\n",
      "[138/00071] train_loss: 0.006071\n",
      "[138/00121] train_loss: 0.006136\n",
      "[138/00171] train_loss: 0.006144\n",
      "[138/00221] train_loss: 0.006199\n",
      "[138/00271] train_loss: 0.006053\n",
      "[138/00321] train_loss: 0.006073\n",
      "[138/00371] train_loss: 0.006037\n",
      "[139/00015] train_loss: 0.006128\n",
      "[139/00065] train_loss: 0.006052\n",
      "[139/00115] train_loss: 0.006227\n",
      "[139/00165] train_loss: 0.006114\n",
      "[139/00215] train_loss: 0.006109\n",
      "[139/00265] train_loss: 0.006116\n",
      "[139/00315] train_loss: 0.006090\n",
      "[139/00365] train_loss: 0.006081\n",
      "[140/00009] train_loss: 0.006095\n",
      "[140/00059] train_loss: 0.006092\n",
      "[140/00109] train_loss: 0.006062\n",
      "[140/00159] train_loss: 0.006193\n",
      "[140/00209] train_loss: 0.006132\n",
      "[140/00259] train_loss: 0.006033\n",
      "[140/00309] train_loss: 0.006083\n",
      "[140/00359] train_loss: 0.006087\n",
      "[141/00003] train_loss: 0.006085\n",
      "[141/00053] train_loss: 0.006217\n",
      "[141/00103] train_loss: 0.006072\n",
      "[141/00153] train_loss: 0.006057\n",
      "[141/00203] train_loss: 0.006097\n",
      "[141/00253] train_loss: 0.006189\n",
      "[141/00303] train_loss: 0.006122\n",
      "[141/00353] train_loss: 0.006071\n",
      "[141/00403] train_loss: 0.006190\n",
      "[142/00047] train_loss: 0.006050\n",
      "[142/00097] train_loss: 0.006142\n",
      "[142/00147] train_loss: 0.006143\n",
      "[142/00197] train_loss: 0.006134\n",
      "[142/00247] train_loss: 0.006121\n",
      "[142/00297] train_loss: 0.006039\n",
      "[142/00347] train_loss: 0.006147\n",
      "[142/00397] train_loss: 0.006131\n",
      "[143/00041] train_loss: 0.006103\n",
      "[143/00091] train_loss: 0.006026\n",
      "[143/00141] train_loss: 0.006112\n",
      "[143/00191] train_loss: 0.006113\n",
      "[143/00241] train_loss: 0.005946\n",
      "[143/00291] train_loss: 0.006123\n",
      "[143/00341] train_loss: 0.006161\n",
      "[143/00391] train_loss: 0.006072\n",
      "[144/00035] train_loss: 0.006089\n",
      "[144/00085] train_loss: 0.006131\n",
      "[144/00135] train_loss: 0.006049\n",
      "[144/00185] train_loss: 0.006069\n",
      "[144/00235] train_loss: 0.006074\n",
      "[144/00285] train_loss: 0.006120\n",
      "[144/00335] train_loss: 0.006146\n",
      "[144/00385] train_loss: 0.006081\n",
      "[145/00029] train_loss: 0.006030\n",
      "[145/00079] train_loss: 0.006018\n",
      "[145/00129] train_loss: 0.006059\n",
      "[145/00179] train_loss: 0.006111\n",
      "[145/00229] train_loss: 0.006089\n",
      "[145/00279] train_loss: 0.006116\n",
      "[145/00329] train_loss: 0.006163\n",
      "[145/00379] train_loss: 0.006137\n",
      "[146/00023] train_loss: 0.006140\n",
      "[146/00073] train_loss: 0.006207\n",
      "[146/00123] train_loss: 0.006078\n",
      "[146/00173] train_loss: 0.006077\n",
      "[146/00223] train_loss: 0.006175\n",
      "[146/00273] train_loss: 0.006115\n",
      "[146/00323] train_loss: 0.006132\n",
      "[146/00373] train_loss: 0.006122\n",
      "[147/00017] train_loss: 0.006096\n",
      "[147/00067] train_loss: 0.006126\n",
      "[147/00117] train_loss: 0.006051\n",
      "[147/00167] train_loss: 0.006059\n",
      "[147/00217] train_loss: 0.006071\n",
      "[147/00267] train_loss: 0.006102\n",
      "[147/00317] train_loss: 0.006159\n",
      "[147/00367] train_loss: 0.006161\n",
      "[148/00011] train_loss: 0.005983\n",
      "[148/00061] train_loss: 0.006096\n",
      "[148/00111] train_loss: 0.006092\n",
      "[148/00161] train_loss: 0.006097\n",
      "[148/00211] train_loss: 0.006092\n",
      "[148/00261] train_loss: 0.006152\n",
      "[148/00311] train_loss: 0.006037\n",
      "[148/00361] train_loss: 0.006130\n",
      "[149/00005] train_loss: 0.006126\n",
      "[149/00055] train_loss: 0.005985\n",
      "[149/00105] train_loss: 0.006017\n",
      "[149/00155] train_loss: 0.006083\n",
      "[149/00205] train_loss: 0.006137\n",
      "[149/00255] train_loss: 0.006043\n",
      "[149/00305] train_loss: 0.006085\n",
      "[149/00355] train_loss: 0.006164\n",
      "[149/00405] train_loss: 0.006082\n",
      "[150/00049] train_loss: 0.006043\n",
      "[150/00099] train_loss: 0.006035\n",
      "[150/00149] train_loss: 0.006122\n",
      "[150/00199] train_loss: 0.006110\n",
      "[150/00249] train_loss: 0.006181\n",
      "[150/00299] train_loss: 0.006179\n",
      "[150/00349] train_loss: 0.006083\n",
      "[150/00399] train_loss: 0.006157\n",
      "[151/00043] train_loss: 0.006127\n",
      "[151/00093] train_loss: 0.006054\n",
      "[151/00143] train_loss: 0.006021\n",
      "[151/00193] train_loss: 0.006127\n",
      "[151/00243] train_loss: 0.006046\n",
      "[151/00293] train_loss: 0.006170\n",
      "[151/00343] train_loss: 0.006170\n",
      "[151/00393] train_loss: 0.006106\n",
      "[152/00037] train_loss: 0.006098\n",
      "[152/00087] train_loss: 0.006070\n",
      "[152/00137] train_loss: 0.006091\n",
      "[152/00187] train_loss: 0.006095\n",
      "[152/00237] train_loss: 0.006108\n",
      "[152/00287] train_loss: 0.006174\n",
      "[152/00337] train_loss: 0.006089\n",
      "[152/00387] train_loss: 0.006119\n",
      "[153/00031] train_loss: 0.006062\n",
      "[153/00081] train_loss: 0.006066\n",
      "[153/00131] train_loss: 0.006098\n",
      "[153/00181] train_loss: 0.006124\n",
      "[153/00231] train_loss: 0.006142\n",
      "[153/00281] train_loss: 0.006084\n",
      "[153/00331] train_loss: 0.006182\n",
      "[153/00381] train_loss: 0.006047\n",
      "[154/00025] train_loss: 0.006135\n",
      "[154/00075] train_loss: 0.006147\n",
      "[154/00125] train_loss: 0.006053\n",
      "[154/00175] train_loss: 0.006071\n",
      "[154/00225] train_loss: 0.006105\n",
      "[154/00275] train_loss: 0.006019\n",
      "[154/00325] train_loss: 0.006116\n",
      "[154/00375] train_loss: 0.006095\n",
      "[155/00019] train_loss: 0.006103\n",
      "[155/00069] train_loss: 0.006050\n",
      "[155/00119] train_loss: 0.006073\n",
      "[155/00169] train_loss: 0.006183\n",
      "[155/00219] train_loss: 0.006115\n",
      "[155/00269] train_loss: 0.006156\n",
      "[155/00319] train_loss: 0.006088\n",
      "[155/00369] train_loss: 0.006130\n",
      "[156/00013] train_loss: 0.006124\n",
      "[156/00063] train_loss: 0.006095\n",
      "[156/00113] train_loss: 0.006132\n",
      "[156/00163] train_loss: 0.006139\n",
      "[156/00213] train_loss: 0.006138\n",
      "[156/00263] train_loss: 0.006115\n",
      "[156/00313] train_loss: 0.006177\n",
      "[156/00363] train_loss: 0.006062\n",
      "[157/00007] train_loss: 0.006175\n",
      "[157/00057] train_loss: 0.006039\n",
      "[157/00107] train_loss: 0.006063\n",
      "[157/00157] train_loss: 0.006160\n",
      "[157/00207] train_loss: 0.006130\n",
      "[157/00257] train_loss: 0.006073\n",
      "[157/00307] train_loss: 0.006074\n",
      "[157/00357] train_loss: 0.006111\n",
      "[158/00001] train_loss: 0.006119\n",
      "[158/00051] train_loss: 0.006008\n",
      "[158/00101] train_loss: 0.006109\n",
      "[158/00151] train_loss: 0.006098\n",
      "[158/00201] train_loss: 0.006098\n",
      "[158/00251] train_loss: 0.006046\n",
      "[158/00301] train_loss: 0.006135\n",
      "[158/00351] train_loss: 0.006058\n",
      "[158/00401] train_loss: 0.006066\n",
      "[159/00045] train_loss: 0.006023\n",
      "[159/00095] train_loss: 0.006110\n",
      "[159/00145] train_loss: 0.006063\n",
      "[159/00195] train_loss: 0.006105\n",
      "[159/00245] train_loss: 0.006092\n",
      "[159/00295] train_loss: 0.006074\n",
      "[159/00345] train_loss: 0.006155\n",
      "[159/00395] train_loss: 0.006049\n",
      "[160/00039] train_loss: 0.006056\n",
      "[160/00089] train_loss: 0.006103\n",
      "[160/00139] train_loss: 0.006081\n",
      "[160/00189] train_loss: 0.006134\n",
      "[160/00239] train_loss: 0.006068\n",
      "[160/00289] train_loss: 0.006209\n",
      "[160/00339] train_loss: 0.006103\n",
      "[160/00389] train_loss: 0.006114\n",
      "[161/00033] train_loss: 0.006100\n",
      "[161/00083] train_loss: 0.006099\n",
      "[161/00133] train_loss: 0.006088\n",
      "[161/00183] train_loss: 0.006091\n",
      "[161/00233] train_loss: 0.006113\n",
      "[161/00283] train_loss: 0.006183\n",
      "[161/00333] train_loss: 0.006102\n",
      "[161/00383] train_loss: 0.006084\n",
      "[162/00027] train_loss: 0.006050\n",
      "[162/00077] train_loss: 0.006105\n",
      "[162/00127] train_loss: 0.006129\n",
      "[162/00177] train_loss: 0.006141\n",
      "[162/00227] train_loss: 0.006148\n",
      "[162/00277] train_loss: 0.006153\n",
      "[162/00327] train_loss: 0.006084\n",
      "[162/00377] train_loss: 0.006089\n",
      "[163/00021] train_loss: 0.006106\n",
      "[163/00071] train_loss: 0.006134\n",
      "[163/00121] train_loss: 0.006141\n",
      "[163/00171] train_loss: 0.006061\n",
      "[163/00221] train_loss: 0.006003\n",
      "[163/00271] train_loss: 0.006118\n",
      "[163/00321] train_loss: 0.006172\n",
      "[163/00371] train_loss: 0.006041\n",
      "[164/00015] train_loss: 0.005971\n",
      "[164/00065] train_loss: 0.006133\n",
      "[164/00115] train_loss: 0.006160\n",
      "[164/00165] train_loss: 0.006025\n",
      "[164/00215] train_loss: 0.006043\n",
      "[164/00265] train_loss: 0.006106\n",
      "[164/00315] train_loss: 0.006112\n",
      "[164/00365] train_loss: 0.006225\n",
      "[165/00009] train_loss: 0.006074\n",
      "[165/00059] train_loss: 0.006187\n",
      "[165/00109] train_loss: 0.006174\n",
      "[165/00159] train_loss: 0.005970\n",
      "[165/00209] train_loss: 0.006108\n",
      "[165/00259] train_loss: 0.006205\n",
      "[165/00309] train_loss: 0.006059\n",
      "[165/00359] train_loss: 0.006108\n",
      "[166/00003] train_loss: 0.006011\n",
      "[166/00053] train_loss: 0.006039\n",
      "[166/00103] train_loss: 0.006110\n",
      "[166/00153] train_loss: 0.006114\n",
      "[166/00203] train_loss: 0.006087\n",
      "[166/00253] train_loss: 0.006067\n",
      "[166/00303] train_loss: 0.006070\n",
      "[166/00353] train_loss: 0.006212\n",
      "[166/00403] train_loss: 0.006080\n",
      "[167/00047] train_loss: 0.006119\n",
      "[167/00097] train_loss: 0.006129\n",
      "[167/00147] train_loss: 0.006175\n",
      "[167/00197] train_loss: 0.006073\n",
      "[167/00247] train_loss: 0.006091\n",
      "[167/00297] train_loss: 0.006006\n",
      "[167/00347] train_loss: 0.006053\n",
      "[167/00397] train_loss: 0.006103\n",
      "[168/00041] train_loss: 0.006239\n",
      "[168/00091] train_loss: 0.006108\n",
      "[168/00141] train_loss: 0.006104\n",
      "[168/00191] train_loss: 0.006074\n",
      "[168/00241] train_loss: 0.006170\n",
      "[168/00291] train_loss: 0.006139\n",
      "[168/00341] train_loss: 0.006078\n",
      "[168/00391] train_loss: 0.006060\n",
      "[169/00035] train_loss: 0.006063\n",
      "[169/00085] train_loss: 0.006125\n",
      "[169/00135] train_loss: 0.006137\n",
      "[169/00185] train_loss: 0.006161\n",
      "[169/00235] train_loss: 0.006167\n",
      "[169/00285] train_loss: 0.006024\n",
      "[169/00335] train_loss: 0.006131\n",
      "[169/00385] train_loss: 0.006043\n",
      "[170/00029] train_loss: 0.006087\n",
      "[170/00079] train_loss: 0.006066\n",
      "[170/00129] train_loss: 0.006045\n",
      "[170/00179] train_loss: 0.006030\n",
      "[170/00229] train_loss: 0.006176\n",
      "[170/00279] train_loss: 0.006017\n",
      "[170/00329] train_loss: 0.006067\n",
      "[170/00379] train_loss: 0.006090\n",
      "[171/00023] train_loss: 0.006005\n",
      "[171/00073] train_loss: 0.006108\n",
      "[171/00123] train_loss: 0.006075\n",
      "[171/00173] train_loss: 0.006111\n",
      "[171/00223] train_loss: 0.006112\n",
      "[171/00273] train_loss: 0.006112\n",
      "[171/00323] train_loss: 0.006062\n",
      "[171/00373] train_loss: 0.006077\n",
      "[172/00017] train_loss: 0.006135\n",
      "[172/00067] train_loss: 0.006087\n",
      "[172/00117] train_loss: 0.006072\n",
      "[172/00167] train_loss: 0.006053\n",
      "[172/00217] train_loss: 0.006011\n",
      "[172/00267] train_loss: 0.006124\n",
      "[172/00317] train_loss: 0.006130\n",
      "[172/00367] train_loss: 0.006029\n",
      "[173/00011] train_loss: 0.006013\n",
      "[173/00061] train_loss: 0.006062\n",
      "[173/00111] train_loss: 0.006003\n",
      "[173/00161] train_loss: 0.006185\n",
      "[173/00211] train_loss: 0.006096\n",
      "[173/00261] train_loss: 0.006125\n",
      "[173/00311] train_loss: 0.006149\n",
      "[173/00361] train_loss: 0.006015\n",
      "[174/00005] train_loss: 0.006147\n",
      "[174/00055] train_loss: 0.006150\n",
      "[174/00105] train_loss: 0.006181\n",
      "[174/00155] train_loss: 0.006049\n",
      "[174/00205] train_loss: 0.006021\n",
      "[174/00255] train_loss: 0.006098\n",
      "[174/00305] train_loss: 0.006155\n",
      "[174/00355] train_loss: 0.006155\n",
      "[174/00405] train_loss: 0.006149\n",
      "[175/00049] train_loss: 0.006056\n",
      "[175/00099] train_loss: 0.006056\n",
      "[175/00149] train_loss: 0.006143\n",
      "[175/00199] train_loss: 0.006188\n",
      "[175/00249] train_loss: 0.006033\n",
      "[175/00299] train_loss: 0.006119\n",
      "[175/00349] train_loss: 0.006128\n",
      "[175/00399] train_loss: 0.006085\n",
      "[176/00043] train_loss: 0.006063\n",
      "[176/00093] train_loss: 0.006073\n",
      "[176/00143] train_loss: 0.006027\n",
      "[176/00193] train_loss: 0.006125\n",
      "[176/00243] train_loss: 0.006121\n",
      "[176/00293] train_loss: 0.006155\n",
      "[176/00343] train_loss: 0.006125\n",
      "[176/00393] train_loss: 0.006083\n",
      "[177/00037] train_loss: 0.006111\n",
      "[177/00087] train_loss: 0.006089\n",
      "[177/00137] train_loss: 0.006064\n",
      "[177/00187] train_loss: 0.006231\n",
      "[177/00237] train_loss: 0.006133\n",
      "[177/00287] train_loss: 0.006087\n",
      "[177/00337] train_loss: 0.006170\n",
      "[177/00387] train_loss: 0.006112\n",
      "[178/00031] train_loss: 0.006031\n",
      "[178/00081] train_loss: 0.006118\n",
      "[178/00131] train_loss: 0.006115\n",
      "[178/00181] train_loss: 0.006099\n",
      "[178/00231] train_loss: 0.006069\n",
      "[178/00281] train_loss: 0.006055\n",
      "[178/00331] train_loss: 0.006074\n",
      "[178/00381] train_loss: 0.006047\n",
      "[179/00025] train_loss: 0.006082\n",
      "[179/00075] train_loss: 0.006110\n",
      "[179/00125] train_loss: 0.006112\n",
      "[179/00175] train_loss: 0.006066\n",
      "[179/00225] train_loss: 0.006133\n",
      "[179/00275] train_loss: 0.006131\n",
      "[179/00325] train_loss: 0.006149\n",
      "[179/00375] train_loss: 0.006069\n",
      "[180/00019] train_loss: 0.006124\n",
      "[180/00069] train_loss: 0.006070\n",
      "[180/00119] train_loss: 0.006067\n",
      "[180/00169] train_loss: 0.006110\n",
      "[180/00219] train_loss: 0.006103\n",
      "[180/00269] train_loss: 0.006094\n",
      "[180/00319] train_loss: 0.006000\n",
      "[180/00369] train_loss: 0.006129\n",
      "[181/00013] train_loss: 0.006082\n",
      "[181/00063] train_loss: 0.006196\n",
      "[181/00113] train_loss: 0.006188\n",
      "[181/00163] train_loss: 0.006056\n",
      "[181/00213] train_loss: 0.006124\n",
      "[181/00263] train_loss: 0.006173\n",
      "[181/00313] train_loss: 0.005997\n",
      "[181/00363] train_loss: 0.006121\n",
      "[182/00007] train_loss: 0.006128\n",
      "[182/00057] train_loss: 0.006000\n",
      "[182/00107] train_loss: 0.006073\n",
      "[182/00157] train_loss: 0.006068\n",
      "[182/00207] train_loss: 0.006044\n",
      "[182/00257] train_loss: 0.006039\n",
      "[182/00307] train_loss: 0.006092\n",
      "[182/00357] train_loss: 0.006113\n",
      "[183/00001] train_loss: 0.006068\n",
      "[183/00051] train_loss: 0.006092\n",
      "[183/00101] train_loss: 0.006091\n",
      "[183/00151] train_loss: 0.006140\n",
      "[183/00201] train_loss: 0.006137\n",
      "[183/00251] train_loss: 0.006133\n",
      "[183/00301] train_loss: 0.006152\n",
      "[183/00351] train_loss: 0.006127\n",
      "[183/00401] train_loss: 0.006128\n",
      "[184/00045] train_loss: 0.006101\n",
      "[184/00095] train_loss: 0.006084\n",
      "[184/00145] train_loss: 0.006068\n",
      "[184/00195] train_loss: 0.006107\n",
      "[184/00245] train_loss: 0.006189\n",
      "[184/00295] train_loss: 0.006105\n",
      "[184/00345] train_loss: 0.006115\n",
      "[184/00395] train_loss: 0.006202\n",
      "[185/00039] train_loss: 0.006093\n",
      "[185/00089] train_loss: 0.006096\n",
      "[185/00139] train_loss: 0.006086\n",
      "[185/00189] train_loss: 0.006097\n",
      "[185/00239] train_loss: 0.006109\n",
      "[185/00289] train_loss: 0.006077\n",
      "[185/00339] train_loss: 0.006172\n",
      "[185/00389] train_loss: 0.006092\n",
      "[186/00033] train_loss: 0.006140\n",
      "[186/00083] train_loss: 0.006110\n",
      "[186/00133] train_loss: 0.006060\n",
      "[186/00183] train_loss: 0.006188\n",
      "[186/00233] train_loss: 0.006188\n",
      "[186/00283] train_loss: 0.005998\n",
      "[186/00333] train_loss: 0.006089\n",
      "[186/00383] train_loss: 0.006084\n",
      "[187/00027] train_loss: 0.006087\n",
      "[187/00077] train_loss: 0.006093\n",
      "[187/00127] train_loss: 0.006174\n",
      "[187/00177] train_loss: 0.006121\n",
      "[187/00227] train_loss: 0.006116\n",
      "[187/00277] train_loss: 0.006100\n",
      "[187/00327] train_loss: 0.006049\n",
      "[187/00377] train_loss: 0.006142\n",
      "[188/00021] train_loss: 0.006127\n",
      "[188/00071] train_loss: 0.006138\n",
      "[188/00121] train_loss: 0.006014\n",
      "[188/00171] train_loss: 0.006130\n",
      "[188/00221] train_loss: 0.006110\n",
      "[188/00271] train_loss: 0.006048\n",
      "[188/00321] train_loss: 0.006144\n",
      "[188/00371] train_loss: 0.006070\n",
      "[189/00015] train_loss: 0.006131\n",
      "[189/00065] train_loss: 0.006149\n",
      "[189/00115] train_loss: 0.006035\n",
      "[189/00165] train_loss: 0.006078\n",
      "[189/00215] train_loss: 0.006144\n",
      "[189/00265] train_loss: 0.006078\n",
      "[189/00315] train_loss: 0.006139\n",
      "[189/00365] train_loss: 0.006123\n",
      "[190/00009] train_loss: 0.006082\n",
      "[190/00059] train_loss: 0.006083\n",
      "[190/00109] train_loss: 0.006105\n",
      "[190/00159] train_loss: 0.006191\n",
      "[190/00209] train_loss: 0.006062\n",
      "[190/00259] train_loss: 0.006006\n",
      "[190/00309] train_loss: 0.006059\n",
      "[190/00359] train_loss: 0.006057\n",
      "[191/00003] train_loss: 0.006096\n",
      "[191/00053] train_loss: 0.006004\n",
      "[191/00103] train_loss: 0.006065\n",
      "[191/00153] train_loss: 0.006052\n",
      "[191/00203] train_loss: 0.006094\n",
      "[191/00253] train_loss: 0.006114\n",
      "[191/00303] train_loss: 0.006087\n",
      "[191/00353] train_loss: 0.006062\n",
      "[191/00403] train_loss: 0.006085\n",
      "[192/00047] train_loss: 0.006129\n",
      "[192/00097] train_loss: 0.006071\n",
      "[192/00147] train_loss: 0.006150\n",
      "[192/00197] train_loss: 0.006053\n",
      "[192/00247] train_loss: 0.006168\n",
      "[192/00297] train_loss: 0.006076\n",
      "[192/00347] train_loss: 0.006205\n",
      "[192/00397] train_loss: 0.006110\n",
      "[193/00041] train_loss: 0.006047\n",
      "[193/00091] train_loss: 0.006112\n",
      "[193/00141] train_loss: 0.006055\n",
      "[193/00191] train_loss: 0.006137\n",
      "[193/00241] train_loss: 0.006089\n",
      "[193/00291] train_loss: 0.006103\n",
      "[193/00341] train_loss: 0.006149\n",
      "[193/00391] train_loss: 0.006075\n",
      "[194/00035] train_loss: 0.006167\n",
      "[194/00085] train_loss: 0.006121\n",
      "[194/00135] train_loss: 0.006105\n",
      "[194/00185] train_loss: 0.006120\n",
      "[194/00235] train_loss: 0.006084\n",
      "[194/00285] train_loss: 0.006103\n",
      "[194/00335] train_loss: 0.006090\n",
      "[194/00385] train_loss: 0.006151\n",
      "[195/00029] train_loss: 0.006108\n",
      "[195/00079] train_loss: 0.006155\n",
      "[195/00129] train_loss: 0.006125\n",
      "[195/00179] train_loss: 0.006110\n",
      "[195/00229] train_loss: 0.006108\n",
      "[195/00279] train_loss: 0.006042\n",
      "[195/00329] train_loss: 0.006045\n",
      "[195/00379] train_loss: 0.006181\n",
      "[196/00023] train_loss: 0.006064\n",
      "[196/00073] train_loss: 0.006159\n",
      "[196/00123] train_loss: 0.006163\n",
      "[196/00173] train_loss: 0.006041\n",
      "[196/00223] train_loss: 0.006054\n",
      "[196/00273] train_loss: 0.006101\n",
      "[196/00323] train_loss: 0.006176\n",
      "[196/00373] train_loss: 0.006158\n",
      "[197/00017] train_loss: 0.006086\n",
      "[197/00067] train_loss: 0.006083\n",
      "[197/00117] train_loss: 0.006072\n",
      "[197/00167] train_loss: 0.006117\n",
      "[197/00217] train_loss: 0.006088\n",
      "[197/00267] train_loss: 0.006132\n",
      "[197/00317] train_loss: 0.006099\n",
      "[197/00367] train_loss: 0.006091\n",
      "[198/00011] train_loss: 0.006069\n",
      "[198/00061] train_loss: 0.006102\n",
      "[198/00111] train_loss: 0.006049\n",
      "[198/00161] train_loss: 0.006134\n",
      "[198/00211] train_loss: 0.006081\n",
      "[198/00261] train_loss: 0.006136\n",
      "[198/00311] train_loss: 0.006197\n",
      "[198/00361] train_loss: 0.006056\n",
      "[199/00005] train_loss: 0.006171\n",
      "[199/00055] train_loss: 0.006133\n",
      "[199/00105] train_loss: 0.006143\n",
      "[199/00155] train_loss: 0.006085\n",
      "[199/00205] train_loss: 0.006090\n",
      "[199/00255] train_loss: 0.006068\n",
      "[199/00305] train_loss: 0.006010\n",
      "[199/00355] train_loss: 0.006088\n",
      "[199/00405] train_loss: 0.006162\n",
      "[200/00049] train_loss: 0.006063\n",
      "[200/00099] train_loss: 0.006157\n",
      "[200/00149] train_loss: 0.006093\n",
      "[200/00199] train_loss: 0.006050\n",
      "[200/00249] train_loss: 0.006045\n",
      "[200/00299] train_loss: 0.006082\n",
      "[200/00349] train_loss: 0.006069\n",
      "[200/00399] train_loss: 0.006087\n",
      "[201/00043] train_loss: 0.006130\n",
      "[201/00093] train_loss: 0.006058\n",
      "[201/00143] train_loss: 0.006081\n",
      "[201/00193] train_loss: 0.006131\n",
      "[201/00243] train_loss: 0.006135\n",
      "[201/00293] train_loss: 0.006072\n",
      "[201/00343] train_loss: 0.006047\n",
      "[201/00393] train_loss: 0.006135\n",
      "[202/00037] train_loss: 0.006064\n",
      "[202/00087] train_loss: 0.006066\n",
      "[202/00137] train_loss: 0.006079\n",
      "[202/00187] train_loss: 0.006073\n",
      "[202/00237] train_loss: 0.006081\n",
      "[202/00287] train_loss: 0.006049\n",
      "[202/00337] train_loss: 0.006083\n",
      "[202/00387] train_loss: 0.006074\n",
      "[203/00031] train_loss: 0.006037\n",
      "[203/00081] train_loss: 0.006038\n",
      "[203/00131] train_loss: 0.006068\n",
      "[203/00181] train_loss: 0.006044\n",
      "[203/00231] train_loss: 0.006102\n",
      "[203/00281] train_loss: 0.006028\n",
      "[203/00331] train_loss: 0.006073\n",
      "[203/00381] train_loss: 0.006094\n",
      "[204/00025] train_loss: 0.006112\n",
      "[204/00075] train_loss: 0.006127\n",
      "[204/00125] train_loss: 0.006087\n",
      "[204/00175] train_loss: 0.006059\n",
      "[204/00225] train_loss: 0.006161\n",
      "[204/00275] train_loss: 0.006120\n",
      "[204/00325] train_loss: 0.006150\n",
      "[204/00375] train_loss: 0.006168\n",
      "[205/00019] train_loss: 0.006078\n",
      "[205/00069] train_loss: 0.006161\n",
      "[205/00119] train_loss: 0.006183\n",
      "[205/00169] train_loss: 0.006077\n",
      "[205/00219] train_loss: 0.006141\n",
      "[205/00269] train_loss: 0.006064\n",
      "[205/00319] train_loss: 0.006166\n",
      "[205/00369] train_loss: 0.006076\n",
      "[206/00013] train_loss: 0.006160\n",
      "[206/00063] train_loss: 0.006121\n",
      "[206/00113] train_loss: 0.006132\n",
      "[206/00163] train_loss: 0.006132\n",
      "[206/00213] train_loss: 0.005986\n",
      "[206/00263] train_loss: 0.006127\n",
      "[206/00313] train_loss: 0.006150\n",
      "[206/00363] train_loss: 0.006132\n",
      "[207/00007] train_loss: 0.006209\n",
      "[207/00057] train_loss: 0.006113\n",
      "[207/00107] train_loss: 0.006104\n",
      "[207/00157] train_loss: 0.006074\n",
      "[207/00207] train_loss: 0.006157\n",
      "[207/00257] train_loss: 0.006075\n",
      "[207/00307] train_loss: 0.006141\n",
      "[207/00357] train_loss: 0.006078\n",
      "[208/00001] train_loss: 0.006136\n",
      "[208/00051] train_loss: 0.006033\n",
      "[208/00101] train_loss: 0.006064\n",
      "[208/00151] train_loss: 0.006086\n",
      "[208/00201] train_loss: 0.006104\n",
      "[208/00251] train_loss: 0.006107\n",
      "[208/00301] train_loss: 0.006108\n",
      "[208/00351] train_loss: 0.006085\n",
      "[208/00401] train_loss: 0.006043\n",
      "[209/00045] train_loss: 0.006122\n",
      "[209/00095] train_loss: 0.006044\n",
      "[209/00145] train_loss: 0.006155\n",
      "[209/00195] train_loss: 0.006094\n",
      "[209/00245] train_loss: 0.006127\n",
      "[209/00295] train_loss: 0.006048\n",
      "[209/00345] train_loss: 0.006154\n",
      "[209/00395] train_loss: 0.006112\n",
      "[210/00039] train_loss: 0.006147\n",
      "[210/00089] train_loss: 0.006145\n",
      "[210/00139] train_loss: 0.006043\n",
      "[210/00189] train_loss: 0.006173\n",
      "[210/00239] train_loss: 0.006200\n",
      "[210/00289] train_loss: 0.006061\n",
      "[210/00339] train_loss: 0.006074\n",
      "[210/00389] train_loss: 0.006199\n",
      "[211/00033] train_loss: 0.006133\n",
      "[211/00083] train_loss: 0.006167\n",
      "[211/00133] train_loss: 0.006099\n",
      "[211/00183] train_loss: 0.006137\n",
      "[211/00233] train_loss: 0.006053\n",
      "[211/00283] train_loss: 0.006088\n",
      "[211/00333] train_loss: 0.006166\n",
      "[211/00383] train_loss: 0.006040\n",
      "[212/00027] train_loss: 0.006079\n",
      "[212/00077] train_loss: 0.006088\n",
      "[212/00127] train_loss: 0.006029\n",
      "[212/00177] train_loss: 0.006060\n",
      "[212/00227] train_loss: 0.006144\n",
      "[212/00277] train_loss: 0.006102\n",
      "[212/00327] train_loss: 0.006127\n",
      "[212/00377] train_loss: 0.006009\n",
      "[213/00021] train_loss: 0.006058\n",
      "[213/00071] train_loss: 0.006090\n",
      "[213/00121] train_loss: 0.006052\n",
      "[213/00171] train_loss: 0.006185\n",
      "[213/00221] train_loss: 0.006130\n",
      "[213/00271] train_loss: 0.006110\n",
      "[213/00321] train_loss: 0.006039\n",
      "[213/00371] train_loss: 0.006140\n",
      "[214/00015] train_loss: 0.006101\n",
      "[214/00065] train_loss: 0.006090\n",
      "[214/00115] train_loss: 0.006077\n",
      "[214/00165] train_loss: 0.006067\n",
      "[214/00215] train_loss: 0.006133\n",
      "[214/00265] train_loss: 0.006074\n",
      "[214/00315] train_loss: 0.006105\n",
      "[214/00365] train_loss: 0.006121\n",
      "[215/00009] train_loss: 0.006136\n",
      "[215/00059] train_loss: 0.006085\n",
      "[215/00109] train_loss: 0.006142\n",
      "[215/00159] train_loss: 0.006120\n",
      "[215/00209] train_loss: 0.006020\n",
      "[215/00259] train_loss: 0.006112\n",
      "[215/00309] train_loss: 0.006113\n",
      "[215/00359] train_loss: 0.006061\n",
      "[216/00003] train_loss: 0.006039\n",
      "[216/00053] train_loss: 0.006071\n",
      "[216/00103] train_loss: 0.006044\n",
      "[216/00153] train_loss: 0.006102\n",
      "[216/00203] train_loss: 0.006117\n",
      "[216/00253] train_loss: 0.006109\n",
      "[216/00303] train_loss: 0.006109\n",
      "[216/00353] train_loss: 0.006136\n",
      "[216/00403] train_loss: 0.006071\n",
      "[217/00047] train_loss: 0.006090\n",
      "[217/00097] train_loss: 0.006083\n",
      "[217/00147] train_loss: 0.006080\n",
      "[217/00197] train_loss: 0.006081\n",
      "[217/00247] train_loss: 0.006170\n",
      "[217/00297] train_loss: 0.006052\n",
      "[217/00347] train_loss: 0.006169\n",
      "[217/00397] train_loss: 0.006073\n",
      "[218/00041] train_loss: 0.006025\n",
      "[218/00091] train_loss: 0.006170\n",
      "[218/00141] train_loss: 0.006104\n",
      "[218/00191] train_loss: 0.006147\n",
      "[218/00241] train_loss: 0.006014\n",
      "[218/00291] train_loss: 0.006104\n",
      "[218/00341] train_loss: 0.006154\n",
      "[218/00391] train_loss: 0.006156\n",
      "[219/00035] train_loss: 0.006093\n",
      "[219/00085] train_loss: 0.006105\n",
      "[219/00135] train_loss: 0.006034\n",
      "[219/00185] train_loss: 0.006083\n",
      "[219/00235] train_loss: 0.006115\n",
      "[219/00285] train_loss: 0.006064\n",
      "[219/00335] train_loss: 0.006144\n",
      "[219/00385] train_loss: 0.006157\n",
      "[220/00029] train_loss: 0.006056\n",
      "[220/00079] train_loss: 0.006011\n",
      "[220/00129] train_loss: 0.006152\n",
      "[220/00179] train_loss: 0.006024\n",
      "[220/00229] train_loss: 0.006065\n",
      "[220/00279] train_loss: 0.006106\n",
      "[220/00329] train_loss: 0.006118\n",
      "[220/00379] train_loss: 0.006193\n",
      "[221/00023] train_loss: 0.006062\n",
      "[221/00073] train_loss: 0.006087\n",
      "[221/00123] train_loss: 0.006108\n",
      "[221/00173] train_loss: 0.006097\n",
      "[221/00223] train_loss: 0.006076\n",
      "[221/00273] train_loss: 0.006042\n",
      "[221/00323] train_loss: 0.006163\n",
      "[221/00373] train_loss: 0.006089\n",
      "[222/00017] train_loss: 0.006132\n",
      "[222/00067] train_loss: 0.006147\n",
      "[222/00117] train_loss: 0.006172\n",
      "[222/00167] train_loss: 0.006088\n",
      "[222/00217] train_loss: 0.006083\n",
      "[222/00267] train_loss: 0.006026\n",
      "[222/00317] train_loss: 0.006173\n",
      "[222/00367] train_loss: 0.006068\n",
      "[223/00011] train_loss: 0.006090\n",
      "[223/00061] train_loss: 0.006155\n",
      "[223/00111] train_loss: 0.006051\n",
      "[223/00161] train_loss: 0.006088\n",
      "[223/00211] train_loss: 0.006128\n",
      "[223/00261] train_loss: 0.006142\n",
      "[223/00311] train_loss: 0.006049\n",
      "[223/00361] train_loss: 0.006170\n",
      "[224/00005] train_loss: 0.006083\n",
      "[224/00055] train_loss: 0.006060\n",
      "[224/00105] train_loss: 0.006080\n",
      "[224/00155] train_loss: 0.006135\n",
      "[224/00205] train_loss: 0.006041\n",
      "[224/00255] train_loss: 0.006051\n",
      "[224/00305] train_loss: 0.006132\n",
      "[224/00355] train_loss: 0.006030\n",
      "[224/00405] train_loss: 0.006094\n",
      "[225/00049] train_loss: 0.006130\n",
      "[225/00099] train_loss: 0.006033\n",
      "[225/00149] train_loss: 0.006142\n",
      "[225/00199] train_loss: 0.006036\n",
      "[225/00249] train_loss: 0.006142\n",
      "[225/00299] train_loss: 0.006047\n",
      "[225/00349] train_loss: 0.006027\n",
      "[225/00399] train_loss: 0.006117\n",
      "[226/00043] train_loss: 0.006096\n",
      "[226/00093] train_loss: 0.006103\n",
      "[226/00143] train_loss: 0.006078\n",
      "[226/00193] train_loss: 0.006061\n",
      "[226/00243] train_loss: 0.006176\n",
      "[226/00293] train_loss: 0.006040\n",
      "[226/00343] train_loss: 0.006157\n",
      "[226/00393] train_loss: 0.006084\n",
      "[227/00037] train_loss: 0.006077\n",
      "[227/00087] train_loss: 0.006018\n",
      "[227/00137] train_loss: 0.006092\n",
      "[227/00187] train_loss: 0.006035\n",
      "[227/00237] train_loss: 0.006085\n",
      "[227/00287] train_loss: 0.006139\n",
      "[227/00337] train_loss: 0.006120\n",
      "[227/00387] train_loss: 0.006031\n",
      "[228/00031] train_loss: 0.006043\n",
      "[228/00081] train_loss: 0.006113\n",
      "[228/00131] train_loss: 0.006082\n",
      "[228/00181] train_loss: 0.006157\n",
      "[228/00231] train_loss: 0.006166\n",
      "[228/00281] train_loss: 0.006071\n",
      "[228/00331] train_loss: 0.006044\n",
      "[228/00381] train_loss: 0.006137\n",
      "[229/00025] train_loss: 0.006177\n",
      "[229/00075] train_loss: 0.006072\n",
      "[229/00125] train_loss: 0.006018\n",
      "[229/00175] train_loss: 0.006224\n",
      "[229/00225] train_loss: 0.006112\n",
      "[229/00275] train_loss: 0.006106\n",
      "[229/00325] train_loss: 0.006077\n",
      "[229/00375] train_loss: 0.006093\n",
      "[230/00019] train_loss: 0.006068\n",
      "[230/00069] train_loss: 0.006067\n",
      "[230/00119] train_loss: 0.006094\n",
      "[230/00169] train_loss: 0.006066\n",
      "[230/00219] train_loss: 0.006066\n",
      "[230/00269] train_loss: 0.006089\n",
      "[230/00319] train_loss: 0.006106\n",
      "[230/00369] train_loss: 0.006213\n",
      "[231/00013] train_loss: 0.006098\n",
      "[231/00063] train_loss: 0.006173\n",
      "[231/00113] train_loss: 0.006110\n",
      "[231/00163] train_loss: 0.006048\n",
      "[231/00213] train_loss: 0.006055\n",
      "[231/00263] train_loss: 0.006066\n",
      "[231/00313] train_loss: 0.006144\n",
      "[231/00363] train_loss: 0.006106\n",
      "[232/00007] train_loss: 0.006059\n",
      "[232/00057] train_loss: 0.006089\n",
      "[232/00107] train_loss: 0.006091\n",
      "[232/00157] train_loss: 0.006140\n",
      "[232/00207] train_loss: 0.006123\n",
      "[232/00257] train_loss: 0.006149\n",
      "[232/00307] train_loss: 0.006151\n",
      "[232/00357] train_loss: 0.006113\n",
      "[233/00001] train_loss: 0.006045\n",
      "[233/00051] train_loss: 0.006183\n",
      "[233/00101] train_loss: 0.006117\n",
      "[233/00151] train_loss: 0.006143\n",
      "[233/00201] train_loss: 0.006064\n",
      "[233/00251] train_loss: 0.006058\n",
      "[233/00301] train_loss: 0.006094\n",
      "[233/00351] train_loss: 0.006103\n",
      "[233/00401] train_loss: 0.005988\n",
      "[234/00045] train_loss: 0.006199\n",
      "[234/00095] train_loss: 0.006160\n",
      "[234/00145] train_loss: 0.006115\n",
      "[234/00195] train_loss: 0.006136\n",
      "[234/00245] train_loss: 0.006091\n",
      "[234/00295] train_loss: 0.006010\n",
      "[234/00345] train_loss: 0.006140\n",
      "[234/00395] train_loss: 0.006116\n",
      "[235/00039] train_loss: 0.006096\n",
      "[235/00089] train_loss: 0.006111\n",
      "[235/00139] train_loss: 0.006055\n",
      "[235/00189] train_loss: 0.006053\n",
      "[235/00239] train_loss: 0.006129\n",
      "[235/00289] train_loss: 0.006055\n",
      "[235/00339] train_loss: 0.006089\n",
      "[235/00389] train_loss: 0.006086\n",
      "[236/00033] train_loss: 0.006120\n",
      "[236/00083] train_loss: 0.006086\n",
      "[236/00133] train_loss: 0.006087\n",
      "[236/00183] train_loss: 0.006064\n",
      "[236/00233] train_loss: 0.006148\n",
      "[236/00283] train_loss: 0.006202\n",
      "[236/00333] train_loss: 0.006102\n",
      "[236/00383] train_loss: 0.006097\n",
      "[237/00027] train_loss: 0.006089\n",
      "[237/00077] train_loss: 0.006057\n",
      "[237/00127] train_loss: 0.006118\n",
      "[237/00177] train_loss: 0.006103\n",
      "[237/00227] train_loss: 0.006165\n",
      "[237/00277] train_loss: 0.006187\n",
      "[237/00327] train_loss: 0.006143\n",
      "[237/00377] train_loss: 0.006156\n",
      "[238/00021] train_loss: 0.006094\n",
      "[238/00071] train_loss: 0.006076\n",
      "[238/00121] train_loss: 0.006138\n",
      "[238/00171] train_loss: 0.006121\n",
      "[238/00221] train_loss: 0.006067\n",
      "[238/00271] train_loss: 0.006231\n",
      "[238/00321] train_loss: 0.006071\n",
      "[238/00371] train_loss: 0.006117\n",
      "[239/00015] train_loss: 0.006079\n",
      "[239/00065] train_loss: 0.006092\n",
      "[239/00115] train_loss: 0.006105\n",
      "[239/00165] train_loss: 0.006014\n",
      "[239/00215] train_loss: 0.006091\n",
      "[239/00265] train_loss: 0.006081\n",
      "[239/00315] train_loss: 0.006048\n",
      "[239/00365] train_loss: 0.006095\n",
      "[240/00009] train_loss: 0.006082\n",
      "[240/00059] train_loss: 0.006083\n",
      "[240/00109] train_loss: 0.006068\n",
      "[240/00159] train_loss: 0.006105\n",
      "[240/00209] train_loss: 0.006204\n",
      "[240/00259] train_loss: 0.006136\n",
      "[240/00309] train_loss: 0.006050\n",
      "[240/00359] train_loss: 0.006112\n",
      "[241/00003] train_loss: 0.006076\n",
      "[241/00053] train_loss: 0.006205\n",
      "[241/00103] train_loss: 0.006150\n",
      "[241/00153] train_loss: 0.006168\n",
      "[241/00203] train_loss: 0.006151\n",
      "[241/00253] train_loss: 0.006027\n",
      "[241/00303] train_loss: 0.005990\n",
      "[241/00353] train_loss: 0.006112\n",
      "[241/00403] train_loss: 0.006149\n",
      "[242/00047] train_loss: 0.006032\n",
      "[242/00097] train_loss: 0.006162\n",
      "[242/00147] train_loss: 0.006183\n",
      "[242/00197] train_loss: 0.006208\n",
      "[242/00247] train_loss: 0.006070\n",
      "[242/00297] train_loss: 0.006077\n",
      "[242/00347] train_loss: 0.006111\n",
      "[242/00397] train_loss: 0.006072\n",
      "[243/00041] train_loss: 0.006236\n",
      "[243/00091] train_loss: 0.006017\n",
      "[243/00141] train_loss: 0.006164\n",
      "[243/00191] train_loss: 0.006152\n",
      "[243/00241] train_loss: 0.006082\n",
      "[243/00291] train_loss: 0.005984\n",
      "[243/00341] train_loss: 0.006037\n",
      "[243/00391] train_loss: 0.006069\n",
      "[244/00035] train_loss: 0.006183\n",
      "[244/00085] train_loss: 0.006131\n",
      "[244/00135] train_loss: 0.006120\n",
      "[244/00185] train_loss: 0.006145\n",
      "[244/00235] train_loss: 0.006181\n",
      "[244/00285] train_loss: 0.006039\n",
      "[244/00335] train_loss: 0.006212\n",
      "[244/00385] train_loss: 0.006167\n",
      "[245/00029] train_loss: 0.006071\n",
      "[245/00079] train_loss: 0.006029\n",
      "[245/00129] train_loss: 0.006164\n",
      "[245/00179] train_loss: 0.006114\n",
      "[245/00229] train_loss: 0.006034\n",
      "[245/00279] train_loss: 0.006031\n",
      "[245/00329] train_loss: 0.006132\n",
      "[245/00379] train_loss: 0.006194\n",
      "[246/00023] train_loss: 0.006151\n",
      "[246/00073] train_loss: 0.006083\n",
      "[246/00123] train_loss: 0.006131\n",
      "[246/00173] train_loss: 0.006121\n",
      "[246/00223] train_loss: 0.006070\n",
      "[246/00273] train_loss: 0.006111\n",
      "[246/00323] train_loss: 0.006155\n",
      "[246/00373] train_loss: 0.006099\n",
      "[247/00017] train_loss: 0.006142\n",
      "[247/00067] train_loss: 0.006104\n",
      "[247/00117] train_loss: 0.006099\n",
      "[247/00167] train_loss: 0.006114\n",
      "[247/00217] train_loss: 0.006141\n",
      "[247/00267] train_loss: 0.006085\n",
      "[247/00317] train_loss: 0.006140\n",
      "[247/00367] train_loss: 0.006153\n",
      "[248/00011] train_loss: 0.006056\n",
      "[248/00061] train_loss: 0.006085\n",
      "[248/00111] train_loss: 0.006036\n",
      "[248/00161] train_loss: 0.006141\n",
      "[248/00211] train_loss: 0.006063\n",
      "[248/00261] train_loss: 0.006155\n",
      "[248/00311] train_loss: 0.006048\n",
      "[248/00361] train_loss: 0.006031\n",
      "[249/00005] train_loss: 0.006106\n",
      "[249/00055] train_loss: 0.006134\n",
      "[249/00105] train_loss: 0.006028\n",
      "[249/00155] train_loss: 0.006136\n",
      "[249/00205] train_loss: 0.006082\n",
      "[249/00255] train_loss: 0.006092\n",
      "[249/00305] train_loss: 0.006124\n",
      "[249/00355] train_loss: 0.006108\n",
      "[249/00405] train_loss: 0.006088\n",
      "[250/00049] train_loss: 0.006037\n",
      "[250/00099] train_loss: 0.006212\n",
      "[250/00149] train_loss: 0.006127\n",
      "[250/00199] train_loss: 0.006153\n",
      "[250/00249] train_loss: 0.006066\n",
      "[250/00299] train_loss: 0.006059\n",
      "[250/00349] train_loss: 0.006077\n",
      "[250/00399] train_loss: 0.006081\n",
      "[251/00043] train_loss: 0.006078\n",
      "[251/00093] train_loss: 0.006077\n",
      "[251/00143] train_loss: 0.006140\n",
      "[251/00193] train_loss: 0.006188\n",
      "[251/00243] train_loss: 0.006089\n",
      "[251/00293] train_loss: 0.006127\n",
      "[251/00343] train_loss: 0.006060\n",
      "[251/00393] train_loss: 0.006129\n",
      "[252/00037] train_loss: 0.006110\n",
      "[252/00087] train_loss: 0.006046\n",
      "[252/00137] train_loss: 0.006192\n",
      "[252/00187] train_loss: 0.006103\n",
      "[252/00237] train_loss: 0.006176\n",
      "[252/00287] train_loss: 0.006172\n",
      "[252/00337] train_loss: 0.006067\n",
      "[252/00387] train_loss: 0.006041\n",
      "[253/00031] train_loss: 0.006052\n",
      "[253/00081] train_loss: 0.006117\n",
      "[253/00131] train_loss: 0.006121\n",
      "[253/00181] train_loss: 0.006150\n",
      "[253/00231] train_loss: 0.006109\n",
      "[253/00281] train_loss: 0.006119\n",
      "[253/00331] train_loss: 0.006092\n",
      "[253/00381] train_loss: 0.006017\n",
      "[254/00025] train_loss: 0.006046\n",
      "[254/00075] train_loss: 0.006168\n",
      "[254/00125] train_loss: 0.006194\n",
      "[254/00175] train_loss: 0.006135\n",
      "[254/00225] train_loss: 0.006092\n",
      "[254/00275] train_loss: 0.006075\n",
      "[254/00325] train_loss: 0.006082\n",
      "[254/00375] train_loss: 0.006098\n",
      "[255/00019] train_loss: 0.006023\n",
      "[255/00069] train_loss: 0.006037\n",
      "[255/00119] train_loss: 0.006031\n",
      "[255/00169] train_loss: 0.006127\n",
      "[255/00219] train_loss: 0.006010\n",
      "[255/00269] train_loss: 0.006123\n",
      "[255/00319] train_loss: 0.006102\n",
      "[255/00369] train_loss: 0.006080\n",
      "[256/00013] train_loss: 0.006149\n",
      "[256/00063] train_loss: 0.006043\n",
      "[256/00113] train_loss: 0.006008\n",
      "[256/00163] train_loss: 0.006173\n",
      "[256/00213] train_loss: 0.006119\n",
      "[256/00263] train_loss: 0.006160\n",
      "[256/00313] train_loss: 0.006171\n",
      "[256/00363] train_loss: 0.006075\n",
      "[257/00007] train_loss: 0.006167\n",
      "[257/00057] train_loss: 0.006106\n",
      "[257/00107] train_loss: 0.006119\n",
      "[257/00157] train_loss: 0.006078\n",
      "[257/00207] train_loss: 0.006081\n",
      "[257/00257] train_loss: 0.006087\n",
      "[257/00307] train_loss: 0.006041\n",
      "[257/00357] train_loss: 0.005981\n",
      "[258/00001] train_loss: 0.006061\n",
      "[258/00051] train_loss: 0.006100\n",
      "[258/00101] train_loss: 0.006099\n",
      "[258/00151] train_loss: 0.006142\n",
      "[258/00201] train_loss: 0.006031\n",
      "[258/00251] train_loss: 0.006113\n",
      "[258/00301] train_loss: 0.006097\n",
      "[258/00351] train_loss: 0.006073\n",
      "[258/00401] train_loss: 0.006146\n",
      "[259/00045] train_loss: 0.006086\n",
      "[259/00095] train_loss: 0.006088\n",
      "[259/00145] train_loss: 0.006071\n",
      "[259/00195] train_loss: 0.006092\n",
      "[259/00245] train_loss: 0.006067\n",
      "[259/00295] train_loss: 0.006097\n",
      "[259/00345] train_loss: 0.006085\n",
      "[259/00395] train_loss: 0.006163\n",
      "[260/00039] train_loss: 0.006047\n",
      "[260/00089] train_loss: 0.006070\n",
      "[260/00139] train_loss: 0.006063\n",
      "[260/00189] train_loss: 0.006129\n",
      "[260/00239] train_loss: 0.006073\n",
      "[260/00289] train_loss: 0.006118\n",
      "[260/00339] train_loss: 0.006122\n",
      "[260/00389] train_loss: 0.006136\n",
      "[261/00033] train_loss: 0.006070\n",
      "[261/00083] train_loss: 0.006093\n",
      "[261/00133] train_loss: 0.006112\n",
      "[261/00183] train_loss: 0.005989\n",
      "[261/00233] train_loss: 0.006035\n",
      "[261/00283] train_loss: 0.006127\n",
      "[261/00333] train_loss: 0.006077\n",
      "[261/00383] train_loss: 0.006096\n",
      "[262/00027] train_loss: 0.006114\n",
      "[262/00077] train_loss: 0.006132\n",
      "[262/00127] train_loss: 0.006133\n",
      "[262/00177] train_loss: 0.006205\n",
      "[262/00227] train_loss: 0.006071\n",
      "[262/00277] train_loss: 0.005983\n",
      "[262/00327] train_loss: 0.006095\n",
      "[262/00377] train_loss: 0.006055\n",
      "[263/00021] train_loss: 0.006000\n",
      "[263/00071] train_loss: 0.006087\n",
      "[263/00121] train_loss: 0.006151\n",
      "[263/00171] train_loss: 0.006129\n",
      "[263/00221] train_loss: 0.006162\n",
      "[263/00271] train_loss: 0.006072\n",
      "[263/00321] train_loss: 0.006031\n",
      "[263/00371] train_loss: 0.006071\n",
      "[264/00015] train_loss: 0.006165\n",
      "[264/00065] train_loss: 0.006188\n",
      "[264/00115] train_loss: 0.006073\n",
      "[264/00165] train_loss: 0.006091\n",
      "[264/00215] train_loss: 0.006121\n",
      "[264/00265] train_loss: 0.006166\n",
      "[264/00315] train_loss: 0.006238\n",
      "[264/00365] train_loss: 0.006096\n",
      "[265/00009] train_loss: 0.006134\n",
      "[265/00059] train_loss: 0.006033\n",
      "[265/00109] train_loss: 0.006111\n",
      "[265/00159] train_loss: 0.006022\n",
      "[265/00209] train_loss: 0.006066\n",
      "[265/00259] train_loss: 0.006070\n",
      "[265/00309] train_loss: 0.006102\n",
      "[265/00359] train_loss: 0.006043\n",
      "[266/00003] train_loss: 0.006175\n",
      "[266/00053] train_loss: 0.006093\n",
      "[266/00103] train_loss: 0.006091\n",
      "[266/00153] train_loss: 0.006065\n",
      "[266/00203] train_loss: 0.006061\n",
      "[266/00253] train_loss: 0.006100\n",
      "[266/00303] train_loss: 0.006081\n",
      "[266/00353] train_loss: 0.006181\n",
      "[266/00403] train_loss: 0.006189\n",
      "[267/00047] train_loss: 0.006046\n",
      "[267/00097] train_loss: 0.006056\n",
      "[267/00147] train_loss: 0.006129\n",
      "[267/00197] train_loss: 0.006134\n",
      "[267/00247] train_loss: 0.006129\n",
      "[267/00297] train_loss: 0.006059\n",
      "[267/00347] train_loss: 0.006123\n",
      "[267/00397] train_loss: 0.006159\n",
      "[268/00041] train_loss: 0.006072\n",
      "[268/00091] train_loss: 0.006138\n",
      "[268/00141] train_loss: 0.006012\n",
      "[268/00191] train_loss: 0.006021\n",
      "[268/00241] train_loss: 0.006189\n",
      "[268/00291] train_loss: 0.006056\n",
      "[268/00341] train_loss: 0.006110\n",
      "[268/00391] train_loss: 0.006063\n",
      "[269/00035] train_loss: 0.006102\n",
      "[269/00085] train_loss: 0.006021\n",
      "[269/00135] train_loss: 0.006107\n",
      "[269/00185] train_loss: 0.006170\n",
      "[269/00235] train_loss: 0.006115\n",
      "[269/00285] train_loss: 0.006052\n",
      "[269/00335] train_loss: 0.006104\n",
      "[269/00385] train_loss: 0.006123\n",
      "[270/00029] train_loss: 0.006035\n",
      "[270/00079] train_loss: 0.006032\n",
      "[270/00129] train_loss: 0.006191\n",
      "[270/00179] train_loss: 0.006107\n",
      "[270/00229] train_loss: 0.006074\n",
      "[270/00279] train_loss: 0.006020\n",
      "[270/00329] train_loss: 0.006044\n",
      "[270/00379] train_loss: 0.006128\n",
      "[271/00023] train_loss: 0.006199\n",
      "[271/00073] train_loss: 0.006127\n",
      "[271/00123] train_loss: 0.006102\n",
      "[271/00173] train_loss: 0.006129\n",
      "[271/00223] train_loss: 0.006137\n",
      "[271/00273] train_loss: 0.006112\n",
      "[271/00323] train_loss: 0.006122\n",
      "[271/00373] train_loss: 0.006098\n",
      "[272/00017] train_loss: 0.006119\n",
      "[272/00067] train_loss: 0.006185\n",
      "[272/00117] train_loss: 0.006102\n",
      "[272/00167] train_loss: 0.006131\n",
      "[272/00217] train_loss: 0.006026\n",
      "[272/00267] train_loss: 0.006073\n",
      "[272/00317] train_loss: 0.006145\n",
      "[272/00367] train_loss: 0.006021\n",
      "[273/00011] train_loss: 0.006132\n",
      "[273/00061] train_loss: 0.006150\n",
      "[273/00111] train_loss: 0.006165\n",
      "[273/00161] train_loss: 0.006141\n",
      "[273/00211] train_loss: 0.005974\n",
      "[273/00261] train_loss: 0.006175\n",
      "[273/00311] train_loss: 0.006185\n",
      "[273/00361] train_loss: 0.006069\n",
      "[274/00005] train_loss: 0.006083\n",
      "[274/00055] train_loss: 0.006070\n",
      "[274/00105] train_loss: 0.006129\n",
      "[274/00155] train_loss: 0.006045\n",
      "[274/00205] train_loss: 0.006084\n",
      "[274/00255] train_loss: 0.006122\n",
      "[274/00305] train_loss: 0.006131\n",
      "[274/00355] train_loss: 0.006109\n",
      "[274/00405] train_loss: 0.006110\n",
      "[275/00049] train_loss: 0.006089\n",
      "[275/00099] train_loss: 0.006129\n",
      "[275/00149] train_loss: 0.006098\n",
      "[275/00199] train_loss: 0.006084\n",
      "[275/00249] train_loss: 0.006087\n",
      "[275/00299] train_loss: 0.006093\n",
      "[275/00349] train_loss: 0.006052\n",
      "[275/00399] train_loss: 0.006076\n",
      "[276/00043] train_loss: 0.006214\n",
      "[276/00093] train_loss: 0.006153\n",
      "[276/00143] train_loss: 0.006048\n",
      "[276/00193] train_loss: 0.006235\n",
      "[276/00243] train_loss: 0.006136\n",
      "[276/00293] train_loss: 0.006092\n",
      "[276/00343] train_loss: 0.006137\n",
      "[276/00393] train_loss: 0.006094\n",
      "[277/00037] train_loss: 0.006138\n",
      "[277/00087] train_loss: 0.006089\n",
      "[277/00137] train_loss: 0.006109\n",
      "[277/00187] train_loss: 0.006174\n",
      "[277/00237] train_loss: 0.006141\n",
      "[277/00287] train_loss: 0.006045\n",
      "[277/00337] train_loss: 0.006137\n",
      "[277/00387] train_loss: 0.006180\n",
      "[278/00031] train_loss: 0.006115\n",
      "[278/00081] train_loss: 0.006054\n",
      "[278/00131] train_loss: 0.006069\n",
      "[278/00181] train_loss: 0.006065\n",
      "[278/00231] train_loss: 0.006208\n",
      "[278/00281] train_loss: 0.006089\n",
      "[278/00331] train_loss: 0.006058\n",
      "[278/00381] train_loss: 0.006108\n",
      "[279/00025] train_loss: 0.006002\n",
      "[279/00075] train_loss: 0.006053\n",
      "[279/00125] train_loss: 0.006152\n",
      "[279/00175] train_loss: 0.006153\n",
      "[279/00225] train_loss: 0.006162\n",
      "[279/00275] train_loss: 0.006119\n",
      "[279/00325] train_loss: 0.006113\n",
      "[279/00375] train_loss: 0.006169\n",
      "[280/00019] train_loss: 0.006159\n",
      "[280/00069] train_loss: 0.006087\n",
      "[280/00119] train_loss: 0.006131\n",
      "[280/00169] train_loss: 0.006130\n",
      "[280/00219] train_loss: 0.006099\n",
      "[280/00269] train_loss: 0.006101\n",
      "[280/00319] train_loss: 0.006042\n",
      "[280/00369] train_loss: 0.006149\n",
      "[281/00013] train_loss: 0.006079\n",
      "[281/00063] train_loss: 0.006149\n",
      "[281/00113] train_loss: 0.006026\n",
      "[281/00163] train_loss: 0.006098\n",
      "[281/00213] train_loss: 0.006069\n",
      "[281/00263] train_loss: 0.006102\n",
      "[281/00313] train_loss: 0.006179\n",
      "[281/00363] train_loss: 0.006086\n",
      "[282/00007] train_loss: 0.006103\n",
      "[282/00057] train_loss: 0.006123\n",
      "[282/00107] train_loss: 0.006116\n",
      "[282/00157] train_loss: 0.006076\n",
      "[282/00207] train_loss: 0.006066\n",
      "[282/00257] train_loss: 0.006199\n",
      "[282/00307] train_loss: 0.006098\n",
      "[282/00357] train_loss: 0.006090\n",
      "[283/00001] train_loss: 0.006020\n",
      "[283/00051] train_loss: 0.006078\n",
      "[283/00101] train_loss: 0.006119\n",
      "[283/00151] train_loss: 0.006159\n",
      "[283/00201] train_loss: 0.006191\n",
      "[283/00251] train_loss: 0.006181\n",
      "[283/00301] train_loss: 0.006098\n",
      "[283/00351] train_loss: 0.006186\n",
      "[283/00401] train_loss: 0.006026\n",
      "[284/00045] train_loss: 0.006023\n",
      "[284/00095] train_loss: 0.006083\n",
      "[284/00145] train_loss: 0.006099\n",
      "[284/00195] train_loss: 0.006120\n",
      "[284/00245] train_loss: 0.006080\n",
      "[284/00295] train_loss: 0.006080\n",
      "[284/00345] train_loss: 0.006106\n",
      "[284/00395] train_loss: 0.006058\n",
      "[285/00039] train_loss: 0.006078\n",
      "[285/00089] train_loss: 0.006132\n",
      "[285/00139] train_loss: 0.006063\n",
      "[285/00189] train_loss: 0.006109\n",
      "[285/00239] train_loss: 0.006124\n",
      "[285/00289] train_loss: 0.006149\n",
      "[285/00339] train_loss: 0.006011\n",
      "[285/00389] train_loss: 0.006014\n",
      "[286/00033] train_loss: 0.006071\n",
      "[286/00083] train_loss: 0.006045\n",
      "[286/00133] train_loss: 0.006098\n",
      "[286/00183] train_loss: 0.006238\n",
      "[286/00233] train_loss: 0.006072\n",
      "[286/00283] train_loss: 0.006125\n",
      "[286/00333] train_loss: 0.006170\n",
      "[286/00383] train_loss: 0.006057\n",
      "[287/00027] train_loss: 0.006095\n",
      "[287/00077] train_loss: 0.006101\n",
      "[287/00127] train_loss: 0.006055\n",
      "[287/00177] train_loss: 0.006067\n",
      "[287/00227] train_loss: 0.006135\n",
      "[287/00277] train_loss: 0.006194\n",
      "[394/00385] train_loss: 0.006059\n",
      "[395/00029] train_loss: 0.006098\n",
      "[395/00079] train_loss: 0.006163\n",
      "[395/00129] train_loss: 0.006156\n",
      "[395/00179] train_loss: 0.006054\n",
      "[395/00229] train_loss: 0.006083\n",
      "[395/00279] train_loss: 0.006078\n",
      "[395/00329] train_loss: 0.005998\n",
      "[395/00379] train_loss: 0.006166\n",
      "[396/00023] train_loss: 0.006156\n",
      "[396/00073] train_loss: 0.006088\n",
      "[396/00123] train_loss: 0.006241\n",
      "[396/00173] train_loss: 0.006091\n",
      "[396/00223] train_loss: 0.006056\n",
      "[396/00273] train_loss: 0.006078\n",
      "[396/00323] train_loss: 0.006023\n",
      "[396/00373] train_loss: 0.006106\n",
      "[397/00017] train_loss: 0.006056\n",
      "[397/00067] train_loss: 0.006136\n",
      "[397/00117] train_loss: 0.006106\n",
      "[397/00167] train_loss: 0.006110\n",
      "[397/00217] train_loss: 0.006140\n",
      "[397/00267] train_loss: 0.006160\n",
      "[397/00317] train_loss: 0.006144\n",
      "[397/00367] train_loss: 0.006024\n",
      "[398/00011] train_loss: 0.006105\n",
      "[398/00061] train_loss: 0.006054\n",
      "[398/00111] train_loss: 0.006145\n",
      "[398/00161] train_loss: 0.006070\n",
      "[398/00211] train_loss: 0.006044\n",
      "[398/00261] train_loss: 0.006107\n",
      "[398/00311] train_loss: 0.006060\n",
      "[398/00361] train_loss: 0.006118\n",
      "[399/00005] train_loss: 0.006106\n",
      "[399/00055] train_loss: 0.006036\n",
      "[399/00105] train_loss: 0.006073\n",
      "[399/00155] train_loss: 0.006031\n",
      "[399/00205] train_loss: 0.006179\n",
      "[399/00255] train_loss: 0.006154\n",
      "[399/00305] train_loss: 0.006063\n",
      "[399/00355] train_loss: 0.006125\n",
      "[399/00405] train_loss: 0.006112\n",
      "[400/00049] train_loss: 0.006092\n",
      "[400/00099] train_loss: 0.006169\n",
      "[400/00149] train_loss: 0.006122\n",
      "[400/00199] train_loss: 0.006091\n",
      "[400/00249] train_loss: 0.006134\n",
      "[400/00299] train_loss: 0.006045\n",
      "[400/00349] train_loss: 0.006065\n",
      "[400/00399] train_loss: 0.006088\n",
      "[401/00043] train_loss: 0.006101\n",
      "[401/00093] train_loss: 0.006045\n",
      "[401/00143] train_loss: 0.006079\n",
      "[401/00193] train_loss: 0.006084\n",
      "[401/00243] train_loss: 0.006056\n",
      "[401/00293] train_loss: 0.006046\n",
      "[401/00343] train_loss: 0.006071\n",
      "[401/00393] train_loss: 0.006078\n",
      "[402/00037] train_loss: 0.006099\n",
      "[402/00087] train_loss: 0.006061\n",
      "[402/00137] train_loss: 0.006085\n",
      "[402/00187] train_loss: 0.006097\n",
      "[402/00237] train_loss: 0.006073\n",
      "[402/00287] train_loss: 0.006155\n",
      "[402/00337] train_loss: 0.006024\n",
      "[402/00387] train_loss: 0.006046\n",
      "[403/00031] train_loss: 0.006097\n",
      "[403/00081] train_loss: 0.006082\n",
      "[403/00131] train_loss: 0.006054\n",
      "[403/00181] train_loss: 0.006144\n",
      "[403/00231] train_loss: 0.006138\n",
      "[403/00281] train_loss: 0.006016\n",
      "[403/00331] train_loss: 0.006134\n",
      "[403/00381] train_loss: 0.006029\n",
      "[404/00025] train_loss: 0.006072\n",
      "[404/00075] train_loss: 0.006168\n",
      "[404/00125] train_loss: 0.006022\n",
      "[404/00175] train_loss: 0.006139\n",
      "[404/00225] train_loss: 0.006174\n",
      "[404/00275] train_loss: 0.006076\n",
      "[404/00325] train_loss: 0.006135\n",
      "[404/00375] train_loss: 0.006101\n",
      "[405/00019] train_loss: 0.006063\n",
      "[405/00069] train_loss: 0.006171\n",
      "[405/00119] train_loss: 0.006071\n",
      "[405/00169] train_loss: 0.006077\n",
      "[405/00219] train_loss: 0.006107\n",
      "[405/00269] train_loss: 0.006111\n",
      "[405/00319] train_loss: 0.006108\n",
      "[405/00369] train_loss: 0.006143\n",
      "[406/00013] train_loss: 0.006101\n",
      "[406/00063] train_loss: 0.005985\n",
      "[406/00113] train_loss: 0.006045\n",
      "[406/00163] train_loss: 0.006144\n",
      "[406/00213] train_loss: 0.006110\n",
      "[406/00263] train_loss: 0.006042\n",
      "[406/00313] train_loss: 0.005968\n",
      "[406/00363] train_loss: 0.006091\n",
      "[407/00007] train_loss: 0.006168\n",
      "[407/00057] train_loss: 0.006110\n",
      "[407/00107] train_loss: 0.006065\n",
      "[407/00157] train_loss: 0.006148\n",
      "[407/00207] train_loss: 0.006083\n",
      "[407/00257] train_loss: 0.005999\n",
      "[407/00307] train_loss: 0.006093\n",
      "[407/00357] train_loss: 0.006079\n",
      "[408/00001] train_loss: 0.006044\n",
      "[408/00051] train_loss: 0.006066\n",
      "[408/00101] train_loss: 0.006059\n",
      "[408/00151] train_loss: 0.006013\n",
      "[408/00201] train_loss: 0.006119\n",
      "[408/00251] train_loss: 0.006077\n",
      "[408/00301] train_loss: 0.006025\n",
      "[408/00351] train_loss: 0.006233\n",
      "[408/00401] train_loss: 0.006154\n",
      "[409/00045] train_loss: 0.006091\n",
      "[409/00095] train_loss: 0.006178\n",
      "[409/00145] train_loss: 0.006082\n",
      "[409/00195] train_loss: 0.006102\n",
      "[409/00245] train_loss: 0.006031\n",
      "[409/00295] train_loss: 0.006247\n",
      "[409/00345] train_loss: 0.006152\n",
      "[409/00395] train_loss: 0.006047\n",
      "[410/00039] train_loss: 0.006167\n",
      "[410/00089] train_loss: 0.006044\n",
      "[410/00139] train_loss: 0.006037\n",
      "[410/00189] train_loss: 0.006043\n",
      "[410/00239] train_loss: 0.006104\n",
      "[410/00289] train_loss: 0.006146\n",
      "[410/00339] train_loss: 0.006066\n",
      "[410/00389] train_loss: 0.006057\n",
      "[411/00033] train_loss: 0.006170\n",
      "[411/00083] train_loss: 0.006142\n",
      "[411/00133] train_loss: 0.006101\n",
      "[411/00183] train_loss: 0.006165\n",
      "[411/00233] train_loss: 0.006169\n",
      "[411/00283] train_loss: 0.006068\n",
      "[411/00333] train_loss: 0.006131\n",
      "[411/00383] train_loss: 0.006121\n",
      "[412/00027] train_loss: 0.006109\n",
      "[412/00077] train_loss: 0.006197\n",
      "[412/00127] train_loss: 0.006123\n",
      "[412/00177] train_loss: 0.006109\n",
      "[412/00227] train_loss: 0.006079\n",
      "[412/00277] train_loss: 0.006102\n",
      "[412/00327] train_loss: 0.006138\n",
      "[412/00377] train_loss: 0.006117\n",
      "[413/00021] train_loss: 0.006109\n",
      "[413/00071] train_loss: 0.006079\n",
      "[413/00121] train_loss: 0.006103\n",
      "[413/00171] train_loss: 0.006072\n",
      "[413/00221] train_loss: 0.006049\n",
      "[413/00271] train_loss: 0.006231\n",
      "[413/00321] train_loss: 0.006080\n",
      "[413/00371] train_loss: 0.006078\n",
      "[414/00015] train_loss: 0.006131\n",
      "[414/00065] train_loss: 0.005922\n",
      "[414/00115] train_loss: 0.006101\n",
      "[414/00165] train_loss: 0.006069\n",
      "[414/00215] train_loss: 0.006086\n",
      "[414/00265] train_loss: 0.006105\n",
      "[414/00315] train_loss: 0.006096\n",
      "[414/00365] train_loss: 0.006099\n",
      "[415/00009] train_loss: 0.006150\n",
      "[415/00059] train_loss: 0.006168\n",
      "[415/00109] train_loss: 0.006046\n",
      "[415/00159] train_loss: 0.006052\n",
      "[415/00209] train_loss: 0.006130\n",
      "[415/00259] train_loss: 0.006083\n",
      "[415/00309] train_loss: 0.006132\n",
      "[415/00359] train_loss: 0.006099\n",
      "[416/00003] train_loss: 0.006185\n",
      "[416/00053] train_loss: 0.006041\n",
      "[416/00103] train_loss: 0.006079\n",
      "[416/00153] train_loss: 0.006077\n",
      "[416/00203] train_loss: 0.006037\n",
      "[416/00253] train_loss: 0.006204\n",
      "[416/00303] train_loss: 0.006073\n",
      "[416/00353] train_loss: 0.006135\n",
      "[416/00403] train_loss: 0.006131\n",
      "[417/00047] train_loss: 0.006029\n",
      "[417/00097] train_loss: 0.006089\n",
      "[417/00147] train_loss: 0.006068\n",
      "[417/00197] train_loss: 0.006161\n",
      "[417/00247] train_loss: 0.006161\n",
      "[417/00297] train_loss: 0.006228\n",
      "[417/00347] train_loss: 0.006130\n",
      "[417/00397] train_loss: 0.006136\n",
      "[418/00041] train_loss: 0.006139\n",
      "[418/00091] train_loss: 0.006130\n",
      "[418/00141] train_loss: 0.006112\n",
      "[418/00191] train_loss: 0.006061\n",
      "[418/00241] train_loss: 0.006166\n",
      "[418/00291] train_loss: 0.006136\n",
      "[418/00341] train_loss: 0.006012\n",
      "[418/00391] train_loss: 0.006078\n",
      "[419/00035] train_loss: 0.006009\n",
      "[419/00085] train_loss: 0.006172\n",
      "[419/00135] train_loss: 0.006023\n",
      "[419/00185] train_loss: 0.006173\n",
      "[419/00235] train_loss: 0.006189\n",
      "[419/00285] train_loss: 0.006014\n",
      "[419/00335] train_loss: 0.006140\n",
      "[419/00385] train_loss: 0.006071\n",
      "[420/00029] train_loss: 0.006165\n",
      "[420/00079] train_loss: 0.006025\n",
      "[420/00129] train_loss: 0.006051\n",
      "[420/00179] train_loss: 0.006105\n",
      "[420/00229] train_loss: 0.006106\n",
      "[420/00279] train_loss: 0.006076\n",
      "[420/00329] train_loss: 0.006045\n",
      "[420/00379] train_loss: 0.006116\n",
      "[421/00023] train_loss: 0.006068\n",
      "[421/00073] train_loss: 0.006130\n",
      "[421/00123] train_loss: 0.006100\n",
      "[421/00173] train_loss: 0.006104\n",
      "[421/00223] train_loss: 0.006099\n",
      "[421/00273] train_loss: 0.006085\n",
      "[421/00323] train_loss: 0.006007\n",
      "[421/00373] train_loss: 0.006082\n",
      "[422/00017] train_loss: 0.006023\n",
      "[422/00067] train_loss: 0.006109\n",
      "[422/00117] train_loss: 0.006045\n",
      "[422/00167] train_loss: 0.005981\n",
      "[422/00217] train_loss: 0.006110\n",
      "[422/00267] train_loss: 0.006165\n",
      "[422/00317] train_loss: 0.006059\n",
      "[422/00367] train_loss: 0.006111\n",
      "[423/00011] train_loss: 0.006070\n",
      "[423/00061] train_loss: 0.006171\n",
      "[423/00111] train_loss: 0.006130\n",
      "[423/00161] train_loss: 0.006046\n",
      "[423/00211] train_loss: 0.006021\n",
      "[423/00261] train_loss: 0.006126\n",
      "[423/00311] train_loss: 0.006153\n",
      "[423/00361] train_loss: 0.006093\n",
      "[424/00005] train_loss: 0.006077\n",
      "[424/00055] train_loss: 0.006028\n",
      "[424/00105] train_loss: 0.006073\n",
      "[424/00155] train_loss: 0.006150\n",
      "[424/00205] train_loss: 0.006144\n",
      "[424/00255] train_loss: 0.006022\n",
      "[424/00305] train_loss: 0.006125\n",
      "[424/00355] train_loss: 0.006045\n",
      "[424/00405] train_loss: 0.006181\n",
      "[425/00049] train_loss: 0.006101\n",
      "[425/00099] train_loss: 0.006109\n",
      "[425/00149] train_loss: 0.006053\n",
      "[425/00199] train_loss: 0.006133\n",
      "[425/00249] train_loss: 0.006108\n",
      "[425/00299] train_loss: 0.006148\n",
      "[425/00349] train_loss: 0.006122\n",
      "[425/00399] train_loss: 0.006017\n",
      "[426/00043] train_loss: 0.006183\n",
      "[426/00093] train_loss: 0.006156\n",
      "[426/00143] train_loss: 0.006093\n",
      "[426/00193] train_loss: 0.006124\n",
      "[426/00243] train_loss: 0.006138\n",
      "[426/00293] train_loss: 0.006112\n",
      "[426/00343] train_loss: 0.006125\n",
      "[426/00393] train_loss: 0.006043\n",
      "[427/00037] train_loss: 0.006101\n",
      "[427/00087] train_loss: 0.006113\n",
      "[427/00137] train_loss: 0.006142\n",
      "[427/00187] train_loss: 0.006080\n",
      "[427/00237] train_loss: 0.006046\n",
      "[427/00287] train_loss: 0.006087\n",
      "[427/00337] train_loss: 0.006174\n",
      "[427/00387] train_loss: 0.006141\n",
      "[428/00031] train_loss: 0.006074\n",
      "[428/00081] train_loss: 0.006057\n",
      "[428/00131] train_loss: 0.006089\n",
      "[428/00181] train_loss: 0.006080\n",
      "[428/00231] train_loss: 0.006207\n",
      "[428/00281] train_loss: 0.006089\n",
      "[428/00331] train_loss: 0.006152\n",
      "[428/00381] train_loss: 0.006083\n",
      "[429/00025] train_loss: 0.006076\n",
      "[429/00075] train_loss: 0.006089\n",
      "[429/00125] train_loss: 0.006086\n",
      "[429/00175] train_loss: 0.006080\n",
      "[429/00225] train_loss: 0.006036\n",
      "[429/00275] train_loss: 0.006075\n",
      "[429/00325] train_loss: 0.006051\n",
      "[429/00375] train_loss: 0.006113\n",
      "[430/00019] train_loss: 0.006108\n",
      "[430/00069] train_loss: 0.006082\n",
      "[430/00119] train_loss: 0.006051\n",
      "[430/00169] train_loss: 0.006073\n",
      "[430/00219] train_loss: 0.006027\n",
      "[430/00269] train_loss: 0.006103\n",
      "[430/00319] train_loss: 0.006107\n",
      "[430/00369] train_loss: 0.006087\n",
      "[431/00013] train_loss: 0.006024\n",
      "[431/00063] train_loss: 0.006091\n",
      "[431/00113] train_loss: 0.006213\n",
      "[431/00163] train_loss: 0.006075\n",
      "[431/00213] train_loss: 0.006109\n",
      "[431/00263] train_loss: 0.006103\n",
      "[431/00313] train_loss: 0.006187\n",
      "[431/00363] train_loss: 0.006080\n",
      "[432/00007] train_loss: 0.006071\n",
      "[432/00057] train_loss: 0.006050\n",
      "[432/00107] train_loss: 0.006132\n",
      "[432/00157] train_loss: 0.006003\n",
      "[432/00207] train_loss: 0.006079\n",
      "[432/00257] train_loss: 0.006113\n",
      "[432/00307] train_loss: 0.006108\n",
      "[432/00357] train_loss: 0.006006\n",
      "[433/00001] train_loss: 0.006179\n",
      "[433/00051] train_loss: 0.006111\n",
      "[433/00101] train_loss: 0.006153\n",
      "[433/00151] train_loss: 0.006122\n",
      "[433/00201] train_loss: 0.005965\n",
      "[433/00251] train_loss: 0.006093\n",
      "[433/00301] train_loss: 0.006157\n",
      "[433/00351] train_loss: 0.006261\n",
      "[433/00401] train_loss: 0.005999\n",
      "[434/00045] train_loss: 0.006068\n",
      "[434/00095] train_loss: 0.006146\n",
      "[434/00145] train_loss: 0.006133\n",
      "[434/00195] train_loss: 0.006076\n",
      "[434/00245] train_loss: 0.006141\n",
      "[434/00295] train_loss: 0.006146\n",
      "[434/00345] train_loss: 0.006079\n",
      "[434/00395] train_loss: 0.006160\n",
      "[435/00039] train_loss: 0.006067\n",
      "[435/00089] train_loss: 0.006174\n",
      "[435/00139] train_loss: 0.006169\n",
      "[435/00189] train_loss: 0.006139\n",
      "[435/00239] train_loss: 0.006077\n",
      "[435/00289] train_loss: 0.006142\n",
      "[435/00339] train_loss: 0.006092\n",
      "[435/00389] train_loss: 0.006166\n",
      "[436/00033] train_loss: 0.006123\n",
      "[436/00083] train_loss: 0.006112\n",
      "[436/00133] train_loss: 0.006104\n",
      "[436/00183] train_loss: 0.006131\n",
      "[436/00233] train_loss: 0.006145\n",
      "[436/00283] train_loss: 0.006111\n",
      "[436/00333] train_loss: 0.006264\n",
      "[436/00383] train_loss: 0.006112\n",
      "[437/00027] train_loss: 0.006035\n",
      "[437/00077] train_loss: 0.006107\n",
      "[437/00127] train_loss: 0.006074\n",
      "[437/00177] train_loss: 0.006083\n",
      "[437/00227] train_loss: 0.006018\n",
      "[437/00277] train_loss: 0.006130\n",
      "[437/00327] train_loss: 0.006117\n",
      "[437/00377] train_loss: 0.006143\n",
      "[438/00021] train_loss: 0.006080\n",
      "[438/00071] train_loss: 0.006138\n",
      "[438/00121] train_loss: 0.006127\n",
      "[438/00171] train_loss: 0.006104\n",
      "[438/00221] train_loss: 0.006172\n",
      "[438/00271] train_loss: 0.005999\n",
      "[438/00321] train_loss: 0.006115\n",
      "[438/00371] train_loss: 0.006117\n",
      "[439/00015] train_loss: 0.006053\n",
      "[439/00065] train_loss: 0.006104\n",
      "[439/00115] train_loss: 0.006103\n",
      "[439/00165] train_loss: 0.006136\n",
      "[439/00215] train_loss: 0.006072\n",
      "[439/00265] train_loss: 0.006073\n",
      "[439/00315] train_loss: 0.006138\n",
      "[439/00365] train_loss: 0.006185\n",
      "[440/00009] train_loss: 0.006191\n",
      "[440/00059] train_loss: 0.006089\n",
      "[440/00109] train_loss: 0.006117\n",
      "[440/00159] train_loss: 0.006012\n",
      "[440/00209] train_loss: 0.006052\n",
      "[440/00259] train_loss: 0.006177\n",
      "[440/00309] train_loss: 0.006113\n",
      "[440/00359] train_loss: 0.006144\n",
      "[441/00003] train_loss: 0.006182\n",
      "[441/00053] train_loss: 0.006026\n",
      "[441/00103] train_loss: 0.005971\n",
      "[441/00153] train_loss: 0.006113\n",
      "[441/00203] train_loss: 0.006056\n",
      "[441/00253] train_loss: 0.006019\n",
      "[441/00303] train_loss: 0.006036\n",
      "[441/00353] train_loss: 0.006097\n",
      "[441/00403] train_loss: 0.006148\n",
      "[442/00047] train_loss: 0.006092\n",
      "[442/00097] train_loss: 0.006061\n",
      "[442/00147] train_loss: 0.006089\n",
      "[442/00197] train_loss: 0.006053\n",
      "[442/00247] train_loss: 0.006165\n",
      "[442/00297] train_loss: 0.006106\n",
      "[442/00347] train_loss: 0.006130\n",
      "[442/00397] train_loss: 0.006184\n",
      "[443/00041] train_loss: 0.006136\n",
      "[443/00091] train_loss: 0.006177\n",
      "[443/00141] train_loss: 0.006036\n",
      "[443/00191] train_loss: 0.006185\n",
      "[443/00241] train_loss: 0.006102\n",
      "[443/00291] train_loss: 0.006147\n",
      "[443/00341] train_loss: 0.006135\n",
      "[443/00391] train_loss: 0.006051\n",
      "[444/00035] train_loss: 0.006130\n",
      "[444/00085] train_loss: 0.006042\n",
      "[444/00135] train_loss: 0.006114\n",
      "[444/00185] train_loss: 0.006040\n",
      "[444/00235] train_loss: 0.006098\n",
      "[444/00285] train_loss: 0.006084\n",
      "[444/00335] train_loss: 0.006151\n",
      "[444/00385] train_loss: 0.006106\n",
      "[445/00029] train_loss: 0.006099\n",
      "[445/00079] train_loss: 0.006166\n",
      "[445/00129] train_loss: 0.006063\n",
      "[445/00179] train_loss: 0.006071\n",
      "[445/00229] train_loss: 0.006099\n",
      "[445/00279] train_loss: 0.006036\n",
      "[445/00329] train_loss: 0.006074\n",
      "[445/00379] train_loss: 0.006201\n",
      "[446/00023] train_loss: 0.006104\n",
      "[446/00073] train_loss: 0.006009\n",
      "[446/00123] train_loss: 0.006203\n",
      "[446/00173] train_loss: 0.006174\n",
      "[446/00223] train_loss: 0.006147\n",
      "[446/00273] train_loss: 0.006109\n",
      "[446/00323] train_loss: 0.006157\n",
      "[446/00373] train_loss: 0.006130\n",
      "[447/00017] train_loss: 0.006185\n",
      "[447/00067] train_loss: 0.006156\n",
      "[447/00117] train_loss: 0.006147\n",
      "[447/00167] train_loss: 0.006088\n",
      "[447/00217] train_loss: 0.006049\n",
      "[447/00267] train_loss: 0.006169\n",
      "[447/00317] train_loss: 0.006185\n",
      "[447/00367] train_loss: 0.006119\n",
      "[448/00011] train_loss: 0.006171\n",
      "[448/00061] train_loss: 0.006111\n",
      "[448/00111] train_loss: 0.006057\n",
      "[448/00161] train_loss: 0.006049\n",
      "[448/00211] train_loss: 0.006035\n",
      "[448/00261] train_loss: 0.006078\n",
      "[448/00311] train_loss: 0.006093\n",
      "[448/00361] train_loss: 0.006062\n",
      "[449/00005] train_loss: 0.006086\n",
      "[449/00055] train_loss: 0.006126\n",
      "[449/00105] train_loss: 0.006049\n",
      "[449/00155] train_loss: 0.006102\n",
      "[449/00205] train_loss: 0.006093\n",
      "[449/00255] train_loss: 0.006160\n",
      "[449/00305] train_loss: 0.006175\n",
      "[449/00355] train_loss: 0.006128\n",
      "[449/00405] train_loss: 0.006090\n",
      "[450/00049] train_loss: 0.006071\n",
      "[450/00099] train_loss: 0.005989\n",
      "[450/00149] train_loss: 0.006139\n",
      "[450/00199] train_loss: 0.006093\n",
      "[450/00249] train_loss: 0.006136\n",
      "[450/00299] train_loss: 0.006114\n",
      "[450/00349] train_loss: 0.006130\n",
      "[450/00399] train_loss: 0.006107\n",
      "[451/00043] train_loss: 0.006094\n",
      "[451/00093] train_loss: 0.006116\n",
      "[451/00143] train_loss: 0.006091\n",
      "[451/00193] train_loss: 0.006120\n",
      "[451/00243] train_loss: 0.006086\n",
      "[451/00293] train_loss: 0.006132\n",
      "[451/00343] train_loss: 0.006045\n",
      "[451/00393] train_loss: 0.006156\n",
      "[452/00037] train_loss: 0.006127\n",
      "[452/00087] train_loss: 0.006140\n",
      "[452/00137] train_loss: 0.006072\n",
      "[452/00187] train_loss: 0.006059\n",
      "[452/00237] train_loss: 0.006131\n",
      "[452/00287] train_loss: 0.006160\n",
      "[452/00337] train_loss: 0.006086\n",
      "[452/00387] train_loss: 0.006110\n",
      "[453/00031] train_loss: 0.006098\n",
      "[453/00081] train_loss: 0.006101\n",
      "[453/00131] train_loss: 0.006024\n",
      "[453/00181] train_loss: 0.006096\n",
      "[453/00231] train_loss: 0.006064\n",
      "[453/00281] train_loss: 0.006149\n",
      "[453/00331] train_loss: 0.006069\n",
      "[453/00381] train_loss: 0.006147\n",
      "[454/00025] train_loss: 0.006035\n",
      "[454/00075] train_loss: 0.006027\n",
      "[454/00125] train_loss: 0.006174\n",
      "[454/00175] train_loss: 0.006028\n",
      "[454/00225] train_loss: 0.006160\n",
      "[454/00275] train_loss: 0.006116\n",
      "[454/00325] train_loss: 0.006071\n",
      "[454/00375] train_loss: 0.006181\n",
      "[455/00019] train_loss: 0.006203\n",
      "[455/00069] train_loss: 0.006168\n",
      "[455/00119] train_loss: 0.006143\n",
      "[455/00169] train_loss: 0.006075\n",
      "[455/00219] train_loss: 0.006016\n",
      "[455/00269] train_loss: 0.006202\n",
      "[455/00319] train_loss: 0.006129\n",
      "[455/00369] train_loss: 0.006077\n",
      "[456/00013] train_loss: 0.006070\n",
      "[456/00063] train_loss: 0.006112\n",
      "[456/00113] train_loss: 0.006111\n",
      "[456/00163] train_loss: 0.006173\n",
      "[456/00213] train_loss: 0.006118\n",
      "[456/00263] train_loss: 0.006177\n",
      "[456/00313] train_loss: 0.006047\n",
      "[456/00363] train_loss: 0.006091\n",
      "[457/00007] train_loss: 0.006038\n",
      "[457/00057] train_loss: 0.006145\n",
      "[457/00107] train_loss: 0.006068\n",
      "[457/00157] train_loss: 0.006115\n",
      "[457/00207] train_loss: 0.006100\n",
      "[457/00257] train_loss: 0.006108\n",
      "[457/00307] train_loss: 0.006133\n",
      "[457/00357] train_loss: 0.006103\n",
      "[458/00001] train_loss: 0.006116\n",
      "[458/00051] train_loss: 0.006031\n",
      "[458/00101] train_loss: 0.006026\n",
      "[458/00151] train_loss: 0.006127\n",
      "[458/00201] train_loss: 0.006166\n",
      "[458/00251] train_loss: 0.006062\n",
      "[458/00301] train_loss: 0.006060\n",
      "[458/00351] train_loss: 0.006097\n",
      "[458/00401] train_loss: 0.006095\n",
      "[459/00045] train_loss: 0.006039\n",
      "[459/00095] train_loss: 0.005998\n",
      "[459/00145] train_loss: 0.006141\n",
      "[459/00195] train_loss: 0.006119\n",
      "[459/00245] train_loss: 0.006148\n",
      "[459/00295] train_loss: 0.006164\n",
      "[459/00345] train_loss: 0.006173\n",
      "[459/00395] train_loss: 0.006137\n",
      "[460/00039] train_loss: 0.006168\n",
      "[460/00089] train_loss: 0.005996\n",
      "[460/00139] train_loss: 0.006145\n",
      "[460/00189] train_loss: 0.006070\n",
      "[460/00239] train_loss: 0.006183\n",
      "[460/00289] train_loss: 0.006055\n",
      "[460/00339] train_loss: 0.006089\n",
      "[460/00389] train_loss: 0.006149\n",
      "[461/00033] train_loss: 0.006148\n",
      "[461/00083] train_loss: 0.006170\n",
      "[461/00133] train_loss: 0.006013\n",
      "[461/00183] train_loss: 0.006096\n",
      "[461/00233] train_loss: 0.006103\n",
      "[461/00283] train_loss: 0.006096\n",
      "[461/00333] train_loss: 0.006092\n",
      "[461/00383] train_loss: 0.006027\n",
      "[462/00027] train_loss: 0.006101\n",
      "[462/00077] train_loss: 0.006129\n",
      "[462/00127] train_loss: 0.006033\n",
      "[462/00177] train_loss: 0.006079\n",
      "[462/00227] train_loss: 0.006141\n",
      "[462/00277] train_loss: 0.006042\n",
      "[462/00327] train_loss: 0.006186\n",
      "[462/00377] train_loss: 0.006089\n",
      "[463/00021] train_loss: 0.005963\n",
      "[463/00071] train_loss: 0.006046\n",
      "[463/00121] train_loss: 0.005997\n",
      "[463/00171] train_loss: 0.006146\n",
      "[463/00221] train_loss: 0.006186\n",
      "[463/00271] train_loss: 0.006055\n",
      "[463/00321] train_loss: 0.006136\n",
      "[463/00371] train_loss: 0.006204\n",
      "[464/00015] train_loss: 0.006117\n",
      "[464/00065] train_loss: 0.006036\n",
      "[464/00115] train_loss: 0.006129\n",
      "[464/00165] train_loss: 0.006072\n",
      "[464/00215] train_loss: 0.006101\n",
      "[464/00265] train_loss: 0.006092\n",
      "[464/00315] train_loss: 0.006163\n",
      "[464/00365] train_loss: 0.006060\n",
      "[465/00009] train_loss: 0.006040\n",
      "[465/00059] train_loss: 0.006037\n",
      "[465/00109] train_loss: 0.006075\n",
      "[465/00159] train_loss: 0.006131\n",
      "[465/00209] train_loss: 0.006185\n",
      "[465/00259] train_loss: 0.006136\n",
      "[465/00309] train_loss: 0.006014\n",
      "[465/00359] train_loss: 0.006118\n",
      "[466/00003] train_loss: 0.006085\n",
      "[466/00053] train_loss: 0.006170\n",
      "[466/00103] train_loss: 0.006126\n",
      "[466/00153] train_loss: 0.006106\n",
      "[466/00203] train_loss: 0.006142\n",
      "[466/00253] train_loss: 0.006146\n",
      "[466/00303] train_loss: 0.006115\n",
      "[466/00353] train_loss: 0.006064\n",
      "[466/00403] train_loss: 0.005994\n",
      "[467/00047] train_loss: 0.006057\n",
      "[467/00097] train_loss: 0.006051\n",
      "[467/00147] train_loss: 0.006156\n",
      "[467/00197] train_loss: 0.006103\n",
      "[467/00247] train_loss: 0.006079\n",
      "[467/00297] train_loss: 0.006187\n",
      "[467/00347] train_loss: 0.006089\n",
      "[467/00397] train_loss: 0.006104\n",
      "[468/00041] train_loss: 0.006087\n",
      "[468/00091] train_loss: 0.006076\n",
      "[468/00141] train_loss: 0.006027\n",
      "[468/00191] train_loss: 0.006091\n",
      "[468/00241] train_loss: 0.006155\n",
      "[468/00291] train_loss: 0.006079\n",
      "[468/00341] train_loss: 0.006123\n",
      "[468/00391] train_loss: 0.006107\n",
      "[469/00035] train_loss: 0.006092\n",
      "[469/00085] train_loss: 0.006227\n",
      "[469/00135] train_loss: 0.006095\n",
      "[469/00185] train_loss: 0.006088\n",
      "[469/00235] train_loss: 0.006026\n",
      "[469/00285] train_loss: 0.006058\n",
      "[469/00335] train_loss: 0.006061\n",
      "[469/00385] train_loss: 0.006114\n",
      "[470/00029] train_loss: 0.006068\n",
      "[470/00079] train_loss: 0.006079\n",
      "[470/00129] train_loss: 0.006176\n",
      "[470/00179] train_loss: 0.006128\n",
      "[470/00229] train_loss: 0.006009\n",
      "[470/00279] train_loss: 0.006055\n",
      "[470/00329] train_loss: 0.006163\n",
      "[470/00379] train_loss: 0.006063\n",
      "[471/00023] train_loss: 0.006078\n",
      "[471/00073] train_loss: 0.006119\n",
      "[471/00123] train_loss: 0.006091\n",
      "[471/00173] train_loss: 0.006127\n",
      "[471/00223] train_loss: 0.006164\n",
      "[471/00273] train_loss: 0.006023\n",
      "[471/00323] train_loss: 0.006025\n",
      "[471/00373] train_loss: 0.006208\n",
      "[472/00017] train_loss: 0.006184\n",
      "[472/00067] train_loss: 0.006068\n",
      "[472/00117] train_loss: 0.006113\n",
      "[472/00167] train_loss: 0.006001\n",
      "[472/00217] train_loss: 0.006051\n",
      "[472/00267] train_loss: 0.006087\n",
      "[472/00317] train_loss: 0.006139\n",
      "[472/00367] train_loss: 0.006112\n",
      "[473/00011] train_loss: 0.006059\n",
      "[473/00061] train_loss: 0.006005\n",
      "[473/00111] train_loss: 0.006109\n",
      "[473/00161] train_loss: 0.006102\n",
      "[473/00211] train_loss: 0.006090\n",
      "[473/00261] train_loss: 0.006107\n",
      "[473/00311] train_loss: 0.006131\n",
      "[473/00361] train_loss: 0.006116\n",
      "[474/00005] train_loss: 0.006124\n",
      "[474/00055] train_loss: 0.006069\n",
      "[474/00105] train_loss: 0.006095\n",
      "[474/00155] train_loss: 0.006117\n",
      "[474/00205] train_loss: 0.006142\n",
      "[474/00255] train_loss: 0.006202\n",
      "[474/00305] train_loss: 0.006056\n",
      "[474/00355] train_loss: 0.006104\n",
      "[474/00405] train_loss: 0.006103\n",
      "[475/00049] train_loss: 0.006033\n",
      "[475/00099] train_loss: 0.006091\n",
      "[475/00149] train_loss: 0.006037\n",
      "[475/00199] train_loss: 0.006144\n",
      "[475/00249] train_loss: 0.006128\n",
      "[475/00299] train_loss: 0.006102\n",
      "[475/00349] train_loss: 0.006077\n",
      "[475/00399] train_loss: 0.006091\n",
      "[476/00043] train_loss: 0.006124\n",
      "[476/00093] train_loss: 0.006100\n",
      "[476/00143] train_loss: 0.006084\n",
      "[476/00193] train_loss: 0.006114\n",
      "[476/00243] train_loss: 0.006156\n",
      "[476/00293] train_loss: 0.006131\n",
      "[476/00343] train_loss: 0.006096\n",
      "[476/00393] train_loss: 0.006084\n",
      "[477/00037] train_loss: 0.006081\n",
      "[477/00087] train_loss: 0.006158\n",
      "[477/00137] train_loss: 0.006034\n",
      "[477/00187] train_loss: 0.006042\n",
      "[477/00237] train_loss: 0.006109\n",
      "[477/00287] train_loss: 0.006107\n",
      "[477/00337] train_loss: 0.006126\n",
      "[477/00387] train_loss: 0.006129\n",
      "[478/00031] train_loss: 0.006076\n",
      "[478/00081] train_loss: 0.006065\n",
      "[478/00131] train_loss: 0.006049\n",
      "[478/00181] train_loss: 0.006099\n",
      "[478/00231] train_loss: 0.006122\n",
      "[478/00281] train_loss: 0.006052\n",
      "[478/00331] train_loss: 0.006146\n",
      "[478/00381] train_loss: 0.006076\n",
      "[479/00025] train_loss: 0.006089\n",
      "[479/00075] train_loss: 0.006138\n",
      "[479/00125] train_loss: 0.006075\n",
      "[479/00175] train_loss: 0.006091\n",
      "[479/00225] train_loss: 0.006095\n",
      "[479/00275] train_loss: 0.006152\n",
      "[479/00325] train_loss: 0.006096\n",
      "[479/00375] train_loss: 0.006059\n",
      "[480/00019] train_loss: 0.006122\n",
      "[480/00069] train_loss: 0.006157\n",
      "[480/00119] train_loss: 0.006032\n",
      "[480/00169] train_loss: 0.006024\n",
      "[480/00219] train_loss: 0.006097\n",
      "[480/00269] train_loss: 0.006179\n",
      "[480/00319] train_loss: 0.005995\n",
      "[480/00369] train_loss: 0.006071\n",
      "[481/00013] train_loss: 0.006141\n",
      "[481/00063] train_loss: 0.006141\n",
      "[481/00113] train_loss: 0.006084\n",
      "[481/00163] train_loss: 0.006082\n",
      "[481/00213] train_loss: 0.006077\n",
      "[481/00263] train_loss: 0.006099\n",
      "[481/00313] train_loss: 0.006147\n",
      "[481/00363] train_loss: 0.006089\n",
      "[482/00007] train_loss: 0.006136\n",
      "[482/00057] train_loss: 0.006188\n",
      "[482/00107] train_loss: 0.006171\n",
      "[482/00157] train_loss: 0.006124\n",
      "[482/00207] train_loss: 0.006141\n",
      "[482/00257] train_loss: 0.006115\n",
      "[482/00307] train_loss: 0.006015\n",
      "[482/00357] train_loss: 0.006107\n",
      "[483/00001] train_loss: 0.006107\n",
      "[483/00051] train_loss: 0.006071\n",
      "[483/00101] train_loss: 0.006073\n",
      "[483/00151] train_loss: 0.006133\n",
      "[483/00201] train_loss: 0.006023\n",
      "[483/00251] train_loss: 0.006040\n",
      "[483/00301] train_loss: 0.006125\n",
      "[483/00351] train_loss: 0.006134\n",
      "[483/00401] train_loss: 0.006037\n",
      "[484/00045] train_loss: 0.006070\n",
      "[484/00095] train_loss: 0.006076\n",
      "[484/00145] train_loss: 0.006141\n",
      "[484/00195] train_loss: 0.006166\n",
      "[484/00245] train_loss: 0.006129\n",
      "[484/00295] train_loss: 0.006098\n",
      "[484/00345] train_loss: 0.006070\n",
      "[484/00395] train_loss: 0.006031\n",
      "[485/00039] train_loss: 0.006071\n",
      "[485/00089] train_loss: 0.006058\n",
      "[485/00139] train_loss: 0.006081\n",
      "[485/00189] train_loss: 0.006107\n",
      "[485/00239] train_loss: 0.006114\n",
      "[485/00289] train_loss: 0.006093\n",
      "[485/00339] train_loss: 0.006022\n",
      "[485/00389] train_loss: 0.006082\n",
      "[486/00033] train_loss: 0.006074\n",
      "[486/00083] train_loss: 0.006135\n",
      "[486/00133] train_loss: 0.006066\n",
      "[486/00183] train_loss: 0.006147\n",
      "[486/00233] train_loss: 0.006037\n",
      "[486/00283] train_loss: 0.006050\n",
      "[486/00333] train_loss: 0.006083\n",
      "[486/00383] train_loss: 0.006129\n",
      "[487/00027] train_loss: 0.006036\n",
      "[487/00077] train_loss: 0.006089\n",
      "[487/00127] train_loss: 0.006036\n",
      "[487/00177] train_loss: 0.006057\n",
      "[487/00227] train_loss: 0.006143\n",
      "[487/00277] train_loss: 0.006190\n",
      "[487/00327] train_loss: 0.006089\n",
      "[487/00377] train_loss: 0.006066\n",
      "[488/00021] train_loss: 0.006163\n",
      "[488/00071] train_loss: 0.006178\n",
      "[488/00121] train_loss: 0.006146\n",
      "[488/00171] train_loss: 0.006076\n",
      "[488/00221] train_loss: 0.006111\n",
      "[488/00271] train_loss: 0.006087\n",
      "[488/00321] train_loss: 0.006080\n",
      "[488/00371] train_loss: 0.006105\n",
      "[489/00015] train_loss: 0.006070\n",
      "[489/00065] train_loss: 0.005964\n",
      "[489/00115] train_loss: 0.006154\n",
      "[489/00165] train_loss: 0.006133\n",
      "[489/00215] train_loss: 0.006132\n",
      "[489/00265] train_loss: 0.006177\n",
      "[489/00315] train_loss: 0.006083\n",
      "[489/00365] train_loss: 0.006069\n",
      "[490/00009] train_loss: 0.006084\n",
      "[490/00059] train_loss: 0.006156\n",
      "[490/00109] train_loss: 0.006108\n",
      "[490/00159] train_loss: 0.006063\n",
      "[490/00209] train_loss: 0.006010\n",
      "[490/00259] train_loss: 0.006143\n",
      "[490/00309] train_loss: 0.006084\n",
      "[490/00359] train_loss: 0.006084\n",
      "[491/00003] train_loss: 0.006101\n",
      "[491/00053] train_loss: 0.006030\n",
      "[491/00103] train_loss: 0.006118\n",
      "[491/00153] train_loss: 0.006104\n",
      "[491/00203] train_loss: 0.006040\n",
      "[491/00253] train_loss: 0.006093\n",
      "[491/00303] train_loss: 0.006146\n",
      "[491/00353] train_loss: 0.006124\n",
      "[491/00403] train_loss: 0.006050\n",
      "[492/00047] train_loss: 0.006159\n",
      "[492/00097] train_loss: 0.006141\n",
      "[492/00147] train_loss: 0.006018\n",
      "[492/00197] train_loss: 0.006108\n",
      "[492/00247] train_loss: 0.006092\n",
      "[492/00297] train_loss: 0.006001\n",
      "[492/00347] train_loss: 0.006078\n",
      "[492/00397] train_loss: 0.006018\n",
      "[493/00041] train_loss: 0.006077\n",
      "[493/00091] train_loss: 0.006114\n",
      "[493/00141] train_loss: 0.006130\n",
      "[493/00191] train_loss: 0.006130\n",
      "[493/00241] train_loss: 0.006203\n",
      "[493/00291] train_loss: 0.006082\n",
      "[493/00341] train_loss: 0.006075\n",
      "[493/00391] train_loss: 0.006031\n",
      "[494/00035] train_loss: 0.006130\n",
      "[494/00085] train_loss: 0.006107\n",
      "[494/00135] train_loss: 0.006071\n",
      "[494/00185] train_loss: 0.006074\n",
      "[494/00235] train_loss: 0.006170\n",
      "[494/00285] train_loss: 0.006079\n",
      "[494/00335] train_loss: 0.006131\n",
      "[494/00385] train_loss: 0.006182\n",
      "[495/00029] train_loss: 0.006167\n",
      "[495/00079] train_loss: 0.006085\n",
      "[495/00129] train_loss: 0.006139\n",
      "[495/00179] train_loss: 0.006131\n",
      "[495/00229] train_loss: 0.006034\n",
      "[495/00279] train_loss: 0.006125\n",
      "[495/00329] train_loss: 0.006030\n",
      "[495/00379] train_loss: 0.006027\n",
      "[496/00023] train_loss: 0.006115\n",
      "[496/00073] train_loss: 0.006113\n",
      "[496/00123] train_loss: 0.006014\n",
      "[496/00173] train_loss: 0.006141\n",
      "[496/00223] train_loss: 0.006078\n",
      "[496/00273] train_loss: 0.006111\n",
      "[496/00323] train_loss: 0.006150\n",
      "[496/00373] train_loss: 0.006128\n",
      "[497/00017] train_loss: 0.006065\n",
      "[497/00067] train_loss: 0.006180\n",
      "[497/00117] train_loss: 0.006100\n",
      "[497/00167] train_loss: 0.006049\n",
      "[497/00217] train_loss: 0.006120\n",
      "[497/00267] train_loss: 0.006088\n",
      "[497/00317] train_loss: 0.006163\n",
      "[497/00367] train_loss: 0.006114\n",
      "[498/00011] train_loss: 0.006119\n",
      "[498/00061] train_loss: 0.006134\n",
      "[498/00111] train_loss: 0.006089\n",
      "[498/00161] train_loss: 0.006138\n",
      "[498/00211] train_loss: 0.006141\n",
      "[498/00261] train_loss: 0.006078\n",
      "[498/00311] train_loss: 0.006123\n",
      "[498/00361] train_loss: 0.006056\n",
      "[499/00005] train_loss: 0.006112\n",
      "[499/00055] train_loss: 0.006101\n",
      "[499/00105] train_loss: 0.006085\n",
      "[499/00155] train_loss: 0.006071\n",
      "[499/00205] train_loss: 0.006109\n",
      "[499/00255] train_loss: 0.006189\n",
      "[499/00305] train_loss: 0.006058\n",
      "[499/00355] train_loss: 0.006112\n",
      "[499/00405] train_loss: 0.006074\n",
      "[500/00049] train_loss: 0.006049\n",
      "[500/00099] train_loss: 0.006026\n",
      "[500/00149] train_loss: 0.006056\n",
      "[500/00199] train_loss: 0.006105\n",
      "[500/00249] train_loss: 0.006009\n",
      "[500/00299] train_loss: 0.006157\n",
      "[500/00349] train_loss: 0.006081\n",
      "[500/00399] train_loss: 0.006174\n",
      "[501/00043] train_loss: 0.006089\n",
      "[501/00093] train_loss: 0.006093\n",
      "[501/00143] train_loss: 0.006174\n",
      "[501/00193] train_loss: 0.006180\n",
      "[501/00243] train_loss: 0.006057\n",
      "[501/00293] train_loss: 0.006101\n",
      "[501/00343] train_loss: 0.006124\n",
      "[501/00393] train_loss: 0.006083\n",
      "[502/00037] train_loss: 0.006127\n",
      "[502/00087] train_loss: 0.006171\n",
      "[502/00137] train_loss: 0.006120\n",
      "[502/00187] train_loss: 0.006152\n",
      "[502/00237] train_loss: 0.006210\n",
      "[502/00287] train_loss: 0.006073\n",
      "[502/00337] train_loss: 0.006108\n",
      "[502/00387] train_loss: 0.006194\n",
      "[503/00031] train_loss: 0.006153\n",
      "[503/00081] train_loss: 0.006085\n",
      "[503/00131] train_loss: 0.006104\n",
      "[503/00181] train_loss: 0.006080\n",
      "[503/00231] train_loss: 0.006043\n",
      "[503/00281] train_loss: 0.006145\n",
      "[503/00331] train_loss: 0.006206\n",
      "[503/00381] train_loss: 0.006142\n",
      "[504/00025] train_loss: 0.006150\n",
      "[504/00075] train_loss: 0.006118\n",
      "[504/00125] train_loss: 0.006095\n",
      "[504/00175] train_loss: 0.006026\n",
      "[504/00225] train_loss: 0.006080\n",
      "[504/00275] train_loss: 0.006184\n",
      "[504/00325] train_loss: 0.006033\n",
      "[504/00375] train_loss: 0.006073\n",
      "[505/00019] train_loss: 0.006112\n",
      "[505/00069] train_loss: 0.006160\n",
      "[505/00119] train_loss: 0.006122\n",
      "[505/00169] train_loss: 0.006091\n",
      "[505/00219] train_loss: 0.006154\n",
      "[505/00269] train_loss: 0.006107\n",
      "[505/00319] train_loss: 0.006065\n",
      "[505/00369] train_loss: 0.006083\n",
      "[506/00013] train_loss: 0.006085\n",
      "[506/00063] train_loss: 0.006108\n",
      "[506/00113] train_loss: 0.006108\n",
      "[506/00163] train_loss: 0.006149\n",
      "[506/00213] train_loss: 0.006048\n",
      "[506/00263] train_loss: 0.006050\n",
      "[506/00313] train_loss: 0.006102\n",
      "[506/00363] train_loss: 0.006134\n",
      "[507/00007] train_loss: 0.006106\n",
      "[507/00057] train_loss: 0.006098\n",
      "[507/00107] train_loss: 0.006037\n",
      "[507/00157] train_loss: 0.006064\n",
      "[507/00207] train_loss: 0.006073\n",
      "[507/00257] train_loss: 0.006096\n",
      "[507/00307] train_loss: 0.006129\n",
      "[507/00357] train_loss: 0.006070\n",
      "[508/00001] train_loss: 0.006130\n",
      "[508/00051] train_loss: 0.006156\n",
      "[508/00101] train_loss: 0.006065\n",
      "[508/00151] train_loss: 0.006126\n",
      "[508/00201] train_loss: 0.006106\n",
      "[508/00251] train_loss: 0.006246\n",
      "[508/00301] train_loss: 0.006011\n",
      "[508/00351] train_loss: 0.006159\n",
      "[508/00401] train_loss: 0.006097\n",
      "[509/00045] train_loss: 0.006080\n",
      "[509/00095] train_loss: 0.006056\n",
      "[509/00145] train_loss: 0.006091\n",
      "[509/00195] train_loss: 0.006069\n",
      "[509/00245] train_loss: 0.006208\n",
      "[509/00295] train_loss: 0.006142\n",
      "[509/00345] train_loss: 0.006106\n",
      "[509/00395] train_loss: 0.006062\n",
      "[510/00039] train_loss: 0.006033\n",
      "[510/00089] train_loss: 0.006101\n",
      "[510/00139] train_loss: 0.006104\n",
      "[510/00189] train_loss: 0.006088\n",
      "[510/00239] train_loss: 0.006020\n",
      "[510/00289] train_loss: 0.006149\n",
      "[510/00339] train_loss: 0.006122\n",
      "[510/00389] train_loss: 0.006040\n",
      "[511/00033] train_loss: 0.006050\n",
      "[511/00083] train_loss: 0.006096\n",
      "[511/00133] train_loss: 0.005975\n",
      "[511/00183] train_loss: 0.006177\n",
      "[511/00233] train_loss: 0.006134\n",
      "[511/00283] train_loss: 0.006004\n",
      "[511/00333] train_loss: 0.006059\n",
      "[511/00383] train_loss: 0.006009\n",
      "[512/00027] train_loss: 0.006143\n",
      "[512/00077] train_loss: 0.006155\n",
      "[512/00127] train_loss: 0.006024\n",
      "[512/00177] train_loss: 0.006101\n",
      "[512/00227] train_loss: 0.006190\n",
      "[512/00277] train_loss: 0.006083\n",
      "[512/00327] train_loss: 0.006023\n",
      "[512/00377] train_loss: 0.006124\n",
      "[513/00021] train_loss: 0.006170\n",
      "[513/00071] train_loss: 0.006101\n",
      "[513/00121] train_loss: 0.006119\n",
      "[513/00171] train_loss: 0.006139\n",
      "[513/00221] train_loss: 0.006057\n",
      "[513/00271] train_loss: 0.006101\n",
      "[513/00321] train_loss: 0.006155\n",
      "[513/00371] train_loss: 0.006134\n",
      "[514/00015] train_loss: 0.006118\n",
      "[514/00065] train_loss: 0.006112\n",
      "[514/00115] train_loss: 0.006095\n",
      "[514/00165] train_loss: 0.006068\n",
      "[514/00215] train_loss: 0.006056\n",
      "[514/00265] train_loss: 0.006015\n",
      "[514/00315] train_loss: 0.006086\n",
      "[514/00365] train_loss: 0.006075\n",
      "[515/00009] train_loss: 0.006122\n",
      "[515/00059] train_loss: 0.006047\n",
      "[515/00109] train_loss: 0.006124\n",
      "[515/00159] train_loss: 0.006058\n",
      "[515/00209] train_loss: 0.006157\n",
      "[515/00259] train_loss: 0.006047\n",
      "[515/00309] train_loss: 0.006109\n",
      "[515/00359] train_loss: 0.006117\n",
      "[516/00003] train_loss: 0.006055\n",
      "[516/00053] train_loss: 0.006107\n",
      "[516/00103] train_loss: 0.006118\n",
      "[516/00153] train_loss: 0.006012\n",
      "[516/00203] train_loss: 0.006113\n",
      "[516/00253] train_loss: 0.006097\n",
      "[516/00303] train_loss: 0.006060\n",
      "[516/00353] train_loss: 0.006148\n",
      "[516/00403] train_loss: 0.006088\n",
      "[517/00047] train_loss: 0.006005\n",
      "[517/00097] train_loss: 0.006121\n",
      "[517/00147] train_loss: 0.006014\n",
      "[517/00197] train_loss: 0.005989\n",
      "[517/00247] train_loss: 0.006111\n",
      "[517/00297] train_loss: 0.006070\n",
      "[517/00347] train_loss: 0.006084\n",
      "[517/00397] train_loss: 0.006151\n",
      "[518/00041] train_loss: 0.006044\n",
      "[518/00091] train_loss: 0.006077\n",
      "[518/00141] train_loss: 0.006054\n",
      "[518/00191] train_loss: 0.006132\n",
      "[518/00241] train_loss: 0.006046\n",
      "[518/00291] train_loss: 0.006105\n",
      "[518/00341] train_loss: 0.006067\n",
      "[518/00391] train_loss: 0.006041\n",
      "[519/00035] train_loss: 0.006037\n",
      "[519/00085] train_loss: 0.006093\n",
      "[519/00135] train_loss: 0.006060\n",
      "[519/00185] train_loss: 0.006000\n",
      "[519/00235] train_loss: 0.006085\n",
      "[519/00285] train_loss: 0.006054\n",
      "[519/00335] train_loss: 0.006048\n",
      "[519/00385] train_loss: 0.006045\n",
      "[520/00029] train_loss: 0.006149\n",
      "[520/00079] train_loss: 0.006128\n",
      "[520/00129] train_loss: 0.006074\n",
      "[520/00179] train_loss: 0.006043\n",
      "[520/00229] train_loss: 0.006093\n",
      "[520/00279] train_loss: 0.006112\n",
      "[520/00329] train_loss: 0.006149\n",
      "[520/00379] train_loss: 0.006167\n",
      "[521/00023] train_loss: 0.006187\n",
      "[521/00073] train_loss: 0.006131\n",
      "[521/00123] train_loss: 0.006062\n",
      "[521/00173] train_loss: 0.006020\n",
      "[521/00223] train_loss: 0.006027\n",
      "[521/00273] train_loss: 0.006106\n",
      "[521/00323] train_loss: 0.006040\n",
      "[521/00373] train_loss: 0.006101\n",
      "[522/00017] train_loss: 0.006092\n",
      "[522/00067] train_loss: 0.006092\n",
      "[522/00117] train_loss: 0.006075\n",
      "[522/00167] train_loss: 0.006110\n",
      "[522/00217] train_loss: 0.006099\n",
      "[522/00267] train_loss: 0.006075\n",
      "[522/00317] train_loss: 0.006118\n",
      "[522/00367] train_loss: 0.006136\n",
      "[523/00011] train_loss: 0.006129\n",
      "[523/00061] train_loss: 0.006119\n",
      "[523/00111] train_loss: 0.006154\n",
      "[523/00161] train_loss: 0.006127\n",
      "[523/00211] train_loss: 0.006101\n",
      "[523/00261] train_loss: 0.006061\n",
      "[523/00311] train_loss: 0.006128\n",
      "[523/00361] train_loss: 0.006087\n",
      "[524/00005] train_loss: 0.006068\n",
      "[524/00055] train_loss: 0.006165\n",
      "[524/00105] train_loss: 0.006101\n",
      "[524/00155] train_loss: 0.006005\n",
      "[524/00205] train_loss: 0.006052\n",
      "[524/00255] train_loss: 0.006144\n",
      "[524/00305] train_loss: 0.006165\n",
      "[524/00355] train_loss: 0.006124\n",
      "[524/00405] train_loss: 0.006167\n",
      "[525/00049] train_loss: 0.006157\n",
      "[525/00099] train_loss: 0.006134\n",
      "[525/00149] train_loss: 0.006085\n",
      "[525/00199] train_loss: 0.006059\n",
      "[525/00249] train_loss: 0.006121\n",
      "[525/00299] train_loss: 0.006022\n",
      "[525/00349] train_loss: 0.006150\n",
      "[525/00399] train_loss: 0.006069\n",
      "[526/00043] train_loss: 0.006087\n",
      "[526/00093] train_loss: 0.006017\n",
      "[526/00143] train_loss: 0.006076\n",
      "[526/00193] train_loss: 0.006021\n",
      "[526/00243] train_loss: 0.006048\n",
      "[526/00293] train_loss: 0.006171\n",
      "[526/00343] train_loss: 0.006067\n",
      "[526/00393] train_loss: 0.006061\n",
      "[527/00037] train_loss: 0.006127\n",
      "[527/00087] train_loss: 0.006120\n",
      "[527/00137] train_loss: 0.006057\n",
      "[527/00187] train_loss: 0.006046\n",
      "[527/00237] train_loss: 0.006083\n",
      "[527/00287] train_loss: 0.006123\n",
      "[527/00337] train_loss: 0.006064\n",
      "[527/00387] train_loss: 0.006096\n",
      "[528/00031] train_loss: 0.006095\n",
      "[528/00081] train_loss: 0.006105\n",
      "[528/00131] train_loss: 0.006111\n",
      "[528/00181] train_loss: 0.006135\n",
      "[528/00231] train_loss: 0.006085\n",
      "[528/00281] train_loss: 0.006113\n",
      "[528/00331] train_loss: 0.006163\n",
      "[528/00381] train_loss: 0.006046\n",
      "[529/00025] train_loss: 0.006001\n",
      "[529/00075] train_loss: 0.006130\n",
      "[529/00125] train_loss: 0.006166\n",
      "[529/00175] train_loss: 0.006108\n",
      "[529/00225] train_loss: 0.006147\n",
      "[529/00275] train_loss: 0.006162\n",
      "[529/00325] train_loss: 0.006074\n",
      "[529/00375] train_loss: 0.006016\n",
      "[530/00019] train_loss: 0.006036\n",
      "[530/00069] train_loss: 0.006108\n",
      "[530/00119] train_loss: 0.006110\n",
      "[530/00169] train_loss: 0.006135\n",
      "[530/00219] train_loss: 0.006097\n",
      "[530/00269] train_loss: 0.006212\n",
      "[530/00319] train_loss: 0.006188\n",
      "[530/00369] train_loss: 0.006073\n",
      "[531/00013] train_loss: 0.006186\n",
      "[531/00063] train_loss: 0.006134\n",
      "[531/00113] train_loss: 0.006067\n",
      "[531/00163] train_loss: 0.006083\n",
      "[531/00213] train_loss: 0.006094\n",
      "[531/00263] train_loss: 0.006064\n",
      "[531/00313] train_loss: 0.006034\n",
      "[531/00363] train_loss: 0.006165\n",
      "[532/00007] train_loss: 0.006080\n",
      "[532/00057] train_loss: 0.006042\n",
      "[532/00107] train_loss: 0.006124\n",
      "[532/00157] train_loss: 0.006094\n",
      "[532/00207] train_loss: 0.006061\n",
      "[532/00257] train_loss: 0.006177\n",
      "[532/00307] train_loss: 0.006087\n",
      "[532/00357] train_loss: 0.006104\n",
      "[533/00001] train_loss: 0.006080\n",
      "[533/00051] train_loss: 0.006027\n",
      "[533/00101] train_loss: 0.006022\n",
      "[533/00151] train_loss: 0.006054\n",
      "[533/00201] train_loss: 0.006098\n",
      "[533/00251] train_loss: 0.006063\n",
      "[533/00301] train_loss: 0.006071\n",
      "[533/00351] train_loss: 0.006133\n",
      "[533/00401] train_loss: 0.006052\n",
      "[534/00045] train_loss: 0.006111\n",
      "[534/00095] train_loss: 0.006113\n",
      "[534/00145] train_loss: 0.006141\n",
      "[534/00195] train_loss: 0.006190\n",
      "[534/00245] train_loss: 0.006073\n",
      "[534/00295] train_loss: 0.006066\n",
      "[534/00345] train_loss: 0.006153\n",
      "[534/00395] train_loss: 0.006109\n",
      "[535/00039] train_loss: 0.006120\n",
      "[535/00089] train_loss: 0.006102\n",
      "[535/00139] train_loss: 0.006172\n",
      "[535/00189] train_loss: 0.006204\n",
      "[535/00239] train_loss: 0.006196\n",
      "[535/00289] train_loss: 0.006066\n",
      "[535/00339] train_loss: 0.006078\n",
      "[535/00389] train_loss: 0.006117\n",
      "[536/00033] train_loss: 0.005966\n",
      "[536/00083] train_loss: 0.006192\n",
      "[536/00133] train_loss: 0.006109\n",
      "[536/00183] train_loss: 0.006172\n",
      "[536/00233] train_loss: 0.006038\n",
      "[536/00283] train_loss: 0.006035\n",
      "[536/00333] train_loss: 0.006057\n",
      "[536/00383] train_loss: 0.006076\n",
      "[537/00027] train_loss: 0.006088\n",
      "[537/00077] train_loss: 0.006147\n",
      "[537/00127] train_loss: 0.006035\n",
      "[537/00177] train_loss: 0.006073\n",
      "[537/00227] train_loss: 0.006087\n",
      "[537/00277] train_loss: 0.006083\n",
      "[537/00327] train_loss: 0.006097\n",
      "[537/00377] train_loss: 0.006132\n",
      "[538/00021] train_loss: 0.006048\n",
      "[538/00071] train_loss: 0.006054\n",
      "[538/00121] train_loss: 0.006081\n",
      "[538/00171] train_loss: 0.006196\n",
      "[538/00221] train_loss: 0.006152\n",
      "[538/00271] train_loss: 0.006041\n",
      "[538/00321] train_loss: 0.006130\n",
      "[538/00371] train_loss: 0.006149\n",
      "[539/00015] train_loss: 0.006114\n",
      "[539/00065] train_loss: 0.006094\n",
      "[539/00115] train_loss: 0.006096\n",
      "[539/00165] train_loss: 0.006073\n",
      "[539/00215] train_loss: 0.006080\n",
      "[539/00265] train_loss: 0.006201\n",
      "[539/00315] train_loss: 0.006123\n",
      "[539/00365] train_loss: 0.006088\n",
      "[540/00009] train_loss: 0.006138\n",
      "[540/00059] train_loss: 0.006119\n",
      "[540/00109] train_loss: 0.006087\n",
      "[540/00159] train_loss: 0.006075\n",
      "[540/00209] train_loss: 0.006084\n",
      "[540/00259] train_loss: 0.006073\n",
      "[540/00309] train_loss: 0.006165\n",
      "[540/00359] train_loss: 0.006133\n",
      "[541/00003] train_loss: 0.006116\n",
      "[541/00053] train_loss: 0.006097\n",
      "[541/00103] train_loss: 0.006095\n",
      "[541/00153] train_loss: 0.006132\n",
      "[541/00203] train_loss: 0.006155\n",
      "[541/00253] train_loss: 0.006081\n",
      "[541/00303] train_loss: 0.006098\n",
      "[541/00353] train_loss: 0.006180\n",
      "[541/00403] train_loss: 0.006077\n",
      "[542/00047] train_loss: 0.005974\n",
      "[542/00097] train_loss: 0.006101\n",
      "[542/00147] train_loss: 0.006040\n",
      "[542/00197] train_loss: 0.006122\n",
      "[542/00247] train_loss: 0.006074\n",
      "[542/00297] train_loss: 0.006100\n",
      "[542/00347] train_loss: 0.006096\n",
      "[542/00397] train_loss: 0.006091\n",
      "[543/00041] train_loss: 0.006125\n",
      "[543/00091] train_loss: 0.006138\n",
      "[543/00141] train_loss: 0.006110\n",
      "[543/00191] train_loss: 0.006037\n",
      "[543/00241] train_loss: 0.006064\n",
      "[543/00291] train_loss: 0.006117\n",
      "[543/00341] train_loss: 0.006163\n",
      "[543/00391] train_loss: 0.006016\n",
      "[544/00035] train_loss: 0.006140\n",
      "[544/00085] train_loss: 0.006109\n",
      "[544/00135] train_loss: 0.006087\n",
      "[544/00185] train_loss: 0.006150\n",
      "[544/00235] train_loss: 0.006181\n",
      "[544/00285] train_loss: 0.006111\n",
      "[544/00335] train_loss: 0.006100\n",
      "[544/00385] train_loss: 0.006152\n",
      "[545/00029] train_loss: 0.006067\n",
      "[545/00079] train_loss: 0.006086\n",
      "[545/00129] train_loss: 0.006005\n",
      "[545/00179] train_loss: 0.006081\n",
      "[545/00229] train_loss: 0.006151\n",
      "[545/00279] train_loss: 0.006084\n",
      "[545/00329] train_loss: 0.006031\n",
      "[545/00379] train_loss: 0.006116\n",
      "[546/00023] train_loss: 0.006125\n",
      "[546/00073] train_loss: 0.006096\n",
      "[546/00123] train_loss: 0.006011\n",
      "[546/00173] train_loss: 0.006089\n",
      "[546/00223] train_loss: 0.006064\n",
      "[546/00273] train_loss: 0.006103\n",
      "[546/00323] train_loss: 0.006070\n",
      "[546/00373] train_loss: 0.006081\n",
      "[547/00017] train_loss: 0.006109\n",
      "[547/00067] train_loss: 0.006138\n",
      "[547/00117] train_loss: 0.006042\n",
      "[547/00167] train_loss: 0.006141\n",
      "[547/00217] train_loss: 0.006140\n",
      "[547/00267] train_loss: 0.006045\n",
      "[547/00317] train_loss: 0.005984\n",
      "[547/00367] train_loss: 0.006015\n",
      "[548/00011] train_loss: 0.006059\n",
      "[548/00061] train_loss: 0.006093\n",
      "[548/00111] train_loss: 0.006095\n",
      "[548/00161] train_loss: 0.006113\n",
      "[548/00211] train_loss: 0.006094\n",
      "[548/00261] train_loss: 0.006127\n",
      "[548/00311] train_loss: 0.006107\n",
      "[548/00361] train_loss: 0.006137\n",
      "[549/00005] train_loss: 0.006219\n",
      "[549/00055] train_loss: 0.006091\n",
      "[549/00105] train_loss: 0.006116\n",
      "[549/00155] train_loss: 0.006090\n",
      "[549/00205] train_loss: 0.006092\n",
      "[549/00255] train_loss: 0.006100\n",
      "[549/00305] train_loss: 0.006133\n",
      "[549/00355] train_loss: 0.006040\n",
      "[549/00405] train_loss: 0.006030\n",
      "[550/00049] train_loss: 0.006053\n",
      "[550/00099] train_loss: 0.005991\n",
      "[550/00149] train_loss: 0.006078\n",
      "[550/00199] train_loss: 0.006162\n",
      "[550/00249] train_loss: 0.006124\n",
      "[550/00299] train_loss: 0.006177\n",
      "[550/00349] train_loss: 0.006031\n",
      "[550/00399] train_loss: 0.006078\n",
      "[551/00043] train_loss: 0.006040\n",
      "[551/00093] train_loss: 0.006104\n",
      "[551/00143] train_loss: 0.006025\n",
      "[551/00193] train_loss: 0.006075\n",
      "[551/00243] train_loss: 0.006073\n",
      "[551/00293] train_loss: 0.006081\n",
      "[551/00343] train_loss: 0.006161\n",
      "[551/00393] train_loss: 0.006075\n",
      "[552/00037] train_loss: 0.006165\n",
      "[552/00087] train_loss: 0.006062\n",
      "[552/00137] train_loss: 0.006048\n",
      "[552/00187] train_loss: 0.006071\n",
      "[552/00237] train_loss: 0.006046\n",
      "[552/00287] train_loss: 0.006096\n",
      "[552/00337] train_loss: 0.006160\n",
      "[552/00387] train_loss: 0.006152\n",
      "[553/00031] train_loss: 0.006166\n",
      "[553/00081] train_loss: 0.006090\n",
      "[553/00131] train_loss: 0.006089\n",
      "[553/00181] train_loss: 0.006024\n",
      "[553/00231] train_loss: 0.006190\n",
      "[553/00281] train_loss: 0.006129\n",
      "[553/00331] train_loss: 0.006123\n",
      "[553/00381] train_loss: 0.006114\n",
      "[554/00025] train_loss: 0.006133\n",
      "[554/00075] train_loss: 0.006094\n",
      "[554/00125] train_loss: 0.006159\n",
      "[554/00175] train_loss: 0.006206\n",
      "[554/00225] train_loss: 0.006037\n",
      "[554/00275] train_loss: 0.006086\n",
      "[554/00325] train_loss: 0.006137\n",
      "[554/00375] train_loss: 0.006082\n",
      "[555/00019] train_loss: 0.006144\n",
      "[555/00069] train_loss: 0.006093\n",
      "[555/00119] train_loss: 0.006058\n",
      "[555/00169] train_loss: 0.006066\n",
      "[555/00219] train_loss: 0.006143\n",
      "[555/00269] train_loss: 0.006061\n",
      "[555/00319] train_loss: 0.005998\n",
      "[555/00369] train_loss: 0.006039\n",
      "[556/00013] train_loss: 0.006097\n",
      "[556/00063] train_loss: 0.006001\n",
      "[556/00113] train_loss: 0.006107\n",
      "[556/00163] train_loss: 0.006178\n",
      "[556/00213] train_loss: 0.006106\n",
      "[556/00263] train_loss: 0.006124\n",
      "[556/00313] train_loss: 0.006099\n",
      "[556/00363] train_loss: 0.006173\n",
      "[557/00007] train_loss: 0.006087\n",
      "[557/00057] train_loss: 0.006018\n",
      "[557/00107] train_loss: 0.006081\n",
      "[557/00157] train_loss: 0.006113\n",
      "[557/00207] train_loss: 0.006061\n",
      "[557/00257] train_loss: 0.006066\n",
      "[557/00307] train_loss: 0.006150\n",
      "[557/00357] train_loss: 0.006137\n",
      "[558/00001] train_loss: 0.006031\n",
      "[558/00051] train_loss: 0.006202\n",
      "[558/00101] train_loss: 0.006145\n",
      "[558/00151] train_loss: 0.006043\n",
      "[558/00201] train_loss: 0.006091\n",
      "[558/00251] train_loss: 0.006087\n",
      "[558/00301] train_loss: 0.006131\n",
      "[558/00351] train_loss: 0.006011\n",
      "[558/00401] train_loss: 0.006047\n",
      "[559/00045] train_loss: 0.006056\n",
      "[559/00095] train_loss: 0.006079\n",
      "[559/00145] train_loss: 0.006110\n",
      "[559/00195] train_loss: 0.006055\n",
      "[559/00245] train_loss: 0.006105\n",
      "[559/00295] train_loss: 0.006049\n",
      "[559/00345] train_loss: 0.006108\n",
      "[559/00395] train_loss: 0.006054\n",
      "[560/00039] train_loss: 0.006171\n",
      "[560/00089] train_loss: 0.006075\n",
      "[560/00139] train_loss: 0.006151\n",
      "[560/00189] train_loss: 0.006049\n",
      "[560/00239] train_loss: 0.006100\n",
      "[560/00289] train_loss: 0.006076\n",
      "[560/00339] train_loss: 0.006094\n",
      "[560/00389] train_loss: 0.006135\n",
      "[561/00033] train_loss: 0.006060\n",
      "[561/00083] train_loss: 0.006152\n",
      "[561/00133] train_loss: 0.006163\n",
      "[561/00183] train_loss: 0.006058\n",
      "[561/00233] train_loss: 0.006018\n",
      "[561/00283] train_loss: 0.006117\n",
      "[561/00333] train_loss: 0.006103\n",
      "[561/00383] train_loss: 0.006092\n",
      "[562/00027] train_loss: 0.006068\n",
      "[562/00077] train_loss: 0.006088\n",
      "[562/00127] train_loss: 0.006027\n",
      "[562/00177] train_loss: 0.006100\n",
      "[562/00227] train_loss: 0.006049\n",
      "[562/00277] train_loss: 0.006106\n",
      "[562/00327] train_loss: 0.006065\n",
      "[562/00377] train_loss: 0.006188\n",
      "[563/00021] train_loss: 0.006061\n",
      "[563/00071] train_loss: 0.006156\n",
      "[563/00121] train_loss: 0.005995\n",
      "[563/00171] train_loss: 0.006096\n",
      "[563/00221] train_loss: 0.006046\n",
      "[563/00271] train_loss: 0.006099\n",
      "[563/00321] train_loss: 0.006055\n",
      "[563/00371] train_loss: 0.006068\n",
      "[564/00015] train_loss: 0.006111\n",
      "[564/00065] train_loss: 0.006068\n",
      "[564/00115] train_loss: 0.006087\n",
      "[564/00165] train_loss: 0.006170\n",
      "[564/00215] train_loss: 0.006143\n",
      "[564/00265] train_loss: 0.006132\n",
      "[564/00315] train_loss: 0.006089\n",
      "[564/00365] train_loss: 0.006016\n",
      "[565/00009] train_loss: 0.006121\n",
      "[565/00059] train_loss: 0.006139\n",
      "[565/00109] train_loss: 0.006042\n",
      "[565/00159] train_loss: 0.006056\n",
      "[565/00209] train_loss: 0.006167\n",
      "[565/00259] train_loss: 0.006124\n",
      "[565/00309] train_loss: 0.006110\n",
      "[565/00359] train_loss: 0.006073\n",
      "[566/00003] train_loss: 0.006056\n",
      "[566/00053] train_loss: 0.006084\n",
      "[566/00103] train_loss: 0.006067\n",
      "[566/00153] train_loss: 0.006124\n",
      "[566/00203] train_loss: 0.006089\n",
      "[566/00253] train_loss: 0.006189\n",
      "[566/00303] train_loss: 0.006067\n",
      "[566/00353] train_loss: 0.006072\n",
      "[566/00403] train_loss: 0.006102\n",
      "[567/00047] train_loss: 0.006120\n",
      "[567/00097] train_loss: 0.006118\n",
      "[567/00147] train_loss: 0.006033\n",
      "[567/00197] train_loss: 0.006118\n",
      "[567/00247] train_loss: 0.006136\n",
      "[567/00297] train_loss: 0.006053\n",
      "[567/00347] train_loss: 0.006027\n",
      "[567/00397] train_loss: 0.006071\n",
      "[568/00041] train_loss: 0.006149\n",
      "[568/00091] train_loss: 0.006083\n",
      "[568/00141] train_loss: 0.006125\n",
      "[568/00191] train_loss: 0.006057\n",
      "[568/00241] train_loss: 0.006073\n",
      "[568/00291] train_loss: 0.006145\n",
      "[568/00341] train_loss: 0.006061\n",
      "[568/00391] train_loss: 0.006135\n",
      "[569/00035] train_loss: 0.006149\n",
      "[569/00085] train_loss: 0.006074\n",
      "[569/00135] train_loss: 0.006102\n",
      "[569/00185] train_loss: 0.006044\n",
      "[569/00235] train_loss: 0.006046\n",
      "[569/00285] train_loss: 0.006134\n",
      "[569/00335] train_loss: 0.006140\n",
      "[569/00385] train_loss: 0.006072\n",
      "[570/00029] train_loss: 0.006039\n",
      "[570/00079] train_loss: 0.006022\n",
      "[570/00129] train_loss: 0.006070\n",
      "[570/00179] train_loss: 0.006078\n",
      "[570/00229] train_loss: 0.006087\n",
      "[570/00279] train_loss: 0.006046\n",
      "[570/00329] train_loss: 0.006042\n",
      "[570/00379] train_loss: 0.006009\n",
      "[571/00023] train_loss: 0.006115\n",
      "[571/00073] train_loss: 0.006067\n",
      "[571/00123] train_loss: 0.006088\n",
      "[571/00173] train_loss: 0.006098\n",
      "[571/00223] train_loss: 0.006137\n",
      "[571/00273] train_loss: 0.006036\n",
      "[571/00323] train_loss: 0.006108\n",
      "[571/00373] train_loss: 0.006058\n",
      "[572/00017] train_loss: 0.006153\n",
      "[572/00067] train_loss: 0.006096\n",
      "[572/00117] train_loss: 0.006073\n",
      "[572/00167] train_loss: 0.006109\n",
      "[572/00217] train_loss: 0.006024\n",
      "[572/00267] train_loss: 0.006149\n",
      "[572/00317] train_loss: 0.006029\n",
      "[572/00367] train_loss: 0.005988\n",
      "[573/00011] train_loss: 0.006056\n",
      "[573/00061] train_loss: 0.006119\n",
      "[573/00111] train_loss: 0.006200\n",
      "[573/00161] train_loss: 0.006092\n",
      "[573/00211] train_loss: 0.006030\n",
      "[573/00261] train_loss: 0.006102\n",
      "[573/00311] train_loss: 0.006141\n",
      "[573/00361] train_loss: 0.006030\n",
      "[574/00005] train_loss: 0.006084\n",
      "[574/00055] train_loss: 0.006015\n",
      "[574/00105] train_loss: 0.006157\n",
      "[574/00155] train_loss: 0.006076\n",
      "[574/00205] train_loss: 0.006115\n",
      "[574/00255] train_loss: 0.006075\n",
      "[574/00305] train_loss: 0.006079\n",
      "[574/00355] train_loss: 0.006074\n",
      "[574/00405] train_loss: 0.006081\n",
      "[575/00049] train_loss: 0.006105\n",
      "[575/00099] train_loss: 0.006177\n",
      "[575/00149] train_loss: 0.006057\n",
      "[575/00199] train_loss: 0.006146\n",
      "[575/00249] train_loss: 0.006039\n",
      "[575/00299] train_loss: 0.006182\n",
      "[575/00349] train_loss: 0.006103\n",
      "[575/00399] train_loss: 0.006084\n",
      "[576/00043] train_loss: 0.006150\n",
      "[576/00093] train_loss: 0.006190\n",
      "[576/00143] train_loss: 0.006051\n",
      "[576/00193] train_loss: 0.006025\n",
      "[576/00243] train_loss: 0.006138\n",
      "[576/00293] train_loss: 0.006095\n",
      "[576/00343] train_loss: 0.005997\n",
      "[576/00393] train_loss: 0.006046\n",
      "[577/00037] train_loss: 0.006133\n",
      "[577/00087] train_loss: 0.006116\n",
      "[577/00137] train_loss: 0.006054\n",
      "[577/00187] train_loss: 0.006049\n",
      "[577/00237] train_loss: 0.006171\n",
      "[577/00287] train_loss: 0.006043\n",
      "[577/00337] train_loss: 0.006033\n",
      "[577/00387] train_loss: 0.006151\n",
      "[578/00031] train_loss: 0.006091\n",
      "[578/00081] train_loss: 0.006066\n",
      "[578/00131] train_loss: 0.006122\n",
      "[578/00181] train_loss: 0.006097\n",
      "[578/00231] train_loss: 0.006058\n",
      "[578/00281] train_loss: 0.006132\n",
      "[578/00331] train_loss: 0.006132\n",
      "[578/00381] train_loss: 0.006007\n",
      "[579/00025] train_loss: 0.006088\n",
      "[579/00075] train_loss: 0.006115\n",
      "[579/00125] train_loss: 0.006198\n",
      "[579/00175] train_loss: 0.006014\n",
      "[579/00225] train_loss: 0.006062\n",
      "[579/00275] train_loss: 0.006124\n",
      "[579/00325] train_loss: 0.006141\n",
      "[579/00375] train_loss: 0.006054\n",
      "[580/00019] train_loss: 0.006093\n",
      "[580/00069] train_loss: 0.006058\n",
      "[580/00119] train_loss: 0.006076\n",
      "[580/00169] train_loss: 0.006046\n",
      "[580/00219] train_loss: 0.006017\n",
      "[580/00269] train_loss: 0.006096\n",
      "[580/00319] train_loss: 0.006001\n",
      "[580/00369] train_loss: 0.006081\n",
      "[581/00013] train_loss: 0.006106\n",
      "[581/00063] train_loss: 0.006101\n",
      "[581/00113] train_loss: 0.006105\n",
      "[581/00163] train_loss: 0.005990\n",
      "[581/00213] train_loss: 0.006107\n",
      "[581/00263] train_loss: 0.006143\n",
      "[581/00313] train_loss: 0.006064\n",
      "[581/00363] train_loss: 0.006131\n",
      "[582/00007] train_loss: 0.006047\n",
      "[582/00057] train_loss: 0.006167\n",
      "[582/00107] train_loss: 0.006062\n",
      "[582/00157] train_loss: 0.006118\n",
      "[582/00207] train_loss: 0.006144\n",
      "[582/00257] train_loss: 0.006075\n",
      "[582/00307] train_loss: 0.006056\n",
      "[582/00357] train_loss: 0.006041\n",
      "[583/00001] train_loss: 0.006103\n",
      "[583/00051] train_loss: 0.006051\n",
      "[583/00101] train_loss: 0.006158\n",
      "[583/00151] train_loss: 0.006099\n",
      "[583/00201] train_loss: 0.006104\n",
      "[583/00251] train_loss: 0.006099\n",
      "[583/00301] train_loss: 0.006098\n",
      "[583/00351] train_loss: 0.006075\n",
      "[583/00401] train_loss: 0.006075\n",
      "[584/00045] train_loss: 0.006046\n",
      "[584/00095] train_loss: 0.006066\n",
      "[584/00145] train_loss: 0.006128\n",
      "[584/00195] train_loss: 0.005949\n",
      "[584/00245] train_loss: 0.006131\n",
      "[584/00295] train_loss: 0.006133\n",
      "[584/00345] train_loss: 0.006168\n",
      "[584/00395] train_loss: 0.006139\n",
      "[585/00039] train_loss: 0.006187\n",
      "[585/00089] train_loss: 0.006072\n",
      "[585/00139] train_loss: 0.006065\n",
      "[585/00189] train_loss: 0.006051\n",
      "[585/00239] train_loss: 0.006034\n",
      "[585/00289] train_loss: 0.006152\n",
      "[585/00339] train_loss: 0.006008\n",
      "[585/00389] train_loss: 0.006084\n",
      "[586/00033] train_loss: 0.006038\n",
      "[586/00083] train_loss: 0.006080\n",
      "[586/00133] train_loss: 0.006062\n",
      "[586/00183] train_loss: 0.006076\n",
      "[586/00233] train_loss: 0.006137\n",
      "[586/00283] train_loss: 0.006092\n",
      "[586/00333] train_loss: 0.006095\n",
      "[586/00383] train_loss: 0.006078\n",
      "[587/00027] train_loss: 0.006117\n",
      "[587/00077] train_loss: 0.006142\n",
      "[587/00127] train_loss: 0.006094\n",
      "[587/00177] train_loss: 0.006024\n",
      "[587/00227] train_loss: 0.006043\n",
      "[587/00277] train_loss: 0.006148\n",
      "[587/00327] train_loss: 0.006070\n",
      "[587/00377] train_loss: 0.006079\n",
      "[588/00021] train_loss: 0.006128\n",
      "[588/00071] train_loss: 0.006134\n",
      "[588/00121] train_loss: 0.006005\n",
      "[588/00171] train_loss: 0.006058\n",
      "[588/00221] train_loss: 0.006095\n",
      "[588/00271] train_loss: 0.006117\n",
      "[588/00321] train_loss: 0.006097\n",
      "[588/00371] train_loss: 0.006075\n",
      "[589/00015] train_loss: 0.006066\n",
      "[589/00065] train_loss: 0.006063\n",
      "[589/00115] train_loss: 0.006169\n",
      "[589/00165] train_loss: 0.006062\n",
      "[589/00215] train_loss: 0.006057\n",
      "[589/00265] train_loss: 0.006074\n",
      "[589/00315] train_loss: 0.006195\n",
      "[589/00365] train_loss: 0.006087\n",
      "[590/00009] train_loss: 0.006086\n",
      "[590/00059] train_loss: 0.006025\n",
      "[590/00109] train_loss: 0.006124\n",
      "[590/00159] train_loss: 0.006057\n",
      "[590/00209] train_loss: 0.006102\n",
      "[590/00259] train_loss: 0.006046\n",
      "[590/00309] train_loss: 0.006084\n",
      "[590/00359] train_loss: 0.006050\n",
      "[591/00003] train_loss: 0.006047\n",
      "[591/00053] train_loss: 0.005973\n",
      "[591/00103] train_loss: 0.006135\n",
      "[591/00153] train_loss: 0.006117\n",
      "[591/00203] train_loss: 0.006042\n",
      "[591/00253] train_loss: 0.006163\n",
      "[591/00303] train_loss: 0.006077\n",
      "[591/00353] train_loss: 0.006047\n",
      "[591/00403] train_loss: 0.006112\n",
      "[592/00047] train_loss: 0.006119\n",
      "[592/00097] train_loss: 0.006073\n",
      "[592/00147] train_loss: 0.006075\n",
      "[592/00197] train_loss: 0.006122\n",
      "[592/00247] train_loss: 0.006054\n",
      "[592/00297] train_loss: 0.006091\n",
      "[592/00347] train_loss: 0.006031\n",
      "[592/00397] train_loss: 0.006075\n",
      "[593/00041] train_loss: 0.006123\n",
      "[593/00091] train_loss: 0.006053\n",
      "[593/00141] train_loss: 0.006147\n",
      "[593/00191] train_loss: 0.006061\n",
      "[593/00241] train_loss: 0.005989\n",
      "[593/00291] train_loss: 0.006126\n",
      "[593/00341] train_loss: 0.005997\n",
      "[593/00391] train_loss: 0.006170\n",
      "[594/00035] train_loss: 0.006073\n",
      "[594/00085] train_loss: 0.006169\n",
      "[594/00135] train_loss: 0.006044\n",
      "[594/00185] train_loss: 0.006068\n",
      "[594/00235] train_loss: 0.006138\n",
      "[594/00285] train_loss: 0.006067\n",
      "[594/00335] train_loss: 0.006113\n",
      "[594/00385] train_loss: 0.006088\n",
      "[595/00029] train_loss: 0.006130\n",
      "[595/00079] train_loss: 0.006127\n",
      "[595/00129] train_loss: 0.006076\n",
      "[595/00179] train_loss: 0.006118\n",
      "[595/00229] train_loss: 0.006105\n",
      "[595/00279] train_loss: 0.006164\n",
      "[595/00329] train_loss: 0.006094\n",
      "[595/00379] train_loss: 0.006030\n",
      "[596/00023] train_loss: 0.006128\n",
      "[596/00073] train_loss: 0.006071\n",
      "[596/00123] train_loss: 0.006136\n",
      "[596/00173] train_loss: 0.006103\n",
      "[596/00223] train_loss: 0.006133\n",
      "[596/00273] train_loss: 0.006119\n",
      "[596/00323] train_loss: 0.006031\n",
      "[596/00373] train_loss: 0.006176\n",
      "[597/00017] train_loss: 0.006002\n",
      "[597/00067] train_loss: 0.006160\n",
      "[597/00117] train_loss: 0.006025\n",
      "[597/00167] train_loss: 0.006150\n",
      "[597/00217] train_loss: 0.006092\n",
      "[597/00267] train_loss: 0.006134\n",
      "[597/00317] train_loss: 0.006124\n",
      "[597/00367] train_loss: 0.006053\n",
      "[598/00011] train_loss: 0.006101\n",
      "[598/00061] train_loss: 0.006031\n",
      "[598/00111] train_loss: 0.006172\n",
      "[598/00161] train_loss: 0.006012\n",
      "[598/00211] train_loss: 0.006099\n",
      "[598/00261] train_loss: 0.006100\n",
      "[598/00311] train_loss: 0.006012\n",
      "[598/00361] train_loss: 0.006119\n",
      "[599/00005] train_loss: 0.006164\n",
      "[599/00055] train_loss: 0.006142\n",
      "[599/00105] train_loss: 0.006140\n",
      "[599/00155] train_loss: 0.006027\n",
      "[599/00205] train_loss: 0.006102\n",
      "[599/00255] train_loss: 0.006110\n",
      "[599/00305] train_loss: 0.006178\n",
      "[599/00355] train_loss: 0.006084\n",
      "[599/00405] train_loss: 0.006122\n",
      "[600/00049] train_loss: 0.006012\n",
      "[600/00099] train_loss: 0.006153\n",
      "[600/00149] train_loss: 0.006094\n",
      "[600/00199] train_loss: 0.006138\n",
      "[600/00249] train_loss: 0.006104\n",
      "[600/00299] train_loss: 0.006114\n",
      "[600/00349] train_loss: 0.006179\n",
      "[600/00399] train_loss: 0.006093\n",
      "[601/00043] train_loss: 0.006173\n",
      "[601/00093] train_loss: 0.006104\n",
      "[601/00143] train_loss: 0.006096\n",
      "[601/00193] train_loss: 0.006021\n",
      "[601/00243] train_loss: 0.006099\n",
      "[601/00293] train_loss: 0.006143\n",
      "[601/00343] train_loss: 0.005994\n",
      "[601/00393] train_loss: 0.006008\n",
      "[602/00037] train_loss: 0.006018\n",
      "[602/00087] train_loss: 0.006137\n",
      "[602/00137] train_loss: 0.006135\n",
      "[602/00187] train_loss: 0.006105\n",
      "[602/00237] train_loss: 0.006040\n",
      "[602/00287] train_loss: 0.006108\n",
      "[602/00337] train_loss: 0.006124\n",
      "[602/00387] train_loss: 0.006047\n",
      "[603/00031] train_loss: 0.006114\n",
      "[603/00081] train_loss: 0.006092\n",
      "[603/00131] train_loss: 0.006085\n",
      "[603/00181] train_loss: 0.006042\n",
      "[603/00231] train_loss: 0.006123\n",
      "[603/00281] train_loss: 0.006175\n",
      "[603/00331] train_loss: 0.006106\n",
      "[603/00381] train_loss: 0.006040\n",
      "[604/00025] train_loss: 0.006029\n",
      "[604/00075] train_loss: 0.006050\n",
      "[604/00125] train_loss: 0.006079\n",
      "[604/00175] train_loss: 0.006064\n",
      "[604/00225] train_loss: 0.006110\n",
      "[604/00275] train_loss: 0.006124\n",
      "[604/00325] train_loss: 0.006085\n",
      "[604/00375] train_loss: 0.006042\n",
      "[605/00019] train_loss: 0.006082\n",
      "[605/00069] train_loss: 0.006058\n",
      "[605/00119] train_loss: 0.006051\n",
      "[605/00169] train_loss: 0.006115\n",
      "[605/00219] train_loss: 0.006093\n",
      "[605/00269] train_loss: 0.006088\n",
      "[605/00319] train_loss: 0.006097\n",
      "[605/00369] train_loss: 0.006084\n",
      "[606/00013] train_loss: 0.006070\n",
      "[606/00063] train_loss: 0.006162\n",
      "[606/00113] train_loss: 0.006017\n",
      "[606/00163] train_loss: 0.006105\n",
      "[606/00213] train_loss: 0.006157\n",
      "[606/00263] train_loss: 0.006060\n",
      "[606/00313] train_loss: 0.006100\n",
      "[606/00363] train_loss: 0.006062\n",
      "[607/00007] train_loss: 0.006055\n",
      "[607/00057] train_loss: 0.006057\n",
      "[607/00107] train_loss: 0.006155\n",
      "[607/00157] train_loss: 0.006064\n",
      "[607/00207] train_loss: 0.006102\n",
      "[607/00257] train_loss: 0.006066\n",
      "[607/00307] train_loss: 0.006034\n",
      "[607/00357] train_loss: 0.006049\n",
      "[608/00001] train_loss: 0.006037\n",
      "[608/00051] train_loss: 0.006049\n",
      "[608/00101] train_loss: 0.006141\n",
      "[608/00151] train_loss: 0.006088\n",
      "[608/00201] train_loss: 0.006078\n",
      "[608/00251] train_loss: 0.006000\n",
      "[608/00301] train_loss: 0.006119\n",
      "[608/00351] train_loss: 0.006083\n",
      "[608/00401] train_loss: 0.006085\n",
      "[609/00045] train_loss: 0.006193\n",
      "[609/00095] train_loss: 0.006066\n",
      "[609/00145] train_loss: 0.006053\n",
      "[609/00195] train_loss: 0.006041\n",
      "[609/00245] train_loss: 0.005994\n",
      "[609/00295] train_loss: 0.006037\n",
      "[609/00345] train_loss: 0.006102\n",
      "[609/00395] train_loss: 0.006052\n",
      "[610/00039] train_loss: 0.006085\n",
      "[610/00089] train_loss: 0.006118\n",
      "[610/00139] train_loss: 0.006115\n",
      "[610/00189] train_loss: 0.006162\n",
      "[610/00239] train_loss: 0.006021\n",
      "[610/00289] train_loss: 0.006082\n",
      "[610/00339] train_loss: 0.006018\n",
      "[610/00389] train_loss: 0.006103\n",
      "[611/00033] train_loss: 0.006115\n",
      "[611/00083] train_loss: 0.006048\n",
      "[611/00133] train_loss: 0.006144\n",
      "[611/00183] train_loss: 0.006150\n",
      "[611/00233] train_loss: 0.006068\n",
      "[611/00283] train_loss: 0.006144\n",
      "[611/00333] train_loss: 0.006033\n",
      "[611/00383] train_loss: 0.006105\n",
      "[612/00027] train_loss: 0.006141\n",
      "[612/00077] train_loss: 0.006132\n",
      "[612/00127] train_loss: 0.006096\n",
      "[612/00177] train_loss: 0.006168\n",
      "[612/00227] train_loss: 0.006124\n",
      "[612/00277] train_loss: 0.006101\n",
      "[612/00327] train_loss: 0.006133\n",
      "[612/00377] train_loss: 0.006058\n",
      "[613/00021] train_loss: 0.006123\n",
      "[613/00071] train_loss: 0.006162\n",
      "[613/00121] train_loss: 0.006059\n",
      "[613/00171] train_loss: 0.006084\n",
      "[613/00221] train_loss: 0.006145\n",
      "[613/00271] train_loss: 0.006229\n",
      "[613/00321] train_loss: 0.006169\n",
      "[613/00371] train_loss: 0.006146\n",
      "[614/00015] train_loss: 0.006162\n",
      "[614/00065] train_loss: 0.006221\n",
      "[614/00115] train_loss: 0.006147\n",
      "[614/00165] train_loss: 0.006055\n",
      "[614/00215] train_loss: 0.006094\n",
      "[614/00265] train_loss: 0.006083\n",
      "[614/00315] train_loss: 0.006041\n",
      "[614/00365] train_loss: 0.006128\n",
      "[615/00009] train_loss: 0.006194\n",
      "[615/00059] train_loss: 0.006041\n",
      "[615/00109] train_loss: 0.006184\n",
      "[615/00159] train_loss: 0.006076\n",
      "[615/00209] train_loss: 0.006005\n",
      "[615/00259] train_loss: 0.006043\n",
      "[615/00309] train_loss: 0.006120\n",
      "[615/00359] train_loss: 0.006144\n",
      "[616/00003] train_loss: 0.006089\n",
      "[616/00053] train_loss: 0.006086\n",
      "[616/00103] train_loss: 0.006080\n",
      "[616/00153] train_loss: 0.006110\n",
      "[616/00203] train_loss: 0.006063\n",
      "[616/00253] train_loss: 0.006056\n",
      "[616/00303] train_loss: 0.006022\n",
      "[616/00353] train_loss: 0.006086\n",
      "[616/00403] train_loss: 0.006112\n",
      "[617/00047] train_loss: 0.006026\n",
      "[617/00097] train_loss: 0.006103\n",
      "[617/00147] train_loss: 0.006071\n",
      "[617/00197] train_loss: 0.006051\n",
      "[617/00247] train_loss: 0.006088\n",
      "[617/00297] train_loss: 0.006132\n",
      "[617/00347] train_loss: 0.006165\n",
      "[617/00397] train_loss: 0.006113\n",
      "[618/00041] train_loss: 0.006050\n",
      "[618/00091] train_loss: 0.006067\n",
      "[618/00141] train_loss: 0.006024\n",
      "[618/00191] train_loss: 0.006164\n",
      "[618/00241] train_loss: 0.006102\n",
      "[618/00291] train_loss: 0.006077\n",
      "[618/00341] train_loss: 0.006069\n",
      "[618/00391] train_loss: 0.006107\n",
      "[619/00035] train_loss: 0.006144\n",
      "[619/00085] train_loss: 0.005999\n",
      "[619/00135] train_loss: 0.006068\n",
      "[619/00185] train_loss: 0.006146\n",
      "[619/00235] train_loss: 0.006077\n",
      "[619/00285] train_loss: 0.006116\n",
      "[619/00335] train_loss: 0.005966\n",
      "[619/00385] train_loss: 0.006094\n",
      "[620/00029] train_loss: 0.006068\n",
      "[620/00079] train_loss: 0.006113\n",
      "[620/00129] train_loss: 0.006146\n",
      "[620/00179] train_loss: 0.006157\n",
      "[620/00229] train_loss: 0.006055\n",
      "[620/00279] train_loss: 0.006141\n",
      "[620/00329] train_loss: 0.006125\n",
      "[620/00379] train_loss: 0.006109\n",
      "[621/00023] train_loss: 0.006032\n",
      "[621/00073] train_loss: 0.006140\n",
      "[621/00123] train_loss: 0.006068\n",
      "[621/00173] train_loss: 0.006072\n",
      "[621/00223] train_loss: 0.006037\n",
      "[621/00273] train_loss: 0.006024\n",
      "[621/00323] train_loss: 0.006133\n",
      "[621/00373] train_loss: 0.006109\n",
      "[622/00017] train_loss: 0.006107\n",
      "[622/00067] train_loss: 0.006136\n",
      "[622/00117] train_loss: 0.006075\n",
      "[622/00167] train_loss: 0.006134\n",
      "[622/00217] train_loss: 0.006114\n",
      "[622/00267] train_loss: 0.006065\n",
      "[622/00317] train_loss: 0.006081\n",
      "[622/00367] train_loss: 0.006045\n",
      "[623/00011] train_loss: 0.006135\n",
      "[623/00061] train_loss: 0.006032\n",
      "[623/00111] train_loss: 0.006104\n",
      "[623/00161] train_loss: 0.006135\n",
      "[623/00211] train_loss: 0.006118\n",
      "[623/00261] train_loss: 0.006107\n",
      "[623/00311] train_loss: 0.006085\n",
      "[623/00361] train_loss: 0.006101\n",
      "[624/00005] train_loss: 0.006140\n",
      "[624/00055] train_loss: 0.006065\n",
      "[624/00105] train_loss: 0.006098\n",
      "[624/00155] train_loss: 0.006047\n",
      "[624/00205] train_loss: 0.006142\n",
      "[624/00255] train_loss: 0.006137\n",
      "[624/00305] train_loss: 0.006090\n",
      "[624/00355] train_loss: 0.006131\n",
      "[624/00405] train_loss: 0.006044\n",
      "[625/00049] train_loss: 0.006162\n",
      "[625/00099] train_loss: 0.006146\n",
      "[625/00149] train_loss: 0.006094\n",
      "[625/00199] train_loss: 0.006032\n",
      "[625/00249] train_loss: 0.006141\n",
      "[625/00299] train_loss: 0.006156\n",
      "[625/00349] train_loss: 0.006095\n",
      "[625/00399] train_loss: 0.006129\n",
      "[626/00043] train_loss: 0.006035\n",
      "[626/00093] train_loss: 0.006053\n",
      "[626/00143] train_loss: 0.006122\n",
      "[626/00193] train_loss: 0.006067\n",
      "[626/00243] train_loss: 0.006061\n",
      "[626/00293] train_loss: 0.006045\n",
      "[626/00343] train_loss: 0.006037\n",
      "[626/00393] train_loss: 0.006154\n",
      "[627/00037] train_loss: 0.006120\n",
      "[627/00087] train_loss: 0.006118\n",
      "[627/00137] train_loss: 0.005984\n",
      "[627/00187] train_loss: 0.006132\n",
      "[627/00237] train_loss: 0.006091\n",
      "[627/00287] train_loss: 0.006082\n",
      "[627/00337] train_loss: 0.006117\n",
      "[627/00387] train_loss: 0.006134\n",
      "[628/00031] train_loss: 0.006039\n",
      "[628/00081] train_loss: 0.006088\n",
      "[628/00131] train_loss: 0.006071\n",
      "[628/00181] train_loss: 0.006114\n",
      "[628/00231] train_loss: 0.006082\n",
      "[628/00281] train_loss: 0.006025\n",
      "[628/00331] train_loss: 0.006047\n",
      "[628/00381] train_loss: 0.006026\n",
      "[629/00025] train_loss: 0.006068\n",
      "[629/00075] train_loss: 0.006083\n",
      "[629/00125] train_loss: 0.006077\n",
      "[629/00175] train_loss: 0.006090\n",
      "[629/00225] train_loss: 0.006144\n",
      "[629/00275] train_loss: 0.006124\n",
      "[629/00325] train_loss: 0.006083\n",
      "[629/00375] train_loss: 0.006118\n",
      "[630/00019] train_loss: 0.006102\n",
      "[630/00069] train_loss: 0.006088\n",
      "[630/00119] train_loss: 0.006139\n",
      "[630/00169] train_loss: 0.006101\n",
      "[630/00219] train_loss: 0.006078\n",
      "[630/00269] train_loss: 0.006051\n",
      "[630/00319] train_loss: 0.006086\n",
      "[630/00369] train_loss: 0.006108\n",
      "[631/00013] train_loss: 0.005997\n",
      "[631/00063] train_loss: 0.006060\n",
      "[631/00113] train_loss: 0.006016\n",
      "[631/00163] train_loss: 0.006054\n",
      "[631/00213] train_loss: 0.006134\n",
      "[631/00263] train_loss: 0.006102\n",
      "[631/00313] train_loss: 0.006055\n",
      "[631/00363] train_loss: 0.006161\n",
      "[632/00007] train_loss: 0.006170\n",
      "[632/00057] train_loss: 0.006131\n",
      "[632/00107] train_loss: 0.006125\n",
      "[632/00157] train_loss: 0.006111\n",
      "[632/00207] train_loss: 0.006053\n",
      "[632/00257] train_loss: 0.006117\n",
      "[632/00307] train_loss: 0.006158\n",
      "[632/00357] train_loss: 0.006074\n",
      "[633/00001] train_loss: 0.005963\n",
      "[633/00051] train_loss: 0.006065\n",
      "[633/00101] train_loss: 0.006072\n",
      "[633/00151] train_loss: 0.006101\n",
      "[633/00201] train_loss: 0.006098\n",
      "[633/00251] train_loss: 0.006193\n",
      "[633/00301] train_loss: 0.006099\n",
      "[633/00351] train_loss: 0.006036\n",
      "[633/00401] train_loss: 0.006211\n",
      "[634/00045] train_loss: 0.006055\n",
      "[634/00095] train_loss: 0.005948\n",
      "[634/00145] train_loss: 0.006069\n",
      "[634/00195] train_loss: 0.006071\n",
      "[634/00245] train_loss: 0.006066\n",
      "[634/00295] train_loss: 0.006071\n",
      "[634/00345] train_loss: 0.006152\n",
      "[634/00395] train_loss: 0.006032\n",
      "[635/00039] train_loss: 0.006069\n",
      "[635/00089] train_loss: 0.006022\n",
      "[635/00139] train_loss: 0.006098\n",
      "[635/00189] train_loss: 0.006087\n",
      "[635/00239] train_loss: 0.006011\n",
      "[635/00289] train_loss: 0.006164\n",
      "[635/00339] train_loss: 0.006036\n",
      "[635/00389] train_loss: 0.006094\n",
      "[636/00033] train_loss: 0.006080\n",
      "[636/00083] train_loss: 0.006037\n",
      "[636/00133] train_loss: 0.006189\n",
      "[636/00183] train_loss: 0.006168\n",
      "[636/00233] train_loss: 0.006131\n",
      "[636/00283] train_loss: 0.006011\n",
      "[636/00333] train_loss: 0.006148\n",
      "[636/00383] train_loss: 0.006051\n",
      "[637/00027] train_loss: 0.005998\n",
      "[637/00077] train_loss: 0.006087\n",
      "[637/00127] train_loss: 0.006187\n",
      "[637/00177] train_loss: 0.006113\n",
      "[637/00227] train_loss: 0.006189\n",
      "[637/00277] train_loss: 0.006066\n",
      "[637/00327] train_loss: 0.006064\n",
      "[637/00377] train_loss: 0.006094\n",
      "[638/00021] train_loss: 0.006125\n",
      "[638/00071] train_loss: 0.006035\n",
      "[638/00121] train_loss: 0.006084\n",
      "[638/00171] train_loss: 0.006157\n",
      "[638/00221] train_loss: 0.006110\n",
      "[638/00271] train_loss: 0.006054\n",
      "[638/00321] train_loss: 0.006159\n",
      "[638/00371] train_loss: 0.006049\n",
      "[639/00015] train_loss: 0.006127\n",
      "[639/00065] train_loss: 0.006164\n",
      "[639/00115] train_loss: 0.006197\n",
      "[639/00165] train_loss: 0.006063\n",
      "[639/00215] train_loss: 0.006128\n",
      "[639/00265] train_loss: 0.006081\n",
      "[639/00315] train_loss: 0.006037\n",
      "[639/00365] train_loss: 0.006099\n",
      "[640/00009] train_loss: 0.006149\n",
      "[640/00059] train_loss: 0.006085\n",
      "[640/00109] train_loss: 0.006076\n",
      "[640/00159] train_loss: 0.006090\n",
      "[640/00209] train_loss: 0.006133\n",
      "[640/00259] train_loss: 0.005986\n",
      "[640/00309] train_loss: 0.006002\n",
      "[640/00359] train_loss: 0.006039\n",
      "[641/00003] train_loss: 0.006164\n",
      "[641/00053] train_loss: 0.006047\n",
      "[641/00103] train_loss: 0.006153\n",
      "[641/00153] train_loss: 0.006082\n",
      "[641/00203] train_loss: 0.006108\n",
      "[641/00253] train_loss: 0.006167\n",
      "[641/00303] train_loss: 0.006114\n",
      "[641/00353] train_loss: 0.006104\n",
      "[641/00403] train_loss: 0.006097\n",
      "[642/00047] train_loss: 0.005995\n",
      "[642/00097] train_loss: 0.006166\n",
      "[642/00147] train_loss: 0.006070\n",
      "[642/00197] train_loss: 0.006107\n",
      "[642/00247] train_loss: 0.006069\n",
      "[642/00297] train_loss: 0.006158\n",
      "[642/00347] train_loss: 0.006031\n",
      "[642/00397] train_loss: 0.006082\n",
      "[643/00041] train_loss: 0.006129\n",
      "[643/00091] train_loss: 0.006074\n",
      "[643/00141] train_loss: 0.006133\n",
      "[643/00191] train_loss: 0.006160\n",
      "[643/00241] train_loss: 0.006163\n",
      "[643/00291] train_loss: 0.006168\n",
      "[643/00341] train_loss: 0.006124\n",
      "[643/00391] train_loss: 0.006095\n",
      "[644/00035] train_loss: 0.006131\n",
      "[644/00085] train_loss: 0.006086\n",
      "[644/00135] train_loss: 0.006084\n",
      "[644/00185] train_loss: 0.006003\n",
      "[644/00235] train_loss: 0.006130\n",
      "[644/00285] train_loss: 0.006045\n",
      "[644/00335] train_loss: 0.006117\n",
      "[644/00385] train_loss: 0.006174\n",
      "[645/00029] train_loss: 0.006186\n",
      "[645/00079] train_loss: 0.006150\n",
      "[645/00129] train_loss: 0.006061\n",
      "[645/00179] train_loss: 0.006060\n",
      "[645/00229] train_loss: 0.006050\n",
      "[645/00279] train_loss: 0.006050\n",
      "[645/00329] train_loss: 0.006113\n",
      "[645/00379] train_loss: 0.006143\n",
      "[646/00023] train_loss: 0.006111\n",
      "[646/00073] train_loss: 0.006076\n",
      "[646/00123] train_loss: 0.006113\n",
      "[646/00173] train_loss: 0.006105\n",
      "[646/00223] train_loss: 0.006116\n",
      "[646/00273] train_loss: 0.006061\n",
      "[646/00323] train_loss: 0.006130\n",
      "[646/00373] train_loss: 0.006042\n",
      "[647/00017] train_loss: 0.006037\n",
      "[647/00067] train_loss: 0.006036\n",
      "[647/00117] train_loss: 0.006139\n",
      "[647/00167] train_loss: 0.006121\n",
      "[647/00217] train_loss: 0.006113\n",
      "[647/00267] train_loss: 0.006070\n",
      "[647/00317] train_loss: 0.006172\n",
      "[647/00367] train_loss: 0.006033\n",
      "[648/00011] train_loss: 0.006147\n",
      "[648/00061] train_loss: 0.006103\n",
      "[648/00111] train_loss: 0.006115\n",
      "[648/00161] train_loss: 0.006062\n",
      "[648/00211] train_loss: 0.006142\n",
      "[648/00261] train_loss: 0.006079\n",
      "[648/00311] train_loss: 0.006063\n",
      "[648/00361] train_loss: 0.006016\n",
      "[649/00005] train_loss: 0.006090\n",
      "[649/00055] train_loss: 0.006145\n",
      "[649/00105] train_loss: 0.006125\n",
      "[649/00155] train_loss: 0.006116\n",
      "[649/00205] train_loss: 0.006013\n",
      "[649/00255] train_loss: 0.006140\n",
      "[649/00305] train_loss: 0.006108\n",
      "[649/00355] train_loss: 0.006111\n",
      "[649/00405] train_loss: 0.006042\n",
      "[650/00049] train_loss: 0.006092\n",
      "[650/00099] train_loss: 0.006056\n",
      "[650/00149] train_loss: 0.006036\n",
      "[650/00199] train_loss: 0.006085\n",
      "[650/00249] train_loss: 0.006137\n",
      "[650/00299] train_loss: 0.005938\n",
      "[650/00349] train_loss: 0.006113\n",
      "[650/00399] train_loss: 0.006053\n",
      "[651/00043] train_loss: 0.006101\n",
      "[651/00093] train_loss: 0.006000\n",
      "[651/00143] train_loss: 0.006146\n",
      "[651/00193] train_loss: 0.006045\n",
      "[651/00243] train_loss: 0.006114\n",
      "[651/00293] train_loss: 0.006063\n",
      "[651/00343] train_loss: 0.006136\n",
      "[651/00393] train_loss: 0.006208\n",
      "[652/00037] train_loss: 0.006104\n",
      "[652/00087] train_loss: 0.006049\n",
      "[652/00137] train_loss: 0.006084\n",
      "[652/00187] train_loss: 0.006100\n",
      "[652/00237] train_loss: 0.006087\n",
      "[652/00287] train_loss: 0.006125\n",
      "[652/00337] train_loss: 0.006073\n",
      "[652/00387] train_loss: 0.006120\n",
      "[653/00031] train_loss: 0.006123\n",
      "[653/00081] train_loss: 0.006021\n",
      "[653/00131] train_loss: 0.006023\n",
      "[653/00181] train_loss: 0.005990\n",
      "[653/00231] train_loss: 0.006116\n",
      "[653/00281] train_loss: 0.006079\n",
      "[653/00331] train_loss: 0.006189\n",
      "[653/00381] train_loss: 0.006157\n",
      "[654/00025] train_loss: 0.006120\n",
      "[654/00075] train_loss: 0.006120\n",
      "[654/00125] train_loss: 0.006201\n",
      "[654/00175] train_loss: 0.006125\n",
      "[654/00225] train_loss: 0.006148\n",
      "[654/00275] train_loss: 0.006117\n",
      "[654/00325] train_loss: 0.006117\n",
      "[654/00375] train_loss: 0.006134\n",
      "[655/00019] train_loss: 0.006151\n",
      "[655/00069] train_loss: 0.006034\n",
      "[655/00119] train_loss: 0.006125\n",
      "[655/00169] train_loss: 0.006045\n",
      "[655/00219] train_loss: 0.006080\n",
      "[655/00269] train_loss: 0.006146\n",
      "[655/00319] train_loss: 0.006088\n",
      "[655/00369] train_loss: 0.006112\n",
      "[656/00013] train_loss: 0.006107\n",
      "[656/00063] train_loss: 0.006031\n",
      "[656/00113] train_loss: 0.006141\n",
      "[656/00163] train_loss: 0.006100\n",
      "[656/00213] train_loss: 0.006059\n",
      "[656/00263] train_loss: 0.006127\n",
      "[656/00313] train_loss: 0.006173\n",
      "[656/00363] train_loss: 0.005969\n",
      "[657/00007] train_loss: 0.006164\n",
      "[657/00057] train_loss: 0.006072\n",
      "[657/00107] train_loss: 0.006086\n",
      "[657/00157] train_loss: 0.006096\n",
      "[657/00207] train_loss: 0.006140\n",
      "[657/00257] train_loss: 0.006051\n",
      "[657/00307] train_loss: 0.006064\n",
      "[657/00357] train_loss: 0.006045\n",
      "[658/00001] train_loss: 0.006121\n",
      "[658/00051] train_loss: 0.006132\n",
      "[658/00101] train_loss: 0.006039\n",
      "[658/00151] train_loss: 0.006077\n",
      "[658/00201] train_loss: 0.006187\n",
      "[658/00251] train_loss: 0.006116\n",
      "[658/00301] train_loss: 0.006078\n",
      "[658/00351] train_loss: 0.006122\n",
      "[658/00401] train_loss: 0.006131\n",
      "[659/00045] train_loss: 0.006142\n",
      "[659/00095] train_loss: 0.006043\n",
      "[659/00145] train_loss: 0.006068\n",
      "[659/00195] train_loss: 0.006133\n",
      "[659/00245] train_loss: 0.006093\n",
      "[659/00295] train_loss: 0.006104\n",
      "[659/00345] train_loss: 0.006120\n",
      "[659/00395] train_loss: 0.006146\n",
      "[660/00039] train_loss: 0.006075\n",
      "[660/00089] train_loss: 0.006068\n",
      "[660/00139] train_loss: 0.006060\n",
      "[660/00189] train_loss: 0.006171\n",
      "[660/00239] train_loss: 0.006054\n",
      "[660/00289] train_loss: 0.006145\n",
      "[660/00339] train_loss: 0.006138\n",
      "[660/00389] train_loss: 0.006119\n",
      "[661/00033] train_loss: 0.006131\n",
      "[661/00083] train_loss: 0.006086\n",
      "[661/00133] train_loss: 0.005930\n",
      "[661/00183] train_loss: 0.006141\n",
      "[661/00233] train_loss: 0.006063\n",
      "[661/00283] train_loss: 0.006184\n",
      "[661/00333] train_loss: 0.006119\n",
      "[661/00383] train_loss: 0.006177\n",
      "[662/00027] train_loss: 0.006145\n",
      "[662/00077] train_loss: 0.006175\n",
      "[662/00127] train_loss: 0.006058\n",
      "[662/00177] train_loss: 0.006136\n",
      "[662/00227] train_loss: 0.006122\n",
      "[662/00277] train_loss: 0.006145\n",
      "[662/00327] train_loss: 0.006109\n",
      "[662/00377] train_loss: 0.006093\n",
      "[663/00021] train_loss: 0.006048\n",
      "[663/00071] train_loss: 0.006146\n",
      "[663/00121] train_loss: 0.006097\n",
      "[663/00171] train_loss: 0.006102\n",
      "[663/00221] train_loss: 0.006150\n",
      "[663/00271] train_loss: 0.006002\n",
      "[663/00321] train_loss: 0.006160\n",
      "[663/00371] train_loss: 0.006089\n",
      "[664/00015] train_loss: 0.006053\n",
      "[664/00065] train_loss: 0.006094\n",
      "[664/00115] train_loss: 0.006084\n",
      "[664/00165] train_loss: 0.005990\n",
      "[664/00215] train_loss: 0.006010\n",
      "[664/00265] train_loss: 0.006161\n",
      "[664/00315] train_loss: 0.006044\n",
      "[664/00365] train_loss: 0.005997\n",
      "[665/00009] train_loss: 0.006069\n",
      "[665/00059] train_loss: 0.006088\n",
      "[665/00109] train_loss: 0.006129\n",
      "[665/00159] train_loss: 0.006165\n",
      "[665/00209] train_loss: 0.006100\n",
      "[665/00259] train_loss: 0.006068\n",
      "[665/00309] train_loss: 0.006074\n",
      "[665/00359] train_loss: 0.006059\n",
      "[666/00003] train_loss: 0.006120\n",
      "[666/00053] train_loss: 0.006062\n",
      "[666/00103] train_loss: 0.006015\n",
      "[666/00153] train_loss: 0.006128\n",
      "[666/00203] train_loss: 0.006027\n",
      "[666/00253] train_loss: 0.006063\n",
      "[666/00303] train_loss: 0.006095\n",
      "[666/00353] train_loss: 0.006151\n",
      "[666/00403] train_loss: 0.006131\n",
      "[667/00047] train_loss: 0.006041\n",
      "[667/00097] train_loss: 0.006132\n",
      "[667/00147] train_loss: 0.006064\n",
      "[667/00197] train_loss: 0.006112\n",
      "[667/00247] train_loss: 0.006058\n",
      "[667/00297] train_loss: 0.006104\n",
      "[667/00347] train_loss: 0.006090\n",
      "[667/00397] train_loss: 0.006061\n",
      "[668/00041] train_loss: 0.006090\n",
      "[668/00091] train_loss: 0.006011\n",
      "[668/00141] train_loss: 0.006106\n",
      "[668/00191] train_loss: 0.006116\n",
      "[668/00241] train_loss: 0.006146\n",
      "[668/00291] train_loss: 0.006106\n",
      "[668/00341] train_loss: 0.006142\n",
      "[668/00391] train_loss: 0.006072\n",
      "[669/00035] train_loss: 0.006065\n",
      "[669/00085] train_loss: 0.005990\n",
      "[669/00135] train_loss: 0.006012\n",
      "[669/00185] train_loss: 0.006022\n",
      "[669/00235] train_loss: 0.006129\n",
      "[669/00285] train_loss: 0.006086\n",
      "[669/00335] train_loss: 0.006205\n",
      "[669/00385] train_loss: 0.006190\n",
      "[670/00029] train_loss: 0.006000\n",
      "[670/00079] train_loss: 0.006077\n",
      "[670/00129] train_loss: 0.006033\n",
      "[670/00179] train_loss: 0.006122\n",
      "[670/00229] train_loss: 0.006072\n",
      "[670/00279] train_loss: 0.006082\n",
      "[670/00329] train_loss: 0.006112\n",
      "[670/00379] train_loss: 0.006146\n",
      "[671/00023] train_loss: 0.006037\n",
      "[671/00073] train_loss: 0.006062\n",
      "[671/00123] train_loss: 0.006100\n",
      "[671/00173] train_loss: 0.006015\n",
      "[671/00223] train_loss: 0.006170\n",
      "[671/00273] train_loss: 0.006059\n",
      "[671/00323] train_loss: 0.006132\n",
      "[671/00373] train_loss: 0.006075\n",
      "[672/00017] train_loss: 0.006161\n",
      "[672/00067] train_loss: 0.006030\n",
      "[672/00117] train_loss: 0.006113\n",
      "[672/00167] train_loss: 0.006117\n",
      "[672/00217] train_loss: 0.006049\n",
      "[672/00267] train_loss: 0.006095\n",
      "[672/00317] train_loss: 0.006097\n",
      "[672/00367] train_loss: 0.005989\n",
      "[673/00011] train_loss: 0.006039\n",
      "[673/00061] train_loss: 0.006081\n",
      "[673/00111] train_loss: 0.006081\n",
      "[673/00161] train_loss: 0.006081\n",
      "[673/00211] train_loss: 0.006044\n",
      "[673/00261] train_loss: 0.006056\n",
      "[673/00311] train_loss: 0.006020\n",
      "[673/00361] train_loss: 0.006104\n",
      "[674/00005] train_loss: 0.006047\n",
      "[674/00055] train_loss: 0.006021\n",
      "[674/00105] train_loss: 0.006127\n",
      "[674/00155] train_loss: 0.006139\n",
      "[674/00205] train_loss: 0.006117\n",
      "[674/00255] train_loss: 0.006101\n",
      "[674/00305] train_loss: 0.006118\n",
      "[674/00355] train_loss: 0.006096\n",
      "[674/00405] train_loss: 0.006010\n",
      "[675/00049] train_loss: 0.006013\n",
      "[675/00099] train_loss: 0.006078\n",
      "[675/00149] train_loss: 0.005961\n",
      "[675/00199] train_loss: 0.006101\n",
      "[675/00249] train_loss: 0.006091\n",
      "[675/00299] train_loss: 0.006135\n",
      "[675/00349] train_loss: 0.006142\n",
      "[675/00399] train_loss: 0.006093\n",
      "[676/00043] train_loss: 0.006077\n",
      "[676/00093] train_loss: 0.006129\n",
      "[676/00143] train_loss: 0.006107\n",
      "[676/00193] train_loss: 0.006025\n",
      "[676/00243] train_loss: 0.006054\n",
      "[676/00293] train_loss: 0.006156\n",
      "[676/00343] train_loss: 0.006089\n",
      "[676/00393] train_loss: 0.006127\n",
      "[677/00037] train_loss: 0.006149\n",
      "[677/00087] train_loss: 0.006037\n",
      "[677/00137] train_loss: 0.006026\n",
      "[677/00187] train_loss: 0.006143\n",
      "[677/00237] train_loss: 0.006119\n",
      "[677/00287] train_loss: 0.006051\n",
      "[677/00337] train_loss: 0.006052\n",
      "[677/00387] train_loss: 0.006077\n",
      "[678/00031] train_loss: 0.006104\n",
      "[678/00081] train_loss: 0.006192\n",
      "[678/00131] train_loss: 0.006055\n",
      "[678/00181] train_loss: 0.006029\n",
      "[678/00231] train_loss: 0.006074\n",
      "[678/00281] train_loss: 0.006093\n",
      "[678/00331] train_loss: 0.006086\n",
      "[678/00381] train_loss: 0.006076\n",
      "[679/00025] train_loss: 0.006056\n",
      "[679/00075] train_loss: 0.006098\n",
      "[679/00125] train_loss: 0.006180\n",
      "[679/00175] train_loss: 0.006041\n",
      "[679/00225] train_loss: 0.006087\n",
      "[679/00275] train_loss: 0.006117\n",
      "[679/00325] train_loss: 0.006088\n",
      "[679/00375] train_loss: 0.006162\n",
      "[680/00019] train_loss: 0.006084\n",
      "[680/00069] train_loss: 0.006101\n",
      "[680/00119] train_loss: 0.006136\n",
      "[680/00169] train_loss: 0.005989\n",
      "[680/00219] train_loss: 0.006117\n",
      "[680/00269] train_loss: 0.006137\n",
      "[680/00319] train_loss: 0.006028\n",
      "[680/00369] train_loss: 0.006129\n",
      "[681/00013] train_loss: 0.006150\n",
      "[681/00063] train_loss: 0.006127\n",
      "[681/00113] train_loss: 0.006043\n",
      "[681/00163] train_loss: 0.006062\n",
      "[681/00213] train_loss: 0.006104\n",
      "[681/00263] train_loss: 0.006070\n",
      "[681/00313] train_loss: 0.006083\n",
      "[681/00363] train_loss: 0.006103\n",
      "[682/00007] train_loss: 0.006160\n",
      "[682/00057] train_loss: 0.006135\n",
      "[682/00107] train_loss: 0.006077\n",
      "[682/00157] train_loss: 0.006172\n",
      "[682/00207] train_loss: 0.006057\n",
      "[682/00257] train_loss: 0.006102\n",
      "[682/00307] train_loss: 0.006074\n",
      "[682/00357] train_loss: 0.006039\n",
      "[683/00001] train_loss: 0.006069\n",
      "[683/00051] train_loss: 0.006139\n",
      "[683/00101] train_loss: 0.006050\n",
      "[683/00151] train_loss: 0.006208\n",
      "[683/00201] train_loss: 0.006152\n",
      "[683/00251] train_loss: 0.006116\n",
      "[683/00301] train_loss: 0.006097\n",
      "[683/00351] train_loss: 0.006086\n",
      "[683/00401] train_loss: 0.006102\n",
      "[684/00045] train_loss: 0.006085\n",
      "[684/00095] train_loss: 0.006074\n",
      "[684/00145] train_loss: 0.006067\n",
      "[684/00195] train_loss: 0.006098\n",
      "[684/00245] train_loss: 0.006133\n",
      "[684/00295] train_loss: 0.006106\n",
      "[684/00345] train_loss: 0.006110\n",
      "[684/00395] train_loss: 0.006178\n",
      "[685/00039] train_loss: 0.006067\n",
      "[685/00089] train_loss: 0.006153\n",
      "[685/00139] train_loss: 0.006130\n",
      "[685/00189] train_loss: 0.005990\n",
      "[685/00239] train_loss: 0.006084\n",
      "[685/00289] train_loss: 0.006079\n",
      "[685/00339] train_loss: 0.006061\n",
      "[685/00389] train_loss: 0.006121\n",
      "[686/00033] train_loss: 0.006059\n",
      "[686/00083] train_loss: 0.006034\n",
      "[686/00133] train_loss: 0.006016\n",
      "[686/00183] train_loss: 0.006129\n",
      "[686/00233] train_loss: 0.006083\n",
      "[686/00283] train_loss: 0.006160\n",
      "[686/00333] train_loss: 0.006080\n",
      "[686/00383] train_loss: 0.006099\n",
      "[687/00027] train_loss: 0.006084\n",
      "[687/00077] train_loss: 0.006115\n",
      "[687/00127] train_loss: 0.006079\n",
      "[687/00177] train_loss: 0.006020\n",
      "[687/00227] train_loss: 0.006112\n",
      "[687/00277] train_loss: 0.006134\n",
      "[687/00327] train_loss: 0.006161\n",
      "[687/00377] train_loss: 0.006025\n",
      "[688/00021] train_loss: 0.006057\n",
      "[688/00071] train_loss: 0.005986\n",
      "[688/00121] train_loss: 0.006122\n",
      "[688/00171] train_loss: 0.005993\n",
      "[688/00221] train_loss: 0.006093\n",
      "[688/00271] train_loss: 0.006162\n",
      "[688/00321] train_loss: 0.006066\n",
      "[688/00371] train_loss: 0.006113\n",
      "[689/00015] train_loss: 0.006159\n",
      "[689/00065] train_loss: 0.006092\n",
      "[689/00115] train_loss: 0.006080\n",
      "[689/00165] train_loss: 0.005988\n",
      "[689/00215] train_loss: 0.006110\n",
      "[689/00265] train_loss: 0.006069\n",
      "[689/00315] train_loss: 0.006035\n",
      "[689/00365] train_loss: 0.006059\n",
      "[690/00009] train_loss: 0.006139\n",
      "[690/00059] train_loss: 0.006034\n",
      "[690/00109] train_loss: 0.006073\n",
      "[690/00159] train_loss: 0.005992\n",
      "[690/00209] train_loss: 0.006136\n",
      "[690/00259] train_loss: 0.006096\n",
      "[690/00309] train_loss: 0.006046\n",
      "[690/00359] train_loss: 0.006136\n",
      "[691/00003] train_loss: 0.006162\n",
      "[691/00053] train_loss: 0.006097\n",
      "[691/00103] train_loss: 0.005980\n",
      "[691/00153] train_loss: 0.006088\n",
      "[691/00203] train_loss: 0.006166\n",
      "[691/00253] train_loss: 0.006205\n",
      "[691/00303] train_loss: 0.006081\n",
      "[691/00353] train_loss: 0.006100\n",
      "[691/00403] train_loss: 0.006087\n",
      "[692/00047] train_loss: 0.006081\n",
      "[692/00097] train_loss: 0.006071\n",
      "[692/00147] train_loss: 0.006123\n",
      "[692/00197] train_loss: 0.006022\n",
      "[692/00247] train_loss: 0.006119\n",
      "[692/00297] train_loss: 0.006085\n",
      "[692/00347] train_loss: 0.006101\n",
      "[692/00397] train_loss: 0.006048\n",
      "[693/00041] train_loss: 0.006039\n",
      "[693/00091] train_loss: 0.006107\n",
      "[693/00141] train_loss: 0.006221\n",
      "[693/00191] train_loss: 0.006117\n",
      "[693/00241] train_loss: 0.005990\n",
      "[693/00291] train_loss: 0.006192\n",
      "[693/00341] train_loss: 0.006103\n",
      "[693/00391] train_loss: 0.006063\n",
      "[694/00035] train_loss: 0.006053\n",
      "[694/00085] train_loss: 0.006110\n",
      "[694/00135] train_loss: 0.006100\n",
      "[694/00185] train_loss: 0.006055\n",
      "[694/00235] train_loss: 0.006180\n",
      "[694/00285] train_loss: 0.005974\n",
      "[694/00335] train_loss: 0.006048\n",
      "[694/00385] train_loss: 0.005996\n",
      "[695/00029] train_loss: 0.006015\n",
      "[695/00079] train_loss: 0.006049\n",
      "[695/00129] train_loss: 0.006079\n",
      "[695/00179] train_loss: 0.006049\n",
      "[695/00229] train_loss: 0.006227\n",
      "[695/00279] train_loss: 0.006114\n",
      "[695/00329] train_loss: 0.006096\n",
      "[695/00379] train_loss: 0.006133\n",
      "[696/00023] train_loss: 0.006110\n",
      "[696/00073] train_loss: 0.006157\n",
      "[696/00123] train_loss: 0.006046\n",
      "[696/00173] train_loss: 0.006022\n",
      "[696/00223] train_loss: 0.006133\n",
      "[696/00273] train_loss: 0.005982\n",
      "[696/00323] train_loss: 0.006000\n",
      "[696/00373] train_loss: 0.006152\n",
      "[697/00017] train_loss: 0.006020\n",
      "[697/00067] train_loss: 0.006200\n",
      "[697/00117] train_loss: 0.006133\n",
      "[697/00167] train_loss: 0.006116\n",
      "[697/00217] train_loss: 0.006098\n",
      "[697/00267] train_loss: 0.006129\n",
      "[697/00317] train_loss: 0.006102\n",
      "[697/00367] train_loss: 0.006120\n",
      "[698/00011] train_loss: 0.006160\n",
      "[698/00061] train_loss: 0.006103\n",
      "[698/00111] train_loss: 0.006138\n",
      "[698/00161] train_loss: 0.006097\n",
      "[698/00211] train_loss: 0.006118\n",
      "[698/00261] train_loss: 0.006126\n",
      "[698/00311] train_loss: 0.006092\n",
      "[698/00361] train_loss: 0.006177\n",
      "[699/00005] train_loss: 0.006168\n",
      "[699/00055] train_loss: 0.006137\n",
      "[699/00105] train_loss: 0.006041\n",
      "[699/00155] train_loss: 0.006106\n",
      "[699/00205] train_loss: 0.006109\n",
      "[699/00255] train_loss: 0.006062\n",
      "[699/00305] train_loss: 0.006134\n",
      "[699/00355] train_loss: 0.006083\n",
      "[699/00405] train_loss: 0.006130\n",
      "[700/00049] train_loss: 0.006158\n",
      "[700/00099] train_loss: 0.006111\n",
      "[700/00149] train_loss: 0.006072\n",
      "[700/00199] train_loss: 0.006125\n",
      "[700/00249] train_loss: 0.006080\n",
      "[700/00299] train_loss: 0.006093\n",
      "[700/00349] train_loss: 0.006054\n",
      "[700/00399] train_loss: 0.006070\n",
      "[701/00043] train_loss: 0.006171\n",
      "[701/00093] train_loss: 0.006166\n",
      "[701/00143] train_loss: 0.006119\n",
      "[701/00193] train_loss: 0.006107\n",
      "[701/00243] train_loss: 0.006003\n",
      "[701/00293] train_loss: 0.006122\n",
      "[701/00343] train_loss: 0.006085\n",
      "[701/00393] train_loss: 0.006093\n",
      "[702/00037] train_loss: 0.006172\n",
      "[702/00087] train_loss: 0.006068\n",
      "[702/00137] train_loss: 0.006081\n",
      "[702/00187] train_loss: 0.006014\n",
      "[702/00237] train_loss: 0.006006\n",
      "[702/00287] train_loss: 0.006128\n",
      "[702/00337] train_loss: 0.006109\n",
      "[702/00387] train_loss: 0.006130\n",
      "[703/00031] train_loss: 0.006061\n",
      "[703/00081] train_loss: 0.006126\n",
      "[703/00131] train_loss: 0.006042\n",
      "[703/00181] train_loss: 0.006059\n",
      "[703/00231] train_loss: 0.006087\n",
      "[703/00281] train_loss: 0.006065\n",
      "[703/00331] train_loss: 0.006115\n",
      "[703/00381] train_loss: 0.006099\n",
      "[704/00025] train_loss: 0.006044\n",
      "[704/00075] train_loss: 0.006096\n",
      "[704/00125] train_loss: 0.006063\n",
      "[704/00175] train_loss: 0.006153\n",
      "[704/00225] train_loss: 0.006019\n",
      "[704/00275] train_loss: 0.006057\n",
      "[704/00325] train_loss: 0.006167\n",
      "[704/00375] train_loss: 0.006103\n",
      "[705/00019] train_loss: 0.006140\n",
      "[705/00069] train_loss: 0.006134\n",
      "[705/00119] train_loss: 0.006089\n",
      "[705/00169] train_loss: 0.006097\n",
      "[705/00219] train_loss: 0.006080\n",
      "[705/00269] train_loss: 0.006119\n",
      "[705/00319] train_loss: 0.006106\n",
      "[705/00369] train_loss: 0.006055\n",
      "[706/00013] train_loss: 0.006035\n",
      "[706/00063] train_loss: 0.006083\n",
      "[706/00113] train_loss: 0.006091\n",
      "[706/00163] train_loss: 0.006057\n",
      "[706/00213] train_loss: 0.006227\n",
      "[706/00263] train_loss: 0.006114\n",
      "[706/00313] train_loss: 0.006026\n",
      "[706/00363] train_loss: 0.006143\n",
      "[707/00007] train_loss: 0.006087\n",
      "[707/00057] train_loss: 0.006071\n",
      "[707/00107] train_loss: 0.006109\n",
      "[707/00157] train_loss: 0.006132\n",
      "[707/00207] train_loss: 0.006043\n",
      "[707/00257] train_loss: 0.006054\n",
      "[707/00307] train_loss: 0.006134\n",
      "[707/00357] train_loss: 0.006050\n",
      "[708/00001] train_loss: 0.006113\n",
      "[708/00051] train_loss: 0.006082\n",
      "[708/00101] train_loss: 0.006103\n",
      "[708/00151] train_loss: 0.006051\n",
      "[708/00201] train_loss: 0.006177\n",
      "[708/00251] train_loss: 0.006036\n",
      "[708/00301] train_loss: 0.006095\n",
      "[708/00351] train_loss: 0.006054\n",
      "[708/00401] train_loss: 0.006097\n",
      "[709/00045] train_loss: 0.006208\n",
      "[709/00095] train_loss: 0.006000\n",
      "[709/00145] train_loss: 0.006128\n",
      "[709/00195] train_loss: 0.006150\n",
      "[709/00245] train_loss: 0.006055\n",
      "[709/00295] train_loss: 0.006102\n",
      "[709/00345] train_loss: 0.006054\n",
      "[709/00395] train_loss: 0.006121\n",
      "[710/00039] train_loss: 0.006041\n",
      "[710/00089] train_loss: 0.006143\n",
      "[710/00139] train_loss: 0.006006\n",
      "[710/00189] train_loss: 0.006097\n",
      "[710/00239] train_loss: 0.006049\n",
      "[710/00289] train_loss: 0.006025\n",
      "[710/00339] train_loss: 0.006144\n",
      "[710/00389] train_loss: 0.006009\n",
      "[711/00033] train_loss: 0.006049\n",
      "[711/00083] train_loss: 0.006024\n",
      "[711/00133] train_loss: 0.006024\n",
      "[711/00183] train_loss: 0.006186\n",
      "[711/00233] train_loss: 0.006057\n",
      "[711/00283] train_loss: 0.006177\n",
      "[711/00333] train_loss: 0.006103\n",
      "[711/00383] train_loss: 0.006036\n",
      "[712/00027] train_loss: 0.006148\n",
      "[712/00077] train_loss: 0.006058\n",
      "[712/00127] train_loss: 0.006127\n",
      "[712/00177] train_loss: 0.006095\n",
      "[712/00227] train_loss: 0.006165\n",
      "[712/00277] train_loss: 0.006149\n",
      "[712/00327] train_loss: 0.006182\n",
      "[712/00377] train_loss: 0.006118\n",
      "[713/00021] train_loss: 0.006064\n",
      "[713/00071] train_loss: 0.006167\n",
      "[713/00121] train_loss: 0.006163\n",
      "[713/00171] train_loss: 0.006069\n",
      "[713/00221] train_loss: 0.006119\n",
      "[713/00271] train_loss: 0.005968\n",
      "[713/00321] train_loss: 0.006148\n",
      "[713/00371] train_loss: 0.006103\n",
      "[714/00015] train_loss: 0.006063\n",
      "[714/00065] train_loss: 0.006056\n",
      "[714/00115] train_loss: 0.006025\n",
      "[714/00165] train_loss: 0.006075\n",
      "[714/00215] train_loss: 0.006049\n",
      "[714/00265] train_loss: 0.006094\n",
      "[714/00315] train_loss: 0.006155\n",
      "[714/00365] train_loss: 0.006012\n",
      "[715/00009] train_loss: 0.006087\n",
      "[715/00059] train_loss: 0.006111\n",
      "[715/00109] train_loss: 0.006062\n",
      "[715/00159] train_loss: 0.006128\n",
      "[715/00209] train_loss: 0.006053\n",
      "[715/00259] train_loss: 0.006146\n",
      "[715/00309] train_loss: 0.006178\n",
      "[715/00359] train_loss: 0.006057\n",
      "[716/00003] train_loss: 0.006102\n",
      "[716/00053] train_loss: 0.006098\n",
      "[716/00103] train_loss: 0.006088\n",
      "[716/00153] train_loss: 0.006112\n",
      "[716/00203] train_loss: 0.006090\n",
      "[716/00253] train_loss: 0.006131\n",
      "[716/00303] train_loss: 0.006140\n",
      "[716/00353] train_loss: 0.006163\n",
      "[716/00403] train_loss: 0.006068\n",
      "[717/00047] train_loss: 0.006077\n",
      "[717/00097] train_loss: 0.006129\n",
      "[717/00147] train_loss: 0.006190\n",
      "[717/00197] train_loss: 0.006058\n",
      "[717/00247] train_loss: 0.006126\n",
      "[717/00297] train_loss: 0.006100\n",
      "[717/00347] train_loss: 0.006095\n",
      "[717/00397] train_loss: 0.006083\n",
      "[718/00041] train_loss: 0.006080\n",
      "[718/00091] train_loss: 0.006091\n",
      "[718/00141] train_loss: 0.006156\n",
      "[718/00191] train_loss: 0.006054\n",
      "[718/00241] train_loss: 0.006196\n",
      "[718/00291] train_loss: 0.006016\n",
      "[718/00341] train_loss: 0.006122\n",
      "[718/00391] train_loss: 0.006007\n",
      "[719/00035] train_loss: 0.006114\n",
      "[719/00085] train_loss: 0.006172\n",
      "[719/00135] train_loss: 0.006085\n",
      "[719/00185] train_loss: 0.006086\n",
      "[719/00235] train_loss: 0.006084\n",
      "[719/00285] train_loss: 0.005958\n",
      "[719/00335] train_loss: 0.006036\n",
      "[719/00385] train_loss: 0.006146\n",
      "[720/00029] train_loss: 0.006147\n",
      "[720/00079] train_loss: 0.006114\n",
      "[720/00129] train_loss: 0.006059\n",
      "[720/00179] train_loss: 0.006079\n",
      "[720/00229] train_loss: 0.006109\n",
      "[720/00279] train_loss: 0.006087\n",
      "[720/00329] train_loss: 0.006078\n",
      "[720/00379] train_loss: 0.005948\n",
      "[721/00023] train_loss: 0.005973\n",
      "[721/00073] train_loss: 0.006109\n",
      "[721/00123] train_loss: 0.006027\n",
      "[721/00173] train_loss: 0.006041\n",
      "[721/00223] train_loss: 0.006154\n",
      "[721/00273] train_loss: 0.006036\n",
      "[721/00323] train_loss: 0.006065\n",
      "[721/00373] train_loss: 0.006092\n",
      "[722/00017] train_loss: 0.006087\n",
      "[722/00067] train_loss: 0.006047\n",
      "[722/00117] train_loss: 0.006106\n",
      "[722/00167] train_loss: 0.006140\n",
      "[722/00217] train_loss: 0.006056\n",
      "[722/00267] train_loss: 0.006118\n",
      "[722/00317] train_loss: 0.006018\n",
      "[722/00367] train_loss: 0.006068\n",
      "[723/00011] train_loss: 0.006102\n",
      "[723/00061] train_loss: 0.006121\n",
      "[723/00111] train_loss: 0.006075\n",
      "[723/00161] train_loss: 0.006024\n",
      "[723/00211] train_loss: 0.006186\n",
      "[723/00261] train_loss: 0.006107\n",
      "[723/00311] train_loss: 0.006163\n",
      "[723/00361] train_loss: 0.006064\n",
      "[724/00005] train_loss: 0.006031\n",
      "[724/00055] train_loss: 0.006037\n",
      "[724/00105] train_loss: 0.006073\n",
      "[724/00155] train_loss: 0.006081\n",
      "[724/00205] train_loss: 0.006088\n",
      "[724/00255] train_loss: 0.006087\n",
      "[724/00305] train_loss: 0.006079\n",
      "[724/00355] train_loss: 0.006163\n",
      "[724/00405] train_loss: 0.006032\n",
      "[725/00049] train_loss: 0.006121\n",
      "[725/00099] train_loss: 0.006150\n",
      "[725/00149] train_loss: 0.006041\n",
      "[725/00199] train_loss: 0.006132\n",
      "[725/00249] train_loss: 0.005986\n",
      "[725/00299] train_loss: 0.006151\n",
      "[725/00349] train_loss: 0.006250\n",
      "[725/00399] train_loss: 0.006122\n",
      "[726/00043] train_loss: 0.006094\n",
      "[726/00093] train_loss: 0.006132\n",
      "[726/00143] train_loss: 0.006024\n",
      "[726/00193] train_loss: 0.006167\n",
      "[726/00243] train_loss: 0.006090\n",
      "[726/00293] train_loss: 0.006123\n",
      "[726/00343] train_loss: 0.006090\n",
      "[726/00393] train_loss: 0.006153\n",
      "[727/00037] train_loss: 0.006082\n",
      "[727/00087] train_loss: 0.006022\n",
      "[727/00137] train_loss: 0.006061\n",
      "[727/00187] train_loss: 0.006043\n",
      "[727/00237] train_loss: 0.006028\n",
      "[727/00287] train_loss: 0.006039\n",
      "[727/00337] train_loss: 0.006149\n",
      "[727/00387] train_loss: 0.006051\n",
      "[728/00031] train_loss: 0.006082\n",
      "[728/00081] train_loss: 0.006079\n",
      "[728/00131] train_loss: 0.006115\n",
      "[728/00181] train_loss: 0.006154\n",
      "[728/00231] train_loss: 0.006108\n",
      "[728/00281] train_loss: 0.006115\n",
      "[728/00331] train_loss: 0.006111\n",
      "[728/00381] train_loss: 0.006216\n",
      "[729/00025] train_loss: 0.006054\n",
      "[729/00075] train_loss: 0.006055\n",
      "[729/00125] train_loss: 0.006133\n",
      "[729/00175] train_loss: 0.006064\n",
      "[729/00225] train_loss: 0.006117\n",
      "[729/00275] train_loss: 0.006056\n",
      "[729/00325] train_loss: 0.005985\n",
      "[729/00375] train_loss: 0.006125\n",
      "[730/00019] train_loss: 0.006098\n",
      "[730/00069] train_loss: 0.006037\n",
      "[730/00119] train_loss: 0.006045\n",
      "[730/00169] train_loss: 0.006089\n",
      "[730/00219] train_loss: 0.006087\n",
      "[730/00269] train_loss: 0.006045\n",
      "[730/00319] train_loss: 0.006023\n",
      "[730/00369] train_loss: 0.006095\n",
      "[731/00013] train_loss: 0.006077\n",
      "[731/00063] train_loss: 0.006026\n",
      "[731/00113] train_loss: 0.006128\n",
      "[731/00163] train_loss: 0.006009\n",
      "[731/00213] train_loss: 0.006052\n",
      "[731/00263] train_loss: 0.006085\n",
      "[731/00313] train_loss: 0.006095\n",
      "[731/00363] train_loss: 0.006130\n",
      "[732/00007] train_loss: 0.006078\n",
      "[732/00057] train_loss: 0.006059\n",
      "[732/00107] train_loss: 0.006185\n",
      "[732/00157] train_loss: 0.006039\n",
      "[732/00207] train_loss: 0.006081\n",
      "[732/00257] train_loss: 0.006138\n",
      "[732/00307] train_loss: 0.006134\n",
      "[732/00357] train_loss: 0.006042\n",
      "[733/00001] train_loss: 0.006089\n",
      "[733/00051] train_loss: 0.006063\n",
      "[733/00101] train_loss: 0.006108\n",
      "[733/00151] train_loss: 0.006060\n",
      "[733/00201] train_loss: 0.006121\n",
      "[733/00251] train_loss: 0.006128\n",
      "[733/00301] train_loss: 0.006011\n",
      "[733/00351] train_loss: 0.006064\n",
      "[733/00401] train_loss: 0.006131\n",
      "[734/00045] train_loss: 0.006117\n",
      "[734/00095] train_loss: 0.006097\n",
      "[734/00145] train_loss: 0.006033\n",
      "[734/00195] train_loss: 0.006120\n",
      "[734/00245] train_loss: 0.006052\n",
      "[734/00295] train_loss: 0.006044\n",
      "[734/00345] train_loss: 0.006129\n",
      "[734/00395] train_loss: 0.006055\n",
      "[735/00039] train_loss: 0.006144\n",
      "[735/00089] train_loss: 0.006156\n",
      "[735/00139] train_loss: 0.006071\n",
      "[735/00189] train_loss: 0.006062\n",
      "[735/00239] train_loss: 0.006117\n",
      "[735/00289] train_loss: 0.006072\n",
      "[735/00339] train_loss: 0.006056\n",
      "[735/00389] train_loss: 0.006099\n",
      "[736/00033] train_loss: 0.006119\n",
      "[736/00083] train_loss: 0.006080\n",
      "[736/00133] train_loss: 0.006091\n",
      "[736/00183] train_loss: 0.006119\n",
      "[736/00233] train_loss: 0.006097\n",
      "[736/00283] train_loss: 0.006111\n",
      "[736/00333] train_loss: 0.006035\n",
      "[736/00383] train_loss: 0.006078\n",
      "[737/00027] train_loss: 0.006093\n",
      "[737/00077] train_loss: 0.006032\n",
      "[737/00127] train_loss: 0.006091\n",
      "[737/00177] train_loss: 0.006018\n",
      "[737/00227] train_loss: 0.006069\n",
      "[737/00277] train_loss: 0.006144\n",
      "[737/00327] train_loss: 0.006010\n",
      "[737/00377] train_loss: 0.006174\n",
      "[738/00021] train_loss: 0.006039\n",
      "[738/00071] train_loss: 0.006074\n",
      "[738/00121] train_loss: 0.006076\n",
      "[738/00171] train_loss: 0.006032\n",
      "[738/00221] train_loss: 0.006161\n",
      "[738/00271] train_loss: 0.006145\n",
      "[738/00321] train_loss: 0.006134\n",
      "[738/00371] train_loss: 0.005990\n",
      "[739/00015] train_loss: 0.006121\n",
      "[739/00065] train_loss: 0.006067\n",
      "[739/00115] train_loss: 0.006133\n",
      "[739/00165] train_loss: 0.006039\n",
      "[739/00215] train_loss: 0.006071\n",
      "[739/00265] train_loss: 0.006086\n",
      "[739/00315] train_loss: 0.006038\n",
      "[739/00365] train_loss: 0.005997\n",
      "[740/00009] train_loss: 0.006064\n",
      "[740/00059] train_loss: 0.006111\n",
      "[740/00109] train_loss: 0.006191\n",
      "[740/00159] train_loss: 0.006059\n",
      "[740/00209] train_loss: 0.006031\n",
      "[740/00259] train_loss: 0.006094\n",
      "[740/00309] train_loss: 0.006069\n",
      "[740/00359] train_loss: 0.006090\n",
      "[741/00003] train_loss: 0.006053\n",
      "[741/00053] train_loss: 0.005988\n",
      "[741/00103] train_loss: 0.006120\n",
      "[741/00153] train_loss: 0.006043\n",
      "[741/00203] train_loss: 0.006101\n",
      "[741/00253] train_loss: 0.006032\n",
      "[741/00303] train_loss: 0.006190\n",
      "[741/00353] train_loss: 0.006119\n",
      "[741/00403] train_loss: 0.006001\n",
      "[742/00047] train_loss: 0.006013\n",
      "[742/00097] train_loss: 0.006204\n",
      "[742/00147] train_loss: 0.006165\n",
      "[742/00197] train_loss: 0.006046\n",
      "[742/00247] train_loss: 0.006040\n",
      "[742/00297] train_loss: 0.006105\n",
      "[742/00347] train_loss: 0.006026\n",
      "[742/00397] train_loss: 0.006085\n",
      "[743/00041] train_loss: 0.006088\n",
      "[743/00091] train_loss: 0.006024\n",
      "[743/00141] train_loss: 0.006054\n",
      "[743/00191] train_loss: 0.006107\n",
      "[743/00241] train_loss: 0.006108\n",
      "[743/00291] train_loss: 0.006089\n",
      "[743/00341] train_loss: 0.006027\n",
      "[743/00391] train_loss: 0.006123\n",
      "[744/00035] train_loss: 0.006111\n",
      "[744/00085] train_loss: 0.006038\n",
      "[744/00135] train_loss: 0.006059\n",
      "[744/00185] train_loss: 0.006126\n",
      "[744/00235] train_loss: 0.006112\n",
      "[744/00285] train_loss: 0.006095\n",
      "[744/00335] train_loss: 0.006130\n",
      "[744/00385] train_loss: 0.006118\n",
      "[745/00029] train_loss: 0.006034\n",
      "[745/00079] train_loss: 0.006077\n",
      "[745/00129] train_loss: 0.006019\n",
      "[745/00179] train_loss: 0.006053\n",
      "[745/00229] train_loss: 0.006117\n",
      "[745/00279] train_loss: 0.006136\n",
      "[745/00329] train_loss: 0.006185\n",
      "[745/00379] train_loss: 0.006139\n",
      "[746/00023] train_loss: 0.006129\n",
      "[746/00073] train_loss: 0.006125\n",
      "[746/00123] train_loss: 0.006061\n",
      "[746/00173] train_loss: 0.006067\n",
      "[746/00223] train_loss: 0.006124\n",
      "[746/00273] train_loss: 0.006096\n",
      "[746/00323] train_loss: 0.006050\n",
      "[746/00373] train_loss: 0.006133\n",
      "[747/00017] train_loss: 0.006081\n",
      "[747/00067] train_loss: 0.006107\n",
      "[747/00117] train_loss: 0.006076\n",
      "[747/00167] train_loss: 0.006098\n",
      "[747/00217] train_loss: 0.006081\n",
      "[747/00267] train_loss: 0.006129\n",
      "[747/00317] train_loss: 0.006115\n",
      "[747/00367] train_loss: 0.006110\n",
      "[748/00011] train_loss: 0.006143\n",
      "[748/00061] train_loss: 0.006146\n",
      "[748/00111] train_loss: 0.006124\n",
      "[748/00161] train_loss: 0.006076\n",
      "[748/00211] train_loss: 0.006087\n",
      "[748/00261] train_loss: 0.006055\n",
      "[748/00311] train_loss: 0.006147\n",
      "[748/00361] train_loss: 0.006109\n",
      "[749/00005] train_loss: 0.006062\n",
      "[749/00055] train_loss: 0.006065\n",
      "[749/00105] train_loss: 0.006073\n",
      "[749/00155] train_loss: 0.006061\n",
      "[749/00205] train_loss: 0.005992\n",
      "[749/00255] train_loss: 0.006167\n",
      "[749/00305] train_loss: 0.006058\n",
      "[749/00355] train_loss: 0.006060\n",
      "[749/00405] train_loss: 0.006072\n",
      "[750/00049] train_loss: 0.006051\n",
      "[750/00099] train_loss: 0.006093\n",
      "[750/00149] train_loss: 0.006105\n",
      "[750/00199] train_loss: 0.006125\n",
      "[750/00249] train_loss: 0.006116\n",
      "[750/00299] train_loss: 0.006041\n",
      "[750/00349] train_loss: 0.006069\n",
      "[750/00399] train_loss: 0.006077\n",
      "[751/00043] train_loss: 0.006067\n",
      "[751/00093] train_loss: 0.006034\n",
      "[751/00143] train_loss: 0.006144\n",
      "[751/00193] train_loss: 0.006061\n",
      "[751/00243] train_loss: 0.006060\n",
      "[751/00293] train_loss: 0.006122\n",
      "[751/00343] train_loss: 0.006141\n",
      "[751/00393] train_loss: 0.006056\n",
      "[752/00037] train_loss: 0.006130\n",
      "[752/00087] train_loss: 0.006120\n",
      "[752/00137] train_loss: 0.006072\n",
      "[752/00187] train_loss: 0.006206\n",
      "[752/00237] train_loss: 0.006073\n",
      "[752/00287] train_loss: 0.006099\n",
      "[752/00337] train_loss: 0.006111\n",
      "[752/00387] train_loss: 0.006175\n",
      "[753/00031] train_loss: 0.006099\n",
      "[753/00081] train_loss: 0.006037\n",
      "[753/00131] train_loss: 0.006152\n",
      "[753/00181] train_loss: 0.006099\n",
      "[753/00231] train_loss: 0.006067\n",
      "[753/00281] train_loss: 0.006131\n",
      "[753/00331] train_loss: 0.006083\n",
      "[753/00381] train_loss: 0.006039\n",
      "[754/00025] train_loss: 0.006089\n",
      "[754/00075] train_loss: 0.006064\n",
      "[754/00125] train_loss: 0.006126\n",
      "[754/00175] train_loss: 0.006100\n",
      "[754/00225] train_loss: 0.006066\n",
      "[754/00275] train_loss: 0.006078\n",
      "[754/00325] train_loss: 0.006088\n",
      "[754/00375] train_loss: 0.006035\n",
      "[755/00019] train_loss: 0.006081\n",
      "[755/00069] train_loss: 0.006134\n",
      "[755/00119] train_loss: 0.006034\n",
      "[755/00169] train_loss: 0.006170\n",
      "[755/00219] train_loss: 0.006066\n",
      "[755/00269] train_loss: 0.006107\n",
      "[755/00319] train_loss: 0.006059\n",
      "[755/00369] train_loss: 0.006029\n",
      "[756/00013] train_loss: 0.006076\n",
      "[756/00063] train_loss: 0.006079\n",
      "[756/00113] train_loss: 0.006088\n",
      "[756/00163] train_loss: 0.006083\n",
      "[756/00213] train_loss: 0.006072\n",
      "[756/00263] train_loss: 0.006102\n",
      "[756/00313] train_loss: 0.006220\n",
      "[756/00363] train_loss: 0.006138\n",
      "[757/00007] train_loss: 0.006139\n",
      "[757/00057] train_loss: 0.006095\n",
      "[757/00107] train_loss: 0.006080\n",
      "[757/00157] train_loss: 0.006082\n",
      "[757/00207] train_loss: 0.006090\n",
      "[757/00257] train_loss: 0.006070\n",
      "[757/00307] train_loss: 0.006041\n",
      "[757/00357] train_loss: 0.006052\n",
      "[758/00001] train_loss: 0.006011\n",
      "[758/00051] train_loss: 0.006060\n",
      "[758/00101] train_loss: 0.006156\n",
      "[758/00151] train_loss: 0.006145\n",
      "[758/00201] train_loss: 0.006007\n",
      "[758/00251] train_loss: 0.006064\n",
      "[758/00301] train_loss: 0.006064\n",
      "[758/00351] train_loss: 0.006145\n",
      "[758/00401] train_loss: 0.006118\n",
      "[759/00045] train_loss: 0.006110\n",
      "[759/00095] train_loss: 0.006012\n",
      "[759/00145] train_loss: 0.006114\n",
      "[759/00195] train_loss: 0.006149\n",
      "[759/00245] train_loss: 0.006104\n",
      "[759/00295] train_loss: 0.006041\n",
      "[759/00345] train_loss: 0.006068\n",
      "[759/00395] train_loss: 0.006016\n",
      "[760/00039] train_loss: 0.006113\n",
      "[760/00089] train_loss: 0.006067\n",
      "[760/00139] train_loss: 0.006138\n",
      "[760/00189] train_loss: 0.006075\n",
      "[760/00239] train_loss: 0.006053\n",
      "[760/00289] train_loss: 0.006053\n",
      "[760/00339] train_loss: 0.006167\n",
      "[760/00389] train_loss: 0.006106\n",
      "[761/00033] train_loss: 0.006072\n",
      "[761/00083] train_loss: 0.006095\n",
      "[761/00133] train_loss: 0.006047\n",
      "[761/00183] train_loss: 0.006156\n",
      "[761/00233] train_loss: 0.006187\n",
      "[761/00283] train_loss: 0.006100\n",
      "[761/00333] train_loss: 0.006073\n",
      "[761/00383] train_loss: 0.006212\n",
      "[762/00027] train_loss: 0.006066\n",
      "[762/00077] train_loss: 0.006120\n",
      "[762/00127] train_loss: 0.006106\n",
      "[762/00177] train_loss: 0.006141\n",
      "[762/00227] train_loss: 0.006111\n",
      "[762/00277] train_loss: 0.006162\n",
      "[762/00327] train_loss: 0.006095\n",
      "[762/00377] train_loss: 0.006085\n",
      "[763/00021] train_loss: 0.006085\n",
      "[763/00071] train_loss: 0.006201\n",
      "[763/00121] train_loss: 0.006107\n",
      "[763/00171] train_loss: 0.006060\n",
      "[763/00221] train_loss: 0.006106\n",
      "[763/00271] train_loss: 0.006046\n",
      "[763/00321] train_loss: 0.006132\n",
      "[763/00371] train_loss: 0.006058\n",
      "[764/00015] train_loss: 0.006012\n",
      "[764/00065] train_loss: 0.006111\n",
      "[764/00115] train_loss: 0.006209\n",
      "[764/00165] train_loss: 0.006053\n",
      "[764/00215] train_loss: 0.006080\n",
      "[764/00265] train_loss: 0.006064\n",
      "[764/00315] train_loss: 0.006197\n",
      "[764/00365] train_loss: 0.005993\n",
      "[765/00009] train_loss: 0.006070\n",
      "[765/00059] train_loss: 0.006131\n",
      "[765/00109] train_loss: 0.006027\n",
      "[765/00159] train_loss: 0.006035\n",
      "[765/00209] train_loss: 0.006004\n",
      "[765/00259] train_loss: 0.006084\n",
      "[765/00309] train_loss: 0.006121\n",
      "[765/00359] train_loss: 0.006133\n",
      "[766/00003] train_loss: 0.006010\n",
      "[766/00053] train_loss: 0.006085\n",
      "[766/00103] train_loss: 0.006113\n",
      "[766/00153] train_loss: 0.006073\n",
      "[766/00203] train_loss: 0.006068\n",
      "[766/00253] train_loss: 0.006077\n",
      "[766/00303] train_loss: 0.006062\n",
      "[766/00353] train_loss: 0.006092\n",
      "[766/00403] train_loss: 0.006066\n",
      "[767/00047] train_loss: 0.006123\n",
      "[767/00097] train_loss: 0.006165\n",
      "[767/00147] train_loss: 0.006125\n",
      "[767/00197] train_loss: 0.006128\n",
      "[767/00247] train_loss: 0.006046\n",
      "[767/00297] train_loss: 0.006128\n",
      "[767/00347] train_loss: 0.006093\n",
      "[767/00397] train_loss: 0.006171\n",
      "[768/00041] train_loss: 0.006180\n",
      "[768/00091] train_loss: 0.006110\n",
      "[768/00141] train_loss: 0.006079\n",
      "[768/00191] train_loss: 0.006086\n",
      "[768/00241] train_loss: 0.006158\n",
      "[768/00291] train_loss: 0.006124\n",
      "[768/00341] train_loss: 0.006049\n",
      "[768/00391] train_loss: 0.006052\n",
      "[769/00035] train_loss: 0.006165\n",
      "[769/00085] train_loss: 0.006130\n",
      "[769/00135] train_loss: 0.006122\n",
      "[769/00185] train_loss: 0.005994\n",
      "[769/00235] train_loss: 0.006075\n",
      "[769/00285] train_loss: 0.006124\n",
      "[769/00335] train_loss: 0.006176\n",
      "[769/00385] train_loss: 0.006106\n",
      "[770/00029] train_loss: 0.006161\n",
      "[770/00079] train_loss: 0.006103\n",
      "[770/00129] train_loss: 0.006105\n",
      "[770/00179] train_loss: 0.006112\n",
      "[770/00229] train_loss: 0.006160\n",
      "[770/00279] train_loss: 0.005998\n",
      "[770/00329] train_loss: 0.006095\n",
      "[770/00379] train_loss: 0.006099\n",
      "[771/00023] train_loss: 0.006098\n",
      "[771/00073] train_loss: 0.006050\n",
      "[771/00123] train_loss: 0.006081\n",
      "[771/00173] train_loss: 0.006116\n",
      "[771/00223] train_loss: 0.006115\n",
      "[771/00273] train_loss: 0.006151\n",
      "[771/00323] train_loss: 0.006124\n",
      "[771/00373] train_loss: 0.006105\n",
      "[772/00017] train_loss: 0.006127\n",
      "[772/00067] train_loss: 0.006067\n",
      "[772/00117] train_loss: 0.006071\n",
      "[772/00167] train_loss: 0.006142\n",
      "[772/00217] train_loss: 0.006110\n",
      "[772/00267] train_loss: 0.006052\n",
      "[772/00317] train_loss: 0.006020\n",
      "[772/00367] train_loss: 0.006065\n",
      "[773/00011] train_loss: 0.006091\n",
      "[773/00061] train_loss: 0.006174\n",
      "[773/00111] train_loss: 0.006060\n",
      "[773/00161] train_loss: 0.006136\n",
      "[773/00211] train_loss: 0.006063\n",
      "[773/00261] train_loss: 0.006162\n",
      "[773/00311] train_loss: 0.006025\n",
      "[773/00361] train_loss: 0.006119\n",
      "[774/00005] train_loss: 0.006119\n",
      "[774/00055] train_loss: 0.006115\n",
      "[774/00105] train_loss: 0.006016\n",
      "[774/00155] train_loss: 0.006082\n",
      "[774/00205] train_loss: 0.006018\n",
      "[774/00255] train_loss: 0.006062\n",
      "[774/00305] train_loss: 0.006074\n",
      "[774/00355] train_loss: 0.006058\n",
      "[774/00405] train_loss: 0.006132\n",
      "[775/00049] train_loss: 0.006011\n",
      "[775/00099] train_loss: 0.005995\n",
      "[775/00149] train_loss: 0.006038\n",
      "[775/00199] train_loss: 0.006159\n",
      "[775/00249] train_loss: 0.006040\n",
      "[775/00299] train_loss: 0.006182\n",
      "[775/00349] train_loss: 0.006120\n",
      "[775/00399] train_loss: 0.006072\n",
      "[776/00043] train_loss: 0.006001\n",
      "[776/00093] train_loss: 0.006125\n",
      "[776/00143] train_loss: 0.005941\n",
      "[776/00193] train_loss: 0.006093\n",
      "[776/00243] train_loss: 0.006186\n",
      "[776/00293] train_loss: 0.006106\n",
      "[776/00343] train_loss: 0.006042\n",
      "[776/00393] train_loss: 0.006135\n",
      "[777/00037] train_loss: 0.006034\n",
      "[777/00087] train_loss: 0.006155\n",
      "[777/00137] train_loss: 0.006021\n",
      "[777/00187] train_loss: 0.006090\n",
      "[777/00237] train_loss: 0.006122\n",
      "[777/00287] train_loss: 0.006033\n",
      "[777/00337] train_loss: 0.006120\n",
      "[777/00387] train_loss: 0.006069\n",
      "[778/00031] train_loss: 0.006087\n",
      "[778/00081] train_loss: 0.006095\n",
      "[778/00131] train_loss: 0.006162\n",
      "[778/00181] train_loss: 0.006087\n",
      "[778/00231] train_loss: 0.006193\n",
      "[778/00281] train_loss: 0.006151\n",
      "[778/00331] train_loss: 0.006050\n",
      "[778/00381] train_loss: 0.006034\n",
      "[779/00025] train_loss: 0.006042\n",
      "[779/00075] train_loss: 0.006160\n",
      "[779/00125] train_loss: 0.006049\n",
      "[779/00175] train_loss: 0.006056\n",
      "[779/00225] train_loss: 0.006105\n",
      "[779/00275] train_loss: 0.006101\n",
      "[779/00325] train_loss: 0.006063\n",
      "[779/00375] train_loss: 0.006089\n",
      "[780/00019] train_loss: 0.006035\n",
      "[780/00069] train_loss: 0.006093\n",
      "[780/00119] train_loss: 0.006157\n",
      "[780/00169] train_loss: 0.006060\n",
      "[780/00219] train_loss: 0.006132\n",
      "[780/00269] train_loss: 0.006136\n",
      "[780/00319] train_loss: 0.006023\n",
      "[780/00369] train_loss: 0.006129\n",
      "[781/00013] train_loss: 0.006168\n",
      "[781/00063] train_loss: 0.006098\n",
      "[781/00113] train_loss: 0.006081\n",
      "[781/00163] train_loss: 0.006141\n",
      "[781/00213] train_loss: 0.006089\n",
      "[781/00263] train_loss: 0.006134\n",
      "[781/00313] train_loss: 0.006100\n",
      "[781/00363] train_loss: 0.006082\n",
      "[782/00007] train_loss: 0.006134\n",
      "[782/00057] train_loss: 0.006199\n",
      "[782/00107] train_loss: 0.006041\n",
      "[782/00157] train_loss: 0.006143\n",
      "[782/00207] train_loss: 0.006027\n",
      "[782/00257] train_loss: 0.006117\n",
      "[782/00307] train_loss: 0.006048\n",
      "[782/00357] train_loss: 0.006059\n",
      "[783/00001] train_loss: 0.006085\n",
      "[783/00051] train_loss: 0.006079\n",
      "[783/00101] train_loss: 0.006171\n",
      "[783/00151] train_loss: 0.006088\n",
      "[783/00201] train_loss: 0.006054\n",
      "[783/00251] train_loss: 0.006050\n",
      "[783/00301] train_loss: 0.006044\n",
      "[783/00351] train_loss: 0.006213\n",
      "[783/00401] train_loss: 0.006078\n",
      "[784/00045] train_loss: 0.006043\n",
      "[784/00095] train_loss: 0.006063\n",
      "[784/00145] train_loss: 0.006134\n",
      "[784/00195] train_loss: 0.006072\n",
      "[784/00245] train_loss: 0.006037\n",
      "[784/00295] train_loss: 0.006129\n",
      "[784/00345] train_loss: 0.006152\n",
      "[784/00395] train_loss: 0.006130\n",
      "[785/00039] train_loss: 0.006090\n",
      "[785/00089] train_loss: 0.005990\n",
      "[785/00139] train_loss: 0.006097\n",
      "[785/00189] train_loss: 0.006107\n",
      "[785/00239] train_loss: 0.006116\n",
      "[785/00289] train_loss: 0.006092\n",
      "[785/00339] train_loss: 0.006069\n",
      "[785/00389] train_loss: 0.006081\n",
      "[786/00033] train_loss: 0.006054\n",
      "[786/00083] train_loss: 0.006054\n",
      "[786/00133] train_loss: 0.006178\n",
      "[786/00183] train_loss: 0.006083\n",
      "[786/00233] train_loss: 0.006105\n",
      "[786/00283] train_loss: 0.006047\n",
      "[786/00333] train_loss: 0.006153\n",
      "[786/00383] train_loss: 0.006114\n",
      "[787/00027] train_loss: 0.006033\n",
      "[787/00077] train_loss: 0.006117\n",
      "[787/00127] train_loss: 0.006063\n",
      "[787/00177] train_loss: 0.006110\n",
      "[787/00227] train_loss: 0.006084\n",
      "[787/00277] train_loss: 0.006143\n",
      "[787/00327] train_loss: 0.005988\n",
      "[787/00377] train_loss: 0.006059\n",
      "[788/00021] train_loss: 0.006123\n",
      "[788/00071] train_loss: 0.006102\n",
      "[788/00121] train_loss: 0.006115\n",
      "[788/00171] train_loss: 0.006194\n",
      "[788/00221] train_loss: 0.006184\n",
      "[788/00271] train_loss: 0.006090\n",
      "[788/00321] train_loss: 0.006005\n",
      "[788/00371] train_loss: 0.006071\n",
      "[789/00015] train_loss: 0.006073\n",
      "[789/00065] train_loss: 0.006088\n",
      "[789/00115] train_loss: 0.006020\n",
      "[789/00165] train_loss: 0.006156\n",
      "[789/00215] train_loss: 0.006128\n",
      "[789/00265] train_loss: 0.006115\n",
      "[789/00315] train_loss: 0.006125\n",
      "[789/00365] train_loss: 0.006024\n",
      "[790/00009] train_loss: 0.006103\n",
      "[790/00059] train_loss: 0.006042\n",
      "[790/00109] train_loss: 0.006155\n",
      "[790/00159] train_loss: 0.006062\n",
      "[790/00209] train_loss: 0.006137\n",
      "[790/00259] train_loss: 0.006086\n",
      "[790/00309] train_loss: 0.006121\n",
      "[790/00359] train_loss: 0.006105\n",
      "[791/00003] train_loss: 0.006146\n",
      "[791/00053] train_loss: 0.006113\n",
      "[791/00103] train_loss: 0.006158\n",
      "[791/00153] train_loss: 0.006158\n",
      "[791/00203] train_loss: 0.006051\n",
      "[791/00253] train_loss: 0.006038\n",
      "[791/00303] train_loss: 0.006146\n",
      "[791/00353] train_loss: 0.006094\n",
      "[791/00403] train_loss: 0.006076\n",
      "[792/00047] train_loss: 0.006124\n",
      "[792/00097] train_loss: 0.006079\n",
      "[792/00147] train_loss: 0.006095\n",
      "[792/00197] train_loss: 0.006100\n",
      "[792/00247] train_loss: 0.006065\n",
      "[792/00297] train_loss: 0.006115\n",
      "[792/00347] train_loss: 0.006080\n",
      "[792/00397] train_loss: 0.006028\n",
      "[793/00041] train_loss: 0.006088\n",
      "[793/00091] train_loss: 0.006200\n",
      "[793/00141] train_loss: 0.006068\n",
      "[793/00191] train_loss: 0.006060\n",
      "[793/00241] train_loss: 0.006133\n",
      "[793/00291] train_loss: 0.006108\n",
      "[793/00341] train_loss: 0.006152\n",
      "[793/00391] train_loss: 0.006048\n",
      "[794/00035] train_loss: 0.006012\n",
      "[794/00085] train_loss: 0.006128\n",
      "[794/00135] train_loss: 0.006059\n",
      "[794/00185] train_loss: 0.006103\n",
      "[794/00235] train_loss: 0.006120\n",
      "[794/00285] train_loss: 0.006103\n",
      "[794/00335] train_loss: 0.006122\n",
      "[794/00385] train_loss: 0.006090\n",
      "[795/00029] train_loss: 0.006140\n",
      "[795/00079] train_loss: 0.006101\n",
      "[795/00129] train_loss: 0.006072\n",
      "[795/00179] train_loss: 0.006119\n",
      "[795/00229] train_loss: 0.006073\n",
      "[795/00279] train_loss: 0.006019\n",
      "[795/00329] train_loss: 0.006022\n",
      "[795/00379] train_loss: 0.006158\n",
      "[796/00023] train_loss: 0.006034\n",
      "[796/00073] train_loss: 0.006156\n",
      "[796/00123] train_loss: 0.006102\n",
      "[796/00173] train_loss: 0.006105\n",
      "[796/00223] train_loss: 0.006115\n",
      "[796/00273] train_loss: 0.006088\n",
      "[796/00323] train_loss: 0.006091\n",
      "[796/00373] train_loss: 0.006040\n",
      "[797/00017] train_loss: 0.006119\n",
      "[797/00067] train_loss: 0.006096\n",
      "[797/00117] train_loss: 0.006052\n",
      "[797/00167] train_loss: 0.006113\n",
      "[797/00217] train_loss: 0.006095\n",
      "[797/00267] train_loss: 0.006023\n",
      "[797/00317] train_loss: 0.006031\n",
      "[797/00367] train_loss: 0.006086\n",
      "[798/00011] train_loss: 0.006165\n",
      "[798/00061] train_loss: 0.005981\n",
      "[798/00111] train_loss: 0.006112\n",
      "[798/00161] train_loss: 0.006043\n",
      "[798/00211] train_loss: 0.006063\n",
      "[798/00261] train_loss: 0.006061\n",
      "[798/00311] train_loss: 0.006048\n",
      "[798/00361] train_loss: 0.006102\n",
      "[799/00005] train_loss: 0.006138\n",
      "[799/00055] train_loss: 0.006060\n",
      "[799/00105] train_loss: 0.006075\n",
      "[799/00155] train_loss: 0.006152\n",
      "[799/00205] train_loss: 0.006099\n",
      "[799/00255] train_loss: 0.006134\n",
      "[799/00305] train_loss: 0.006170\n",
      "[799/00355] train_loss: 0.006036\n",
      "[799/00405] train_loss: 0.006081\n",
      "[800/00049] train_loss: 0.006094\n",
      "[800/00099] train_loss: 0.006076\n",
      "[800/00149] train_loss: 0.006046\n",
      "[800/00199] train_loss: 0.006163\n",
      "[800/00249] train_loss: 0.006141\n",
      "[800/00299] train_loss: 0.006107\n",
      "[800/00349] train_loss: 0.006163\n",
      "[800/00399] train_loss: 0.006125\n",
      "[801/00043] train_loss: 0.006106\n",
      "[801/00093] train_loss: 0.006004\n",
      "[801/00143] train_loss: 0.006175\n",
      "[801/00193] train_loss: 0.006154\n",
      "[801/00243] train_loss: 0.006021\n",
      "[801/00293] train_loss: 0.006051\n",
      "[801/00343] train_loss: 0.006168\n",
      "[801/00393] train_loss: 0.006165\n",
      "[802/00037] train_loss: 0.006046\n",
      "[802/00087] train_loss: 0.006039\n",
      "[802/00137] train_loss: 0.006083\n",
      "[802/00187] train_loss: 0.006051\n",
      "[802/00237] train_loss: 0.006060\n",
      "[802/00287] train_loss: 0.006124\n",
      "[802/00337] train_loss: 0.006093\n",
      "[802/00387] train_loss: 0.006088\n",
      "[803/00031] train_loss: 0.006036\n",
      "[803/00081] train_loss: 0.006064\n",
      "[803/00131] train_loss: 0.006120\n",
      "[803/00181] train_loss: 0.006073\n",
      "[803/00231] train_loss: 0.006107\n",
      "[803/00281] train_loss: 0.006103\n",
      "[803/00331] train_loss: 0.006045\n",
      "[803/00381] train_loss: 0.006070\n",
      "[804/00025] train_loss: 0.005987\n",
      "[804/00075] train_loss: 0.006116\n",
      "[804/00125] train_loss: 0.006083\n",
      "[804/00175] train_loss: 0.006051\n",
      "[804/00225] train_loss: 0.006115\n",
      "[804/00275] train_loss: 0.006135\n",
      "[804/00325] train_loss: 0.006090\n",
      "[804/00375] train_loss: 0.006141\n",
      "[805/00019] train_loss: 0.006129\n",
      "[805/00069] train_loss: 0.006109\n",
      "[805/00119] train_loss: 0.006035\n",
      "[805/00169] train_loss: 0.006204\n",
      "[805/00219] train_loss: 0.006068\n",
      "[805/00269] train_loss: 0.006075\n",
      "[805/00319] train_loss: 0.006150\n",
      "[805/00369] train_loss: 0.005983\n",
      "[806/00013] train_loss: 0.006146\n",
      "[806/00063] train_loss: 0.006051\n",
      "[806/00113] train_loss: 0.006092\n",
      "[806/00163] train_loss: 0.006115\n",
      "[806/00213] train_loss: 0.006123\n",
      "[806/00263] train_loss: 0.006076\n",
      "[806/00313] train_loss: 0.006035\n",
      "[806/00363] train_loss: 0.006108\n",
      "[807/00007] train_loss: 0.006044\n",
      "[807/00057] train_loss: 0.006020\n",
      "[807/00107] train_loss: 0.006132\n",
      "[807/00157] train_loss: 0.006044\n",
      "[807/00207] train_loss: 0.006101\n",
      "[807/00257] train_loss: 0.006161\n",
      "[807/00307] train_loss: 0.006114\n",
      "[807/00357] train_loss: 0.006090\n",
      "[808/00001] train_loss: 0.006067\n",
      "[808/00051] train_loss: 0.005994\n",
      "[808/00101] train_loss: 0.006106\n",
      "[808/00151] train_loss: 0.006075\n",
      "[808/00201] train_loss: 0.006074\n",
      "[808/00251] train_loss: 0.006028\n",
      "[808/00301] train_loss: 0.006064\n",
      "[808/00351] train_loss: 0.006112\n",
      "[808/00401] train_loss: 0.006094\n",
      "[809/00045] train_loss: 0.006112\n",
      "[809/00095] train_loss: 0.006118\n",
      "[809/00145] train_loss: 0.006030\n",
      "[809/00195] train_loss: 0.006063\n",
      "[809/00245] train_loss: 0.006155\n",
      "[809/00295] train_loss: 0.006108\n",
      "[809/00345] train_loss: 0.006119\n",
      "[809/00395] train_loss: 0.006119\n",
      "[810/00039] train_loss: 0.005975\n",
      "[810/00089] train_loss: 0.006028\n",
      "[810/00139] train_loss: 0.006162\n",
      "[810/00189] train_loss: 0.006110\n",
      "[810/00239] train_loss: 0.006071\n",
      "[810/00289] train_loss: 0.006078\n",
      "[810/00339] train_loss: 0.006105\n",
      "[810/00389] train_loss: 0.006148\n",
      "[811/00033] train_loss: 0.006166\n",
      "[811/00083] train_loss: 0.006037\n",
      "[811/00133] train_loss: 0.006172\n",
      "[811/00183] train_loss: 0.006099\n",
      "[811/00233] train_loss: 0.006022\n",
      "[811/00283] train_loss: 0.005999\n",
      "[811/00333] train_loss: 0.006121\n",
      "[811/00383] train_loss: 0.006069\n",
      "[812/00027] train_loss: 0.006032\n",
      "[812/00077] train_loss: 0.006049\n",
      "[812/00127] train_loss: 0.006185\n",
      "[812/00177] train_loss: 0.006069\n",
      "[812/00227] train_loss: 0.006197\n",
      "[812/00277] train_loss: 0.005996\n",
      "[812/00327] train_loss: 0.006148\n",
      "[812/00377] train_loss: 0.006160\n",
      "[813/00021] train_loss: 0.006093\n",
      "[813/00071] train_loss: 0.006098\n",
      "[813/00121] train_loss: 0.006088\n",
      "[813/00171] train_loss: 0.006094\n",
      "[813/00221] train_loss: 0.006058\n",
      "[813/00271] train_loss: 0.006059\n",
      "[813/00321] train_loss: 0.006082\n",
      "[813/00371] train_loss: 0.006084\n",
      "[814/00015] train_loss: 0.006151\n",
      "[814/00065] train_loss: 0.006113\n",
      "[814/00115] train_loss: 0.006110\n",
      "[814/00165] train_loss: 0.006060\n",
      "[814/00215] train_loss: 0.006045\n",
      "[814/00265] train_loss: 0.005998\n",
      "[814/00315] train_loss: 0.006056\n",
      "[814/00365] train_loss: 0.006107\n",
      "[815/00009] train_loss: 0.006187\n",
      "[815/00059] train_loss: 0.006081\n",
      "[815/00109] train_loss: 0.006034\n",
      "[815/00159] train_loss: 0.006059\n",
      "[815/00209] train_loss: 0.006032\n",
      "[815/00259] train_loss: 0.006111\n",
      "[815/00309] train_loss: 0.006153\n",
      "[815/00359] train_loss: 0.006148\n",
      "[816/00003] train_loss: 0.006188\n",
      "[816/00053] train_loss: 0.006133\n",
      "[816/00103] train_loss: 0.006109\n",
      "[816/00153] train_loss: 0.006011\n",
      "[816/00203] train_loss: 0.006070\n",
      "[816/00253] train_loss: 0.006175\n",
      "[816/00303] train_loss: 0.006102\n",
      "[816/00353] train_loss: 0.006060\n",
      "[816/00403] train_loss: 0.006074\n",
      "[817/00047] train_loss: 0.006156\n",
      "[817/00097] train_loss: 0.006125\n",
      "[817/00147] train_loss: 0.006147\n",
      "[817/00197] train_loss: 0.006126\n",
      "[817/00247] train_loss: 0.006101\n",
      "[817/00297] train_loss: 0.006142\n",
      "[817/00347] train_loss: 0.006155\n",
      "[817/00397] train_loss: 0.006095\n",
      "[818/00041] train_loss: 0.006042\n",
      "[818/00091] train_loss: 0.006112\n",
      "[818/00141] train_loss: 0.006162\n",
      "[818/00191] train_loss: 0.006111\n",
      "[818/00241] train_loss: 0.006011\n",
      "[818/00291] train_loss: 0.006153\n",
      "[818/00341] train_loss: 0.006066\n",
      "[818/00391] train_loss: 0.006138\n",
      "[819/00035] train_loss: 0.006086\n",
      "[819/00085] train_loss: 0.006129\n",
      "[819/00135] train_loss: 0.006124\n",
      "[819/00185] train_loss: 0.006099\n",
      "[819/00235] train_loss: 0.006111\n",
      "[819/00285] train_loss: 0.006223\n",
      "[819/00335] train_loss: 0.006084\n",
      "[819/00385] train_loss: 0.006060\n",
      "[820/00029] train_loss: 0.006040\n",
      "[820/00079] train_loss: 0.006115\n",
      "[820/00129] train_loss: 0.006139\n",
      "[820/00179] train_loss: 0.006038\n",
      "[820/00229] train_loss: 0.006084\n",
      "[820/00279] train_loss: 0.006092\n",
      "[820/00329] train_loss: 0.006167\n",
      "[820/00379] train_loss: 0.006037\n",
      "[821/00023] train_loss: 0.006177\n",
      "[821/00073] train_loss: 0.006044\n",
      "[821/00123] train_loss: 0.006066\n",
      "[821/00173] train_loss: 0.006107\n",
      "[821/00223] train_loss: 0.006094\n",
      "[821/00273] train_loss: 0.006067\n",
      "[821/00323] train_loss: 0.006079\n",
      "[821/00373] train_loss: 0.006121\n",
      "[822/00017] train_loss: 0.006060\n",
      "[822/00067] train_loss: 0.006102\n",
      "[822/00117] train_loss: 0.006189\n",
      "[822/00167] train_loss: 0.006067\n",
      "[822/00217] train_loss: 0.006164\n",
      "[822/00267] train_loss: 0.006070\n",
      "[822/00317] train_loss: 0.006117\n",
      "[822/00367] train_loss: 0.006144\n",
      "[823/00011] train_loss: 0.006005\n",
      "[823/00061] train_loss: 0.006065\n",
      "[823/00111] train_loss: 0.006047\n",
      "[823/00161] train_loss: 0.006114\n",
      "[823/00211] train_loss: 0.006066\n",
      "[823/00261] train_loss: 0.006141\n",
      "[823/00311] train_loss: 0.006056\n",
      "[823/00361] train_loss: 0.006087\n",
      "[824/00005] train_loss: 0.006041\n",
      "[824/00055] train_loss: 0.006036\n",
      "[824/00105] train_loss: 0.006117\n",
      "[824/00155] train_loss: 0.006131\n",
      "[824/00205] train_loss: 0.006068\n",
      "[824/00255] train_loss: 0.006105\n",
      "[824/00305] train_loss: 0.006013\n",
      "[824/00355] train_loss: 0.006084\n",
      "[824/00405] train_loss: 0.006091\n",
      "[825/00049] train_loss: 0.006105\n",
      "[825/00099] train_loss: 0.006109\n",
      "[825/00149] train_loss: 0.006097\n",
      "[825/00199] train_loss: 0.006096\n",
      "[825/00249] train_loss: 0.006136\n",
      "[825/00299] train_loss: 0.006159\n",
      "[825/00349] train_loss: 0.005960\n",
      "[825/00399] train_loss: 0.006149\n",
      "[826/00043] train_loss: 0.006069\n",
      "[826/00093] train_loss: 0.006058\n",
      "[826/00143] train_loss: 0.006110\n",
      "[826/00193] train_loss: 0.006082\n",
      "[826/00243] train_loss: 0.006128\n",
      "[826/00293] train_loss: 0.006112\n",
      "[826/00343] train_loss: 0.006087\n",
      "[826/00393] train_loss: 0.006110\n",
      "[827/00037] train_loss: 0.006119\n",
      "[827/00087] train_loss: 0.006132\n",
      "[827/00137] train_loss: 0.006180\n",
      "[827/00187] train_loss: 0.006047\n",
      "[827/00237] train_loss: 0.006077\n",
      "[827/00287] train_loss: 0.006176\n",
      "[827/00337] train_loss: 0.006077\n",
      "[827/00387] train_loss: 0.006062\n",
      "[828/00031] train_loss: 0.006153\n",
      "[828/00081] train_loss: 0.006135\n",
      "[828/00131] train_loss: 0.006100\n",
      "[828/00181] train_loss: 0.006118\n",
      "[828/00231] train_loss: 0.006075\n",
      "[828/00281] train_loss: 0.006121\n",
      "[828/00331] train_loss: 0.006081\n",
      "[828/00381] train_loss: 0.006090\n",
      "[829/00025] train_loss: 0.006179\n",
      "[829/00075] train_loss: 0.006040\n",
      "[829/00125] train_loss: 0.006089\n",
      "[829/00175] train_loss: 0.006086\n",
      "[829/00225] train_loss: 0.006149\n",
      "[829/00275] train_loss: 0.006147\n",
      "[829/00325] train_loss: 0.006089\n",
      "[829/00375] train_loss: 0.006058\n",
      "[830/00019] train_loss: 0.006047\n",
      "[830/00069] train_loss: 0.006099\n",
      "[830/00119] train_loss: 0.006152\n",
      "[830/00169] train_loss: 0.006073\n",
      "[830/00219] train_loss: 0.006102\n",
      "[830/00269] train_loss: 0.006035\n",
      "[830/00319] train_loss: 0.006141\n",
      "[830/00369] train_loss: 0.005979\n",
      "[831/00013] train_loss: 0.006034\n",
      "[831/00063] train_loss: 0.006096\n",
      "[831/00113] train_loss: 0.006033\n",
      "[831/00163] train_loss: 0.006194\n",
      "[831/00213] train_loss: 0.006149\n",
      "[831/00263] train_loss: 0.006084\n",
      "[831/00313] train_loss: 0.006099\n",
      "[831/00363] train_loss: 0.006056\n",
      "[832/00007] train_loss: 0.006062\n",
      "[832/00057] train_loss: 0.006006\n",
      "[832/00107] train_loss: 0.006048\n",
      "[832/00157] train_loss: 0.006116\n",
      "[832/00207] train_loss: 0.006158\n",
      "[832/00257] train_loss: 0.006089\n",
      "[832/00307] train_loss: 0.006122\n",
      "[832/00357] train_loss: 0.006144\n",
      "[833/00001] train_loss: 0.006071\n",
      "[833/00051] train_loss: 0.006107\n",
      "[833/00101] train_loss: 0.006146\n",
      "[833/00151] train_loss: 0.006048\n",
      "[833/00201] train_loss: 0.006028\n",
      "[833/00251] train_loss: 0.006053\n",
      "[833/00301] train_loss: 0.006120\n",
      "[833/00351] train_loss: 0.005993\n",
      "[833/00401] train_loss: 0.006082\n",
      "[834/00045] train_loss: 0.005993\n",
      "[834/00095] train_loss: 0.006066\n",
      "[834/00145] train_loss: 0.006137\n",
      "[834/00195] train_loss: 0.006107\n",
      "[834/00245] train_loss: 0.006082\n",
      "[834/00295] train_loss: 0.006120\n",
      "[834/00345] train_loss: 0.006073\n",
      "[834/00395] train_loss: 0.006084\n",
      "[835/00039] train_loss: 0.006211\n",
      "[835/00089] train_loss: 0.006084\n",
      "[835/00139] train_loss: 0.006057\n",
      "[835/00189] train_loss: 0.006162\n",
      "[835/00239] train_loss: 0.006126\n",
      "[835/00289] train_loss: 0.006071\n",
      "[835/00339] train_loss: 0.006050\n",
      "[835/00389] train_loss: 0.006046\n",
      "[836/00033] train_loss: 0.006139\n",
      "[836/00083] train_loss: 0.005995\n",
      "[836/00133] train_loss: 0.006059\n",
      "[836/00183] train_loss: 0.006160\n",
      "[836/00233] train_loss: 0.006082\n",
      "[836/00283] train_loss: 0.006062\n",
      "[836/00333] train_loss: 0.006134\n",
      "[836/00383] train_loss: 0.006028\n",
      "[837/00027] train_loss: 0.006183\n",
      "[837/00077] train_loss: 0.006075\n",
      "[837/00127] train_loss: 0.006158\n",
      "[837/00177] train_loss: 0.006104\n",
      "[837/00227] train_loss: 0.005989\n",
      "[837/00277] train_loss: 0.006024\n",
      "[837/00327] train_loss: 0.006069\n",
      "[837/00377] train_loss: 0.006104\n",
      "[838/00021] train_loss: 0.006145\n",
      "[838/00071] train_loss: 0.006165\n",
      "[838/00121] train_loss: 0.006133\n",
      "[838/00171] train_loss: 0.006123\n",
      "[838/00221] train_loss: 0.006158\n",
      "[838/00271] train_loss: 0.006090\n",
      "[838/00321] train_loss: 0.006088\n",
      "[838/00371] train_loss: 0.006162\n",
      "[839/00015] train_loss: 0.005959\n",
      "[839/00065] train_loss: 0.006118\n",
      "[839/00115] train_loss: 0.006017\n",
      "[839/00165] train_loss: 0.006176\n",
      "[839/00215] train_loss: 0.006109\n",
      "[839/00265] train_loss: 0.006020\n",
      "[839/00315] train_loss: 0.006105\n",
      "[839/00365] train_loss: 0.006084\n",
      "[840/00009] train_loss: 0.006107\n",
      "[840/00059] train_loss: 0.006075\n",
      "[840/00109] train_loss: 0.006113\n",
      "[840/00159] train_loss: 0.006185\n",
      "[840/00209] train_loss: 0.006053\n",
      "[840/00259] train_loss: 0.006085\n",
      "[840/00309] train_loss: 0.005993\n",
      "[840/00359] train_loss: 0.006143\n",
      "[841/00003] train_loss: 0.006200\n",
      "[841/00053] train_loss: 0.006071\n",
      "[841/00103] train_loss: 0.006050\n",
      "[841/00153] train_loss: 0.006019\n",
      "[841/00203] train_loss: 0.006152\n",
      "[841/00253] train_loss: 0.006145\n",
      "[841/00303] train_loss: 0.006080\n",
      "[841/00353] train_loss: 0.006089\n",
      "[841/00403] train_loss: 0.006149\n",
      "[842/00047] train_loss: 0.006103\n",
      "[842/00097] train_loss: 0.006117\n",
      "[842/00147] train_loss: 0.006110\n",
      "[842/00197] train_loss: 0.006061\n",
      "[842/00247] train_loss: 0.006103\n",
      "[842/00297] train_loss: 0.006116\n",
      "[842/00347] train_loss: 0.006137\n",
      "[842/00397] train_loss: 0.005995\n",
      "[843/00041] train_loss: 0.006105\n",
      "[843/00091] train_loss: 0.006040\n",
      "[843/00141] train_loss: 0.006038\n",
      "[843/00191] train_loss: 0.006057\n",
      "[843/00241] train_loss: 0.005945\n",
      "[843/00291] train_loss: 0.006055\n",
      "[843/00341] train_loss: 0.006041\n",
      "[843/00391] train_loss: 0.006129\n",
      "[844/00035] train_loss: 0.006058\n",
      "[844/00085] train_loss: 0.006023\n",
      "[844/00135] train_loss: 0.006118\n",
      "[844/00185] train_loss: 0.006076\n",
      "[844/00235] train_loss: 0.006118\n",
      "[844/00285] train_loss: 0.005999\n",
      "[844/00335] train_loss: 0.006102\n",
      "[844/00385] train_loss: 0.006166\n",
      "[845/00029] train_loss: 0.006040\n",
      "[845/00079] train_loss: 0.006144\n",
      "[845/00129] train_loss: 0.006086\n",
      "[845/00179] train_loss: 0.006109\n",
      "[845/00229] train_loss: 0.006118\n",
      "[845/00279] train_loss: 0.006145\n",
      "[845/00329] train_loss: 0.006011\n",
      "[845/00379] train_loss: 0.006059\n",
      "[846/00023] train_loss: 0.006063\n",
      "[846/00073] train_loss: 0.006166\n",
      "[846/00123] train_loss: 0.006086\n",
      "[846/00173] train_loss: 0.006086\n",
      "[846/00223] train_loss: 0.006141\n",
      "[846/00273] train_loss: 0.006088\n",
      "[846/00323] train_loss: 0.006103\n",
      "[846/00373] train_loss: 0.006071\n",
      "[847/00017] train_loss: 0.006074\n",
      "[847/00067] train_loss: 0.006031\n",
      "[847/00117] train_loss: 0.006110\n",
      "[847/00167] train_loss: 0.006112\n",
      "[847/00217] train_loss: 0.006094\n",
      "[847/00267] train_loss: 0.006168\n",
      "[847/00317] train_loss: 0.006048\n",
      "[847/00367] train_loss: 0.006149\n",
      "[848/00011] train_loss: 0.006181\n",
      "[848/00061] train_loss: 0.006062\n",
      "[848/00111] train_loss: 0.006030\n",
      "[848/00161] train_loss: 0.006158\n",
      "[848/00211] train_loss: 0.006060\n",
      "[848/00261] train_loss: 0.006141\n",
      "[848/00311] train_loss: 0.006024\n",
      "[848/00361] train_loss: 0.006116\n",
      "[849/00005] train_loss: 0.006055\n",
      "[849/00055] train_loss: 0.006055\n",
      "[849/00105] train_loss: 0.006111\n",
      "[849/00155] train_loss: 0.006069\n",
      "[849/00205] train_loss: 0.006046\n",
      "[849/00255] train_loss: 0.006128\n",
      "[849/00305] train_loss: 0.006078\n",
      "[849/00355] train_loss: 0.006020\n",
      "[849/00405] train_loss: 0.006129\n",
      "[850/00049] train_loss: 0.006100\n",
      "[850/00099] train_loss: 0.006100\n",
      "[850/00149] train_loss: 0.006192\n",
      "[850/00199] train_loss: 0.006083\n",
      "[850/00249] train_loss: 0.006016\n",
      "[850/00299] train_loss: 0.006063\n",
      "[850/00349] train_loss: 0.006057\n",
      "[850/00399] train_loss: 0.006030\n",
      "[851/00043] train_loss: 0.006063\n",
      "[851/00093] train_loss: 0.006091\n",
      "[851/00143] train_loss: 0.006187\n",
      "[851/00193] train_loss: 0.006168\n",
      "[851/00243] train_loss: 0.006129\n",
      "[851/00293] train_loss: 0.006041\n",
      "[851/00343] train_loss: 0.006069\n",
      "[851/00393] train_loss: 0.006098\n",
      "[852/00037] train_loss: 0.006016\n",
      "[852/00087] train_loss: 0.006078\n",
      "[852/00137] train_loss: 0.006077\n",
      "[852/00187] train_loss: 0.006064\n",
      "[852/00237] train_loss: 0.006090\n",
      "[852/00287] train_loss: 0.006094\n",
      "[852/00337] train_loss: 0.006140\n",
      "[852/00387] train_loss: 0.006144\n",
      "[853/00031] train_loss: 0.006141\n",
      "[853/00081] train_loss: 0.006018\n",
      "[853/00131] train_loss: 0.006118\n",
      "[853/00181] train_loss: 0.006089\n",
      "[853/00231] train_loss: 0.006160\n",
      "[853/00281] train_loss: 0.006047\n",
      "[853/00331] train_loss: 0.006107\n",
      "[853/00381] train_loss: 0.006085\n",
      "[854/00025] train_loss: 0.006166\n",
      "[854/00075] train_loss: 0.006129\n",
      "[854/00125] train_loss: 0.006021\n",
      "[854/00175] train_loss: 0.006175\n",
      "[854/00225] train_loss: 0.006146\n",
      "[854/00275] train_loss: 0.006098\n",
      "[854/00325] train_loss: 0.006106\n",
      "[854/00375] train_loss: 0.006066\n",
      "[855/00019] train_loss: 0.006052\n",
      "[855/00069] train_loss: 0.006124\n",
      "[855/00119] train_loss: 0.006131\n",
      "[855/00169] train_loss: 0.006055\n",
      "[855/00219] train_loss: 0.006135\n",
      "[855/00269] train_loss: 0.006072\n",
      "[855/00319] train_loss: 0.006130\n",
      "[855/00369] train_loss: 0.006053\n",
      "[856/00013] train_loss: 0.006041\n",
      "[856/00063] train_loss: 0.006066\n",
      "[856/00113] train_loss: 0.006086\n",
      "[856/00163] train_loss: 0.006108\n",
      "[856/00213] train_loss: 0.006045\n",
      "[856/00263] train_loss: 0.006086\n",
      "[856/00313] train_loss: 0.006149\n",
      "[856/00363] train_loss: 0.006046\n",
      "[857/00007] train_loss: 0.006034\n",
      "[857/00057] train_loss: 0.006141\n",
      "[857/00107] train_loss: 0.006020\n",
      "[857/00157] train_loss: 0.006044\n",
      "[857/00207] train_loss: 0.005996\n",
      "[857/00257] train_loss: 0.006164\n",
      "[857/00307] train_loss: 0.006113\n",
      "[857/00357] train_loss: 0.006203\n",
      "[858/00001] train_loss: 0.006061\n",
      "[858/00051] train_loss: 0.006076\n",
      "[858/00101] train_loss: 0.006093\n",
      "[858/00151] train_loss: 0.006029\n",
      "[858/00201] train_loss: 0.006166\n",
      "[858/00251] train_loss: 0.006128\n",
      "[858/00301] train_loss: 0.006147\n",
      "[858/00351] train_loss: 0.006198\n",
      "[858/00401] train_loss: 0.006094\n",
      "[859/00045] train_loss: 0.006043\n",
      "[859/00095] train_loss: 0.006103\n",
      "[859/00145] train_loss: 0.006105\n",
      "[859/00195] train_loss: 0.006117\n",
      "[859/00245] train_loss: 0.006093\n",
      "[859/00295] train_loss: 0.006092\n",
      "[859/00345] train_loss: 0.006011\n",
      "[859/00395] train_loss: 0.006058\n",
      "[860/00039] train_loss: 0.006118\n",
      "[860/00089] train_loss: 0.006024\n",
      "[860/00139] train_loss: 0.006123\n",
      "[860/00189] train_loss: 0.006089\n",
      "[860/00239] train_loss: 0.006070\n",
      "[860/00289] train_loss: 0.006150\n",
      "[860/00339] train_loss: 0.006130\n",
      "[860/00389] train_loss: 0.006111\n",
      "[861/00033] train_loss: 0.006143\n",
      "[861/00083] train_loss: 0.006180\n",
      "[861/00133] train_loss: 0.006082\n",
      "[861/00183] train_loss: 0.005990\n",
      "[861/00233] train_loss: 0.006049\n",
      "[861/00283] train_loss: 0.006083\n",
      "[861/00333] train_loss: 0.006050\n",
      "[861/00383] train_loss: 0.006117\n",
      "[862/00027] train_loss: 0.006096\n",
      "[862/00077] train_loss: 0.006089\n",
      "[862/00127] train_loss: 0.006091\n",
      "[862/00177] train_loss: 0.006073\n",
      "[862/00227] train_loss: 0.006154\n",
      "[862/00277] train_loss: 0.006085\n",
      "[862/00327] train_loss: 0.006117\n",
      "[862/00377] train_loss: 0.006040\n",
      "[863/00021] train_loss: 0.006122\n",
      "[863/00071] train_loss: 0.006180\n",
      "[863/00121] train_loss: 0.006084\n",
      "[863/00171] train_loss: 0.006062\n",
      "[863/00221] train_loss: 0.006162\n",
      "[863/00271] train_loss: 0.006074\n",
      "[863/00321] train_loss: 0.006112\n",
      "[863/00371] train_loss: 0.006066\n",
      "[864/00015] train_loss: 0.006160\n",
      "[864/00065] train_loss: 0.006106\n",
      "[864/00115] train_loss: 0.006011\n",
      "[864/00165] train_loss: 0.006040\n",
      "[864/00215] train_loss: 0.006061\n",
      "[864/00265] train_loss: 0.006116\n",
      "[864/00315] train_loss: 0.006073\n",
      "[864/00365] train_loss: 0.006085\n",
      "[865/00009] train_loss: 0.006041\n",
      "[865/00059] train_loss: 0.006117\n",
      "[865/00109] train_loss: 0.006060\n",
      "[865/00159] train_loss: 0.006126\n",
      "[865/00209] train_loss: 0.006083\n",
      "[865/00259] train_loss: 0.006124\n",
      "[865/00309] train_loss: 0.006059\n",
      "[865/00359] train_loss: 0.006122\n",
      "[866/00003] train_loss: 0.006115\n",
      "[866/00053] train_loss: 0.006058\n",
      "[866/00103] train_loss: 0.006062\n",
      "[866/00153] train_loss: 0.006103\n",
      "[866/00203] train_loss: 0.006101\n",
      "[866/00253] train_loss: 0.006047\n",
      "[866/00303] train_loss: 0.006166\n",
      "[866/00353] train_loss: 0.006090\n",
      "[866/00403] train_loss: 0.006037\n",
      "[867/00047] train_loss: 0.006170\n",
      "[867/00097] train_loss: 0.006116\n",
      "[867/00147] train_loss: 0.006144\n",
      "[867/00197] train_loss: 0.006074\n",
      "[867/00247] train_loss: 0.006117\n",
      "[867/00297] train_loss: 0.006083\n",
      "[867/00347] train_loss: 0.006167\n",
      "[867/00397] train_loss: 0.006073\n",
      "[868/00041] train_loss: 0.005966\n",
      "[868/00091] train_loss: 0.006051\n",
      "[868/00141] train_loss: 0.006021\n",
      "[868/00191] train_loss: 0.006160\n",
      "[868/00241] train_loss: 0.006152\n",
      "[868/00291] train_loss: 0.006055\n",
      "[868/00341] train_loss: 0.006054\n",
      "[868/00391] train_loss: 0.006020\n",
      "[869/00035] train_loss: 0.006096\n",
      "[869/00085] train_loss: 0.006167\n",
      "[869/00135] train_loss: 0.006077\n",
      "[869/00185] train_loss: 0.006173\n",
      "[869/00235] train_loss: 0.006010\n",
      "[869/00285] train_loss: 0.006105\n",
      "[869/00335] train_loss: 0.006034\n",
      "[869/00385] train_loss: 0.006109\n",
      "[870/00029] train_loss: 0.006114\n",
      "[870/00079] train_loss: 0.006045\n",
      "[870/00129] train_loss: 0.006163\n",
      "[870/00179] train_loss: 0.006086\n",
      "[870/00229] train_loss: 0.006037\n",
      "[870/00279] train_loss: 0.006135\n",
      "[870/00329] train_loss: 0.006125\n",
      "[870/00379] train_loss: 0.006080\n",
      "[871/00023] train_loss: 0.006059\n",
      "[871/00073] train_loss: 0.006167\n",
      "[871/00123] train_loss: 0.006057\n",
      "[871/00173] train_loss: 0.006110\n",
      "[871/00223] train_loss: 0.006156\n",
      "[871/00273] train_loss: 0.006092\n",
      "[871/00323] train_loss: 0.006105\n",
      "[871/00373] train_loss: 0.006075\n",
      "[872/00017] train_loss: 0.006084\n",
      "[872/00067] train_loss: 0.006111\n",
      "[872/00117] train_loss: 0.006054\n",
      "[872/00167] train_loss: 0.006012\n",
      "[872/00217] train_loss: 0.006134\n",
      "[872/00267] train_loss: 0.006176\n",
      "[872/00317] train_loss: 0.006091\n",
      "[872/00367] train_loss: 0.006029\n",
      "[873/00011] train_loss: 0.006143\n",
      "[873/00061] train_loss: 0.006149\n",
      "[873/00111] train_loss: 0.006131\n",
      "[873/00161] train_loss: 0.006074\n",
      "[873/00211] train_loss: 0.006100\n",
      "[873/00261] train_loss: 0.006038\n",
      "[873/00311] train_loss: 0.006003\n",
      "[873/00361] train_loss: 0.006064\n",
      "[874/00005] train_loss: 0.006086\n",
      "[874/00055] train_loss: 0.006097\n",
      "[874/00105] train_loss: 0.006108\n",
      "[874/00155] train_loss: 0.005997\n",
      "[874/00205] train_loss: 0.006073\n",
      "[874/00255] train_loss: 0.006133\n",
      "[874/00305] train_loss: 0.006092\n",
      "[874/00355] train_loss: 0.006078\n",
      "[874/00405] train_loss: 0.006092\n",
      "[875/00049] train_loss: 0.006195\n",
      "[875/00099] train_loss: 0.006066\n",
      "[875/00149] train_loss: 0.006089\n",
      "[875/00199] train_loss: 0.006085\n",
      "[875/00249] train_loss: 0.006051\n",
      "[875/00299] train_loss: 0.006108\n",
      "[875/00349] train_loss: 0.006073\n",
      "[875/00399] train_loss: 0.006117\n",
      "[876/00043] train_loss: 0.005979\n",
      "[876/00093] train_loss: 0.006010\n",
      "[876/00143] train_loss: 0.006126\n",
      "[876/00193] train_loss: 0.006093\n",
      "[876/00243] train_loss: 0.006119\n",
      "[876/00293] train_loss: 0.006147\n",
      "[876/00343] train_loss: 0.006153\n",
      "[876/00393] train_loss: 0.006064\n",
      "[877/00037] train_loss: 0.006133\n",
      "[877/00087] train_loss: 0.006155\n",
      "[877/00137] train_loss: 0.006062\n",
      "[877/00187] train_loss: 0.006047\n",
      "[877/00237] train_loss: 0.006070\n",
      "[877/00287] train_loss: 0.006078\n",
      "[877/00337] train_loss: 0.006126\n",
      "[877/00387] train_loss: 0.006129\n",
      "[878/00031] train_loss: 0.006051\n",
      "[878/00081] train_loss: 0.006078\n",
      "[878/00131] train_loss: 0.006100\n",
      "[878/00181] train_loss: 0.006098\n",
      "[878/00231] train_loss: 0.006122\n",
      "[878/00281] train_loss: 0.006086\n",
      "[878/00331] train_loss: 0.006239\n",
      "[878/00381] train_loss: 0.006090\n",
      "[879/00025] train_loss: 0.006031\n",
      "[879/00075] train_loss: 0.006210\n",
      "[879/00125] train_loss: 0.006023\n",
      "[879/00175] train_loss: 0.006059\n",
      "[879/00225] train_loss: 0.006143\n",
      "[879/00275] train_loss: 0.006066\n",
      "[879/00325] train_loss: 0.006034\n",
      "[879/00375] train_loss: 0.006140\n",
      "[880/00019] train_loss: 0.006058\n",
      "[880/00069] train_loss: 0.006184\n",
      "[880/00119] train_loss: 0.006054\n",
      "[880/00169] train_loss: 0.006099\n",
      "[880/00219] train_loss: 0.006155\n",
      "[880/00269] train_loss: 0.006113\n",
      "[880/00319] train_loss: 0.006154\n",
      "[880/00369] train_loss: 0.006043\n",
      "[881/00013] train_loss: 0.006069\n",
      "[881/00063] train_loss: 0.006159\n",
      "[881/00113] train_loss: 0.006141\n",
      "[881/00163] train_loss: 0.006114\n",
      "[881/00213] train_loss: 0.006058\n",
      "[881/00263] train_loss: 0.006073\n",
      "[881/00313] train_loss: 0.006034\n",
      "[881/00363] train_loss: 0.006100\n",
      "[882/00007] train_loss: 0.006105\n",
      "[882/00057] train_loss: 0.006137\n",
      "[882/00107] train_loss: 0.006047\n",
      "[882/00157] train_loss: 0.006066\n",
      "[882/00207] train_loss: 0.006135\n",
      "[882/00257] train_loss: 0.006096\n",
      "[882/00307] train_loss: 0.006016\n",
      "[882/00357] train_loss: 0.006062\n",
      "[883/00001] train_loss: 0.006067\n",
      "[883/00051] train_loss: 0.006114\n",
      "[883/00101] train_loss: 0.006060\n",
      "[883/00151] train_loss: 0.006108\n",
      "[883/00201] train_loss: 0.006068\n",
      "[883/00251] train_loss: 0.006051\n",
      "[883/00301] train_loss: 0.006128\n",
      "[883/00351] train_loss: 0.006145\n",
      "[883/00401] train_loss: 0.006034\n",
      "[884/00045] train_loss: 0.006115\n",
      "[884/00095] train_loss: 0.006066\n",
      "[884/00145] train_loss: 0.006017\n",
      "[884/00195] train_loss: 0.006030\n",
      "[884/00245] train_loss: 0.006161\n",
      "[884/00295] train_loss: 0.006124\n",
      "[884/00345] train_loss: 0.006137\n",
      "[884/00395] train_loss: 0.006059\n",
      "[885/00039] train_loss: 0.006120\n",
      "[885/00089] train_loss: 0.006064\n",
      "[885/00139] train_loss: 0.006143\n",
      "[885/00189] train_loss: 0.006098\n",
      "[885/00239] train_loss: 0.006086\n",
      "[885/00289] train_loss: 0.006047\n",
      "[885/00339] train_loss: 0.006059\n",
      "[885/00389] train_loss: 0.006111\n",
      "[886/00033] train_loss: 0.006156\n",
      "[886/00083] train_loss: 0.006116\n",
      "[886/00133] train_loss: 0.006253\n",
      "[886/00183] train_loss: 0.006100\n",
      "[886/00233] train_loss: 0.006003\n",
      "[886/00283] train_loss: 0.006135\n",
      "[886/00333] train_loss: 0.006165\n",
      "[886/00383] train_loss: 0.006130\n",
      "[887/00027] train_loss: 0.006121\n",
      "[887/00077] train_loss: 0.006058\n",
      "[887/00127] train_loss: 0.006134\n",
      "[887/00177] train_loss: 0.006079\n",
      "[887/00227] train_loss: 0.006184\n",
      "[887/00277] train_loss: 0.006072\n",
      "[887/00327] train_loss: 0.006095\n",
      "[887/00377] train_loss: 0.006079\n",
      "[888/00021] train_loss: 0.006119\n",
      "[888/00071] train_loss: 0.006071\n",
      "[888/00121] train_loss: 0.006051\n",
      "[888/00171] train_loss: 0.006106\n",
      "[888/00221] train_loss: 0.006113\n",
      "[888/00271] train_loss: 0.006141\n",
      "[888/00321] train_loss: 0.006054\n",
      "[888/00371] train_loss: 0.006098\n",
      "[889/00015] train_loss: 0.006139\n",
      "[889/00065] train_loss: 0.006088\n",
      "[889/00115] train_loss: 0.006137\n",
      "[889/00165] train_loss: 0.006168\n",
      "[889/00215] train_loss: 0.006076\n",
      "[889/00265] train_loss: 0.006165\n",
      "[889/00315] train_loss: 0.006190\n",
      "[889/00365] train_loss: 0.006049\n",
      "[890/00009] train_loss: 0.006146\n",
      "[890/00059] train_loss: 0.006117\n",
      "[890/00109] train_loss: 0.006056\n",
      "[890/00159] train_loss: 0.006112\n",
      "[890/00209] train_loss: 0.006128\n",
      "[890/00259] train_loss: 0.006082\n",
      "[890/00309] train_loss: 0.006073\n",
      "[890/00359] train_loss: 0.006022\n",
      "[891/00003] train_loss: 0.006164\n",
      "[891/00053] train_loss: 0.006113\n",
      "[891/00103] train_loss: 0.006172\n",
      "[891/00153] train_loss: 0.006141\n",
      "[891/00203] train_loss: 0.006045\n",
      "[891/00253] train_loss: 0.006127\n",
      "[891/00303] train_loss: 0.006116\n",
      "[891/00353] train_loss: 0.006022\n",
      "[891/00403] train_loss: 0.006169\n",
      "[892/00047] train_loss: 0.006096\n",
      "[892/00097] train_loss: 0.006030\n",
      "[892/00147] train_loss: 0.006118\n",
      "[892/00197] train_loss: 0.006089\n",
      "[892/00247] train_loss: 0.006122\n",
      "[892/00297] train_loss: 0.006135\n",
      "[892/00347] train_loss: 0.006044\n",
      "[892/00397] train_loss: 0.006178\n",
      "[893/00041] train_loss: 0.006137\n",
      "[893/00091] train_loss: 0.006034\n",
      "[893/00141] train_loss: 0.006074\n",
      "[893/00191] train_loss: 0.006038\n",
      "[893/00241] train_loss: 0.006039\n",
      "[893/00291] train_loss: 0.006113\n",
      "[893/00341] train_loss: 0.006125\n",
      "[893/00391] train_loss: 0.006138\n",
      "[894/00035] train_loss: 0.006029\n",
      "[894/00085] train_loss: 0.006160\n",
      "[894/00135] train_loss: 0.006065\n",
      "[894/00185] train_loss: 0.006007\n",
      "[894/00235] train_loss: 0.006096\n",
      "[894/00285] train_loss: 0.005993\n",
      "[894/00335] train_loss: 0.006061\n",
      "[894/00385] train_loss: 0.006144\n",
      "[895/00029] train_loss: 0.006158\n",
      "[895/00079] train_loss: 0.006107\n",
      "[895/00129] train_loss: 0.006056\n",
      "[895/00179] train_loss: 0.006116\n",
      "[895/00229] train_loss: 0.006146\n",
      "[895/00279] train_loss: 0.006084\n",
      "[895/00329] train_loss: 0.006059\n",
      "[895/00379] train_loss: 0.006101\n",
      "[896/00023] train_loss: 0.006130\n",
      "[896/00073] train_loss: 0.006140\n",
      "[896/00123] train_loss: 0.006086\n",
      "[896/00173] train_loss: 0.006000\n",
      "[896/00223] train_loss: 0.006165\n",
      "[896/00273] train_loss: 0.006110\n",
      "[896/00323] train_loss: 0.006189\n",
      "[896/00373] train_loss: 0.006180\n",
      "[897/00017] train_loss: 0.006094\n",
      "[897/00067] train_loss: 0.006066\n",
      "[897/00117] train_loss: 0.006205\n",
      "[897/00167] train_loss: 0.006061\n",
      "[897/00217] train_loss: 0.006008\n",
      "[897/00267] train_loss: 0.006104\n",
      "[897/00317] train_loss: 0.006066\n",
      "[897/00367] train_loss: 0.005957\n",
      "[898/00011] train_loss: 0.006084\n",
      "[898/00061] train_loss: 0.006085\n",
      "[898/00111] train_loss: 0.006158\n",
      "[898/00161] train_loss: 0.006211\n",
      "[898/00211] train_loss: 0.006054\n",
      "[898/00261] train_loss: 0.006079\n",
      "[898/00311] train_loss: 0.006172\n",
      "[898/00361] train_loss: 0.006107\n",
      "[899/00005] train_loss: 0.006071\n",
      "[899/00055] train_loss: 0.006151\n",
      "[899/00105] train_loss: 0.006182\n",
      "[899/00155] train_loss: 0.006111\n",
      "[899/00205] train_loss: 0.006045\n",
      "[899/00255] train_loss: 0.006054\n",
      "[899/00305] train_loss: 0.006134\n",
      "[899/00355] train_loss: 0.006070\n",
      "[899/00405] train_loss: 0.005935\n",
      "[900/00049] train_loss: 0.006152\n",
      "[900/00099] train_loss: 0.006125\n",
      "[900/00149] train_loss: 0.006074\n",
      "[900/00199] train_loss: 0.006149\n",
      "[900/00249] train_loss: 0.006114\n",
      "[900/00299] train_loss: 0.006065\n",
      "[900/00349] train_loss: 0.006061\n",
      "[900/00399] train_loss: 0.005989\n",
      "[901/00043] train_loss: 0.006092\n",
      "[901/00093] train_loss: 0.006109\n",
      "[901/00143] train_loss: 0.005998\n",
      "[901/00193] train_loss: 0.006106\n",
      "[901/00243] train_loss: 0.006028\n",
      "[901/00293] train_loss: 0.006033\n",
      "[901/00343] train_loss: 0.006109\n",
      "[901/00393] train_loss: 0.006142\n",
      "[902/00037] train_loss: 0.006124\n",
      "[902/00087] train_loss: 0.006119\n",
      "[902/00137] train_loss: 0.006056\n",
      "[902/00187] train_loss: 0.006048\n",
      "[902/00237] train_loss: 0.006100\n",
      "[902/00287] train_loss: 0.006102\n",
      "[902/00337] train_loss: 0.006038\n",
      "[902/00387] train_loss: 0.006168\n",
      "[903/00031] train_loss: 0.006116\n",
      "[903/00081] train_loss: 0.006049\n",
      "[903/00131] train_loss: 0.006018\n",
      "[903/00181] train_loss: 0.006169\n",
      "[903/00231] train_loss: 0.006022\n",
      "[903/00281] train_loss: 0.006001\n",
      "[903/00331] train_loss: 0.006181\n",
      "[903/00381] train_loss: 0.006074\n",
      "[904/00025] train_loss: 0.006171\n",
      "[904/00075] train_loss: 0.006033\n",
      "[904/00125] train_loss: 0.006042\n",
      "[904/00175] train_loss: 0.006067\n",
      "[904/00225] train_loss: 0.006080\n",
      "[904/00275] train_loss: 0.006076\n",
      "[904/00325] train_loss: 0.006134\n",
      "[904/00375] train_loss: 0.006084\n",
      "[905/00019] train_loss: 0.006088\n",
      "[905/00069] train_loss: 0.006138\n",
      "[905/00119] train_loss: 0.006045\n",
      "[905/00169] train_loss: 0.006011\n",
      "[905/00219] train_loss: 0.006099\n",
      "[905/00269] train_loss: 0.006059\n",
      "[905/00319] train_loss: 0.006064\n",
      "[905/00369] train_loss: 0.006009\n",
      "[906/00013] train_loss: 0.006019\n",
      "[906/00063] train_loss: 0.006112\n",
      "[906/00113] train_loss: 0.006128\n",
      "[906/00163] train_loss: 0.006154\n",
      "[906/00213] train_loss: 0.006087\n",
      "[906/00263] train_loss: 0.006140\n",
      "[906/00313] train_loss: 0.006076\n",
      "[906/00363] train_loss: 0.006101\n",
      "[907/00007] train_loss: 0.006118\n",
      "[907/00057] train_loss: 0.005984\n",
      "[907/00107] train_loss: 0.006107\n",
      "[907/00157] train_loss: 0.006059\n",
      "[907/00207] train_loss: 0.006140\n",
      "[907/00257] train_loss: 0.006128\n",
      "[907/00307] train_loss: 0.006022\n",
      "[907/00357] train_loss: 0.006020\n",
      "[908/00001] train_loss: 0.006159\n",
      "[908/00051] train_loss: 0.006086\n",
      "[908/00101] train_loss: 0.006056\n",
      "[908/00151] train_loss: 0.006128\n",
      "[908/00201] train_loss: 0.006102\n",
      "[908/00251] train_loss: 0.006154\n",
      "[908/00301] train_loss: 0.006036\n",
      "[908/00351] train_loss: 0.006011\n",
      "[908/00401] train_loss: 0.005986\n",
      "[909/00045] train_loss: 0.006056\n",
      "[909/00095] train_loss: 0.006068\n",
      "[909/00145] train_loss: 0.006106\n",
      "[909/00195] train_loss: 0.006033\n",
      "[909/00245] train_loss: 0.006133\n",
      "[909/00295] train_loss: 0.006151\n",
      "[909/00345] train_loss: 0.006169\n",
      "[909/00395] train_loss: 0.005961\n",
      "[910/00039] train_loss: 0.006134\n",
      "[910/00089] train_loss: 0.006039\n",
      "[910/00139] train_loss: 0.006135\n",
      "[910/00189] train_loss: 0.006207\n",
      "[910/00239] train_loss: 0.006028\n",
      "[910/00289] train_loss: 0.006158\n",
      "[910/00339] train_loss: 0.006115\n",
      "[910/00389] train_loss: 0.006112\n",
      "[911/00033] train_loss: 0.006084\n",
      "[911/00083] train_loss: 0.006030\n",
      "[911/00133] train_loss: 0.006134\n",
      "[911/00183] train_loss: 0.006130\n",
      "[911/00233] train_loss: 0.006064\n",
      "[911/00283] train_loss: 0.006051\n",
      "[911/00333] train_loss: 0.006033\n",
      "[911/00383] train_loss: 0.006080\n",
      "[912/00027] train_loss: 0.006091\n",
      "[912/00077] train_loss: 0.006094\n",
      "[912/00127] train_loss: 0.006076\n",
      "[912/00177] train_loss: 0.006024\n",
      "[912/00227] train_loss: 0.006062\n",
      "[912/00277] train_loss: 0.006073\n",
      "[912/00327] train_loss: 0.006114\n",
      "[912/00377] train_loss: 0.006138\n",
      "[913/00021] train_loss: 0.006114\n",
      "[913/00071] train_loss: 0.006165\n",
      "[913/00121] train_loss: 0.006089\n",
      "[913/00171] train_loss: 0.006066\n",
      "[913/00221] train_loss: 0.006141\n",
      "[913/00271] train_loss: 0.006047\n",
      "[913/00321] train_loss: 0.006054\n",
      "[913/00371] train_loss: 0.006078\n",
      "[914/00015] train_loss: 0.006177\n",
      "[914/00065] train_loss: 0.006096\n",
      "[914/00115] train_loss: 0.006094\n",
      "[914/00165] train_loss: 0.006084\n",
      "[914/00215] train_loss: 0.006098\n",
      "[914/00265] train_loss: 0.006150\n",
      "[914/00315] train_loss: 0.006102\n",
      "[914/00365] train_loss: 0.006004\n",
      "[915/00009] train_loss: 0.006079\n",
      "[915/00059] train_loss: 0.006086\n",
      "[915/00109] train_loss: 0.006126\n",
      "[915/00159] train_loss: 0.006137\n",
      "[915/00209] train_loss: 0.006143\n",
      "[915/00259] train_loss: 0.006161\n",
      "[915/00309] train_loss: 0.006097\n",
      "[915/00359] train_loss: 0.006053\n",
      "[916/00003] train_loss: 0.006110\n",
      "[916/00053] train_loss: 0.006090\n",
      "[916/00103] train_loss: 0.006103\n",
      "[916/00153] train_loss: 0.006165\n",
      "[916/00203] train_loss: 0.006182\n",
      "[916/00253] train_loss: 0.006025\n",
      "[916/00303] train_loss: 0.006052\n",
      "[916/00353] train_loss: 0.006109\n",
      "[916/00403] train_loss: 0.006114\n",
      "[917/00047] train_loss: 0.005985\n",
      "[917/00097] train_loss: 0.006108\n",
      "[917/00147] train_loss: 0.006074\n",
      "[917/00197] train_loss: 0.006104\n",
      "[917/00247] train_loss: 0.006118\n",
      "[917/00297] train_loss: 0.006098\n",
      "[917/00347] train_loss: 0.006074\n",
      "[917/00397] train_loss: 0.006091\n",
      "[918/00041] train_loss: 0.006035\n",
      "[918/00091] train_loss: 0.006076\n",
      "[918/00141] train_loss: 0.006128\n",
      "[918/00191] train_loss: 0.006153\n",
      "[918/00241] train_loss: 0.006163\n",
      "[918/00291] train_loss: 0.006045\n",
      "[918/00341] train_loss: 0.006065\n",
      "[918/00391] train_loss: 0.006104\n",
      "[919/00035] train_loss: 0.006085\n",
      "[919/00085] train_loss: 0.006012\n",
      "[919/00135] train_loss: 0.006047\n",
      "[919/00185] train_loss: 0.006139\n",
      "[919/00235] train_loss: 0.006085\n",
      "[919/00285] train_loss: 0.006093\n",
      "[919/00335] train_loss: 0.006041\n",
      "[919/00385] train_loss: 0.006141\n",
      "[920/00029] train_loss: 0.006114\n",
      "[920/00079] train_loss: 0.006074\n",
      "[920/00129] train_loss: 0.006076\n",
      "[920/00179] train_loss: 0.006062\n",
      "[920/00229] train_loss: 0.006117\n",
      "[920/00279] train_loss: 0.006031\n",
      "[920/00329] train_loss: 0.006081\n",
      "[920/00379] train_loss: 0.006087\n",
      "[921/00023] train_loss: 0.006184\n",
      "[921/00073] train_loss: 0.006052\n",
      "[921/00123] train_loss: 0.006004\n",
      "[921/00173] train_loss: 0.005995\n",
      "[921/00223] train_loss: 0.006090\n",
      "[921/00273] train_loss: 0.006087\n",
      "[921/00323] train_loss: 0.006093\n",
      "[921/00373] train_loss: 0.006066\n",
      "[922/00017] train_loss: 0.006155\n",
      "[922/00067] train_loss: 0.006149\n",
      "[922/00117] train_loss: 0.006106\n",
      "[922/00167] train_loss: 0.006112\n",
      "[922/00217] train_loss: 0.006090\n",
      "[922/00267] train_loss: 0.006090\n",
      "[922/00317] train_loss: 0.006109\n",
      "[922/00367] train_loss: 0.006009\n",
      "[923/00011] train_loss: 0.006186\n",
      "[923/00061] train_loss: 0.006135\n",
      "[923/00111] train_loss: 0.006167\n",
      "[923/00161] train_loss: 0.006099\n",
      "[923/00211] train_loss: 0.006141\n",
      "[923/00261] train_loss: 0.006097\n",
      "[923/00311] train_loss: 0.006045\n",
      "[923/00361] train_loss: 0.006141\n",
      "[924/00005] train_loss: 0.006170\n",
      "[924/00055] train_loss: 0.006093\n",
      "[924/00105] train_loss: 0.006138\n",
      "[924/00155] train_loss: 0.006131\n",
      "[924/00205] train_loss: 0.006209\n",
      "[924/00255] train_loss: 0.006111\n",
      "[924/00305] train_loss: 0.006053\n",
      "[924/00355] train_loss: 0.006076\n",
      "[924/00405] train_loss: 0.006034\n",
      "[925/00049] train_loss: 0.006090\n",
      "[925/00099] train_loss: 0.006127\n",
      "[925/00149] train_loss: 0.006103\n",
      "[925/00199] train_loss: 0.006128\n",
      "[925/00249] train_loss: 0.006089\n",
      "[925/00299] train_loss: 0.006031\n",
      "[925/00349] train_loss: 0.006139\n",
      "[925/00399] train_loss: 0.006157\n",
      "[926/00043] train_loss: 0.006039\n",
      "[926/00093] train_loss: 0.006083\n",
      "[926/00143] train_loss: 0.006089\n",
      "[926/00193] train_loss: 0.006096\n",
      "[926/00243] train_loss: 0.006083\n",
      "[926/00293] train_loss: 0.006030\n",
      "[926/00343] train_loss: 0.006100\n",
      "[926/00393] train_loss: 0.006094\n",
      "[927/00037] train_loss: 0.006071\n",
      "[927/00087] train_loss: 0.006150\n",
      "[927/00137] train_loss: 0.006057\n",
      "[927/00187] train_loss: 0.006037\n",
      "[927/00237] train_loss: 0.006117\n",
      "[927/00287] train_loss: 0.006081\n",
      "[927/00337] train_loss: 0.005999\n",
      "[927/00387] train_loss: 0.005996\n",
      "[928/00031] train_loss: 0.006054\n",
      "[928/00081] train_loss: 0.006085\n",
      "[928/00131] train_loss: 0.006100\n",
      "[928/00181] train_loss: 0.006008\n",
      "[928/00231] train_loss: 0.006029\n",
      "[928/00281] train_loss: 0.006141\n",
      "[928/00331] train_loss: 0.006188\n",
      "[928/00381] train_loss: 0.006085\n",
      "[929/00025] train_loss: 0.006052\n",
      "[929/00075] train_loss: 0.005907\n",
      "[929/00125] train_loss: 0.006035\n",
      "[929/00175] train_loss: 0.006101\n",
      "[929/00225] train_loss: 0.006113\n",
      "[929/00275] train_loss: 0.006183\n",
      "[929/00325] train_loss: 0.006024\n",
      "[929/00375] train_loss: 0.006077\n",
      "[930/00019] train_loss: 0.006142\n",
      "[930/00069] train_loss: 0.006152\n",
      "[930/00119] train_loss: 0.006002\n",
      "[930/00169] train_loss: 0.006127\n",
      "[930/00219] train_loss: 0.006139\n",
      "[930/00269] train_loss: 0.006039\n",
      "[930/00319] train_loss: 0.006050\n",
      "[930/00369] train_loss: 0.006181\n",
      "[931/00013] train_loss: 0.006044\n",
      "[931/00063] train_loss: 0.006155\n",
      "[931/00113] train_loss: 0.006153\n",
      "[931/00163] train_loss: 0.006131\n",
      "[931/00213] train_loss: 0.006160\n",
      "[931/00263] train_loss: 0.006079\n",
      "[931/00313] train_loss: 0.006205\n",
      "[931/00363] train_loss: 0.006102\n",
      "[932/00007] train_loss: 0.006198\n",
      "[932/00057] train_loss: 0.005943\n",
      "[932/00107] train_loss: 0.006185\n",
      "[932/00157] train_loss: 0.006070\n",
      "[932/00207] train_loss: 0.006071\n",
      "[932/00257] train_loss: 0.006145\n",
      "[932/00307] train_loss: 0.006058\n",
      "[932/00357] train_loss: 0.006045\n",
      "[933/00001] train_loss: 0.006129\n",
      "[933/00051] train_loss: 0.006143\n",
      "[933/00101] train_loss: 0.006135\n",
      "[933/00151] train_loss: 0.006061\n",
      "[933/00201] train_loss: 0.006115\n",
      "[933/00251] train_loss: 0.006024\n",
      "[933/00301] train_loss: 0.006158\n",
      "[933/00351] train_loss: 0.006113\n",
      "[933/00401] train_loss: 0.006031\n",
      "[934/00045] train_loss: 0.006136\n",
      "[934/00095] train_loss: 0.006132\n",
      "[934/00145] train_loss: 0.006006\n",
      "[934/00195] train_loss: 0.006063\n",
      "[934/00245] train_loss: 0.006034\n",
      "[934/00295] train_loss: 0.006042\n",
      "[934/00345] train_loss: 0.006130\n",
      "[934/00395] train_loss: 0.006067\n",
      "[935/00039] train_loss: 0.006035\n",
      "[935/00089] train_loss: 0.006111\n",
      "[935/00139] train_loss: 0.006034\n",
      "[935/00189] train_loss: 0.006083\n",
      "[935/00239] train_loss: 0.006137\n",
      "[935/00289] train_loss: 0.006174\n",
      "[935/00339] train_loss: 0.006146\n",
      "[935/00389] train_loss: 0.006051\n",
      "[936/00033] train_loss: 0.006106\n",
      "[936/00083] train_loss: 0.006072\n",
      "[936/00133] train_loss: 0.006038\n",
      "[936/00183] train_loss: 0.006165\n",
      "[936/00233] train_loss: 0.006071\n",
      "[936/00283] train_loss: 0.005972\n",
      "[936/00333] train_loss: 0.006159\n",
      "[936/00383] train_loss: 0.006165\n",
      "[937/00027] train_loss: 0.006133\n",
      "[937/00077] train_loss: 0.006160\n",
      "[937/00127] train_loss: 0.005979\n",
      "[937/00177] train_loss: 0.006037\n",
      "[937/00227] train_loss: 0.006165\n",
      "[937/00277] train_loss: 0.006028\n",
      "[937/00327] train_loss: 0.006139\n",
      "[937/00377] train_loss: 0.006134\n",
      "[938/00021] train_loss: 0.006083\n",
      "[938/00071] train_loss: 0.006062\n",
      "[938/00121] train_loss: 0.006158\n",
      "[938/00171] train_loss: 0.006117\n",
      "[938/00221] train_loss: 0.006069\n",
      "[938/00271] train_loss: 0.006038\n",
      "[938/00321] train_loss: 0.006118\n",
      "[938/00371] train_loss: 0.006004\n",
      "[939/00015] train_loss: 0.006057\n",
      "[939/00065] train_loss: 0.006080\n",
      "[939/00115] train_loss: 0.006020\n",
      "[939/00165] train_loss: 0.006084\n",
      "[939/00215] train_loss: 0.006013\n",
      "[939/00265] train_loss: 0.006055\n",
      "[939/00315] train_loss: 0.006133\n",
      "[939/00365] train_loss: 0.006126\n",
      "[940/00009] train_loss: 0.006135\n",
      "[940/00059] train_loss: 0.006065\n",
      "[940/00109] train_loss: 0.006050\n",
      "[940/00159] train_loss: 0.006049\n",
      "[940/00209] train_loss: 0.006107\n",
      "[940/00259] train_loss: 0.006158\n",
      "[940/00309] train_loss: 0.006161\n",
      "[940/00359] train_loss: 0.006111\n",
      "[941/00003] train_loss: 0.005999\n",
      "[941/00053] train_loss: 0.006178\n",
      "[941/00103] train_loss: 0.006118\n",
      "[941/00153] train_loss: 0.006117\n",
      "[941/00203] train_loss: 0.006084\n",
      "[941/00253] train_loss: 0.006106\n",
      "[941/00303] train_loss: 0.006100\n",
      "[941/00353] train_loss: 0.006175\n",
      "[941/00403] train_loss: 0.006056\n",
      "[942/00047] train_loss: 0.006127\n",
      "[942/00097] train_loss: 0.006126\n",
      "[942/00147] train_loss: 0.006092\n",
      "[942/00197] train_loss: 0.006045\n",
      "[942/00247] train_loss: 0.006028\n",
      "[942/00297] train_loss: 0.006082\n",
      "[942/00347] train_loss: 0.006095\n",
      "[942/00397] train_loss: 0.006034\n",
      "[943/00041] train_loss: 0.006075\n",
      "[943/00091] train_loss: 0.006068\n",
      "[943/00141] train_loss: 0.006117\n",
      "[943/00191] train_loss: 0.006020\n",
      "[943/00241] train_loss: 0.006213\n",
      "[943/00291] train_loss: 0.006202\n",
      "[943/00341] train_loss: 0.006088\n",
      "[943/00391] train_loss: 0.006010\n",
      "[944/00035] train_loss: 0.006099\n",
      "[944/00085] train_loss: 0.006101\n",
      "[944/00135] train_loss: 0.006080\n",
      "[944/00185] train_loss: 0.006088\n",
      "[944/00235] train_loss: 0.006078\n",
      "[944/00285] train_loss: 0.006113\n",
      "[944/00335] train_loss: 0.006174\n",
      "[944/00385] train_loss: 0.006130\n",
      "[945/00029] train_loss: 0.006043\n",
      "[945/00079] train_loss: 0.006111\n",
      "[945/00129] train_loss: 0.006078\n",
      "[945/00179] train_loss: 0.006078\n",
      "[945/00229] train_loss: 0.006190\n",
      "[945/00279] train_loss: 0.006236\n",
      "[945/00329] train_loss: 0.006073\n",
      "[945/00379] train_loss: 0.006109\n",
      "[946/00023] train_loss: 0.006088\n",
      "[946/00073] train_loss: 0.006086\n",
      "[946/00123] train_loss: 0.006103\n",
      "[946/00173] train_loss: 0.006008\n",
      "[946/00223] train_loss: 0.006086\n",
      "[946/00273] train_loss: 0.006120\n",
      "[946/00323] train_loss: 0.006112\n",
      "[946/00373] train_loss: 0.006139\n",
      "[947/00017] train_loss: 0.006158\n",
      "[947/00067] train_loss: 0.006032\n",
      "[947/00117] train_loss: 0.006117\n",
      "[947/00167] train_loss: 0.006041\n",
      "[947/00217] train_loss: 0.006174\n",
      "[947/00267] train_loss: 0.006080\n",
      "[947/00317] train_loss: 0.006099\n",
      "[947/00367] train_loss: 0.006133\n",
      "[948/00011] train_loss: 0.006047\n",
      "[948/00061] train_loss: 0.006039\n",
      "[948/00111] train_loss: 0.006074\n",
      "[948/00161] train_loss: 0.006048\n",
      "[948/00211] train_loss: 0.006062\n",
      "[948/00261] train_loss: 0.006037\n",
      "[948/00311] train_loss: 0.006186\n",
      "[948/00361] train_loss: 0.006051\n",
      "[949/00005] train_loss: 0.006037\n",
      "[949/00055] train_loss: 0.006098\n",
      "[949/00105] train_loss: 0.006091\n",
      "[949/00155] train_loss: 0.006092\n",
      "[949/00205] train_loss: 0.006070\n",
      "[949/00255] train_loss: 0.006076\n",
      "[949/00305] train_loss: 0.006146\n",
      "[949/00355] train_loss: 0.006036\n",
      "[949/00405] train_loss: 0.006079\n",
      "[950/00049] train_loss: 0.006104\n",
      "[950/00099] train_loss: 0.006123\n",
      "[950/00149] train_loss: 0.006061\n",
      "[950/00199] train_loss: 0.005999\n",
      "[950/00249] train_loss: 0.006077\n",
      "[950/00299] train_loss: 0.006025\n",
      "[950/00349] train_loss: 0.006092\n",
      "[950/00399] train_loss: 0.006094\n",
      "[951/00043] train_loss: 0.006000\n",
      "[951/00093] train_loss: 0.006123\n",
      "[951/00143] train_loss: 0.006066\n",
      "[951/00193] train_loss: 0.006103\n",
      "[951/00243] train_loss: 0.006023\n",
      "[951/00293] train_loss: 0.006050\n",
      "[951/00343] train_loss: 0.006135\n",
      "[951/00393] train_loss: 0.006118\n",
      "[952/00037] train_loss: 0.006079\n",
      "[952/00087] train_loss: 0.006116\n",
      "[952/00137] train_loss: 0.006097\n",
      "[952/00187] train_loss: 0.006121\n",
      "[952/00237] train_loss: 0.006127\n",
      "[952/00287] train_loss: 0.006075\n",
      "[952/00337] train_loss: 0.005998\n",
      "[952/00387] train_loss: 0.006070\n",
      "[953/00031] train_loss: 0.006145\n",
      "[953/00081] train_loss: 0.006065\n",
      "[953/00131] train_loss: 0.006065\n",
      "[953/00181] train_loss: 0.006085\n",
      "[953/00231] train_loss: 0.006106\n",
      "[953/00281] train_loss: 0.006095\n",
      "[953/00331] train_loss: 0.006124\n",
      "[953/00381] train_loss: 0.006048\n",
      "[954/00025] train_loss: 0.006096\n",
      "[954/00075] train_loss: 0.006086\n",
      "[954/00125] train_loss: 0.006130\n",
      "[954/00175] train_loss: 0.006061\n",
      "[954/00225] train_loss: 0.006119\n",
      "[954/00275] train_loss: 0.006006\n",
      "[954/00325] train_loss: 0.006105\n",
      "[954/00375] train_loss: 0.006145\n",
      "[955/00019] train_loss: 0.006050\n",
      "[955/00069] train_loss: 0.006142\n",
      "[955/00119] train_loss: 0.006039\n",
      "[955/00169] train_loss: 0.006048\n",
      "[955/00219] train_loss: 0.006024\n",
      "[955/00269] train_loss: 0.006072\n",
      "[955/00319] train_loss: 0.006174\n",
      "[955/00369] train_loss: 0.006004\n",
      "[956/00013] train_loss: 0.006165\n",
      "[956/00063] train_loss: 0.006141\n",
      "[956/00113] train_loss: 0.006191\n",
      "[956/00163] train_loss: 0.006004\n",
      "[956/00213] train_loss: 0.006112\n",
      "[956/00263] train_loss: 0.006012\n",
      "[956/00313] train_loss: 0.006112\n",
      "[956/00363] train_loss: 0.006031\n",
      "[957/00007] train_loss: 0.006063\n",
      "[957/00057] train_loss: 0.006175\n",
      "[957/00107] train_loss: 0.006082\n",
      "[957/00157] train_loss: 0.006081\n",
      "[957/00207] train_loss: 0.006074\n",
      "[957/00257] train_loss: 0.006063\n",
      "[957/00307] train_loss: 0.006066\n",
      "[957/00357] train_loss: 0.006135\n",
      "[958/00001] train_loss: 0.006100\n",
      "[958/00051] train_loss: 0.005990\n",
      "[958/00101] train_loss: 0.006051\n",
      "[958/00151] train_loss: 0.006102\n",
      "[958/00201] train_loss: 0.006089\n",
      "[958/00251] train_loss: 0.006082\n",
      "[958/00301] train_loss: 0.006143\n",
      "[958/00351] train_loss: 0.006014\n",
      "[958/00401] train_loss: 0.006139\n",
      "[959/00045] train_loss: 0.006046\n",
      "[959/00095] train_loss: 0.006043\n",
      "[959/00145] train_loss: 0.006162\n",
      "[959/00195] train_loss: 0.006117\n",
      "[959/00245] train_loss: 0.006134\n",
      "[959/00295] train_loss: 0.006150\n",
      "[959/00345] train_loss: 0.005995\n",
      "[959/00395] train_loss: 0.006105\n",
      "[960/00039] train_loss: 0.006074\n",
      "[960/00089] train_loss: 0.006086\n",
      "[960/00139] train_loss: 0.006012\n",
      "[960/00189] train_loss: 0.006166\n",
      "[960/00239] train_loss: 0.006101\n",
      "[960/00289] train_loss: 0.006003\n",
      "[960/00339] train_loss: 0.006083\n",
      "[960/00389] train_loss: 0.006052\n",
      "[961/00033] train_loss: 0.005950\n",
      "[961/00083] train_loss: 0.006043\n",
      "[961/00133] train_loss: 0.006101\n",
      "[961/00183] train_loss: 0.006034\n",
      "[961/00233] train_loss: 0.006056\n",
      "[961/00283] train_loss: 0.006063\n",
      "[961/00333] train_loss: 0.006113\n",
      "[961/00383] train_loss: 0.006132\n",
      "[962/00027] train_loss: 0.006130\n",
      "[962/00077] train_loss: 0.006143\n",
      "[962/00127] train_loss: 0.006008\n",
      "[962/00177] train_loss: 0.006171\n",
      "[962/00227] train_loss: 0.006047\n",
      "[962/00277] train_loss: 0.006172\n",
      "[962/00327] train_loss: 0.006128\n",
      "[962/00377] train_loss: 0.006048\n",
      "[963/00021] train_loss: 0.006066\n",
      "[963/00071] train_loss: 0.006088\n",
      "[963/00121] train_loss: 0.006105\n",
      "[963/00171] train_loss: 0.006084\n",
      "[963/00221] train_loss: 0.006028\n",
      "[963/00271] train_loss: 0.006017\n",
      "[963/00321] train_loss: 0.006004\n",
      "[963/00371] train_loss: 0.006075\n",
      "[964/00015] train_loss: 0.006133\n",
      "[964/00065] train_loss: 0.006044\n",
      "[964/00115] train_loss: 0.006038\n",
      "[964/00165] train_loss: 0.006162\n",
      "[964/00215] train_loss: 0.006187\n",
      "[964/00265] train_loss: 0.006108\n",
      "[964/00315] train_loss: 0.006084\n",
      "[964/00365] train_loss: 0.006123\n",
      "[965/00009] train_loss: 0.006047\n",
      "[965/00059] train_loss: 0.006144\n",
      "[965/00109] train_loss: 0.006101\n",
      "[965/00159] train_loss: 0.006155\n",
      "[965/00209] train_loss: 0.006140\n",
      "[965/00259] train_loss: 0.006086\n",
      "[965/00309] train_loss: 0.006086\n",
      "[965/00359] train_loss: 0.006184\n",
      "[966/00003] train_loss: 0.006212\n",
      "[966/00053] train_loss: 0.006128\n",
      "[966/00103] train_loss: 0.006141\n",
      "[966/00153] train_loss: 0.006121\n",
      "[966/00203] train_loss: 0.005999\n",
      "[966/00253] train_loss: 0.006121\n",
      "[966/00303] train_loss: 0.006028\n",
      "[966/00353] train_loss: 0.006088\n",
      "[966/00403] train_loss: 0.006053\n",
      "[967/00047] train_loss: 0.006103\n",
      "[967/00097] train_loss: 0.006032\n",
      "[967/00147] train_loss: 0.006029\n",
      "[967/00197] train_loss: 0.006074\n",
      "[967/00247] train_loss: 0.006074\n",
      "[967/00297] train_loss: 0.006131\n",
      "[967/00347] train_loss: 0.006134\n",
      "[967/00397] train_loss: 0.006114\n",
      "[968/00041] train_loss: 0.006097\n",
      "[968/00091] train_loss: 0.006064\n",
      "[968/00141] train_loss: 0.006101\n",
      "[968/00191] train_loss: 0.006103\n",
      "[968/00241] train_loss: 0.006119\n",
      "[968/00291] train_loss: 0.006074\n",
      "[968/00341] train_loss: 0.005986\n",
      "[968/00391] train_loss: 0.006104\n",
      "[969/00035] train_loss: 0.006093\n",
      "[969/00085] train_loss: 0.006182\n",
      "[969/00135] train_loss: 0.006133\n",
      "[969/00185] train_loss: 0.006120\n",
      "[969/00235] train_loss: 0.006051\n",
      "[969/00285] train_loss: 0.006091\n",
      "[969/00335] train_loss: 0.006116\n",
      "[969/00385] train_loss: 0.006128\n",
      "[970/00029] train_loss: 0.006195\n",
      "[970/00079] train_loss: 0.005995\n",
      "[970/00129] train_loss: 0.006148\n",
      "[970/00179] train_loss: 0.006087\n",
      "[970/00229] train_loss: 0.006072\n",
      "[970/00279] train_loss: 0.006141\n",
      "[970/00329] train_loss: 0.006102\n",
      "[970/00379] train_loss: 0.006029\n",
      "[971/00023] train_loss: 0.006075\n",
      "[971/00073] train_loss: 0.006182\n",
      "[971/00123] train_loss: 0.006014\n",
      "[971/00173] train_loss: 0.006083\n",
      "[971/00223] train_loss: 0.006060\n",
      "[971/00273] train_loss: 0.006049\n",
      "[971/00323] train_loss: 0.006095\n",
      "[971/00373] train_loss: 0.006105\n",
      "[972/00017] train_loss: 0.006062\n",
      "[972/00067] train_loss: 0.006079\n",
      "[972/00117] train_loss: 0.006051\n",
      "[972/00167] train_loss: 0.006072\n",
      "[972/00217] train_loss: 0.006043\n",
      "[972/00267] train_loss: 0.006113\n",
      "[972/00317] train_loss: 0.006197\n",
      "[972/00367] train_loss: 0.006142\n",
      "[973/00011] train_loss: 0.006076\n",
      "[973/00061] train_loss: 0.006098\n",
      "[973/00111] train_loss: 0.006090\n",
      "[973/00161] train_loss: 0.006141\n",
      "[973/00211] train_loss: 0.006104\n",
      "[973/00261] train_loss: 0.006184\n",
      "[973/00311] train_loss: 0.006080\n",
      "[973/00361] train_loss: 0.006005\n",
      "[974/00005] train_loss: 0.006097\n",
      "[974/00055] train_loss: 0.006093\n",
      "[974/00105] train_loss: 0.006132\n",
      "[974/00155] train_loss: 0.006081\n",
      "[974/00205] train_loss: 0.006058\n",
      "[974/00255] train_loss: 0.006004\n",
      "[974/00305] train_loss: 0.006087\n",
      "[974/00355] train_loss: 0.006039\n",
      "[974/00405] train_loss: 0.006096\n",
      "[975/00049] train_loss: 0.006083\n",
      "[975/00099] train_loss: 0.006076\n",
      "[975/00149] train_loss: 0.006017\n",
      "[975/00199] train_loss: 0.006142\n",
      "[975/00249] train_loss: 0.006048\n",
      "[975/00299] train_loss: 0.006028\n",
      "[975/00349] train_loss: 0.006107\n",
      "[975/00399] train_loss: 0.006085\n",
      "[976/00043] train_loss: 0.006126\n",
      "[976/00093] train_loss: 0.006070\n",
      "[976/00143] train_loss: 0.006022\n",
      "[976/00193] train_loss: 0.006050\n",
      "[976/00243] train_loss: 0.006116\n",
      "[976/00293] train_loss: 0.006049\n",
      "[976/00343] train_loss: 0.006085\n",
      "[976/00393] train_loss: 0.006129\n",
      "[977/00037] train_loss: 0.006168\n",
      "[977/00087] train_loss: 0.006176\n",
      "[977/00137] train_loss: 0.006034\n",
      "[977/00187] train_loss: 0.006063\n",
      "[977/00237] train_loss: 0.006046\n",
      "[977/00287] train_loss: 0.006103\n",
      "[977/00337] train_loss: 0.006124\n",
      "[977/00387] train_loss: 0.006088\n",
      "[978/00031] train_loss: 0.006069\n",
      "[978/00081] train_loss: 0.006136\n",
      "[978/00131] train_loss: 0.006064\n",
      "[978/00181] train_loss: 0.006068\n",
      "[978/00231] train_loss: 0.006097\n",
      "[978/00281] train_loss: 0.006111\n",
      "[978/00331] train_loss: 0.005970\n",
      "[978/00381] train_loss: 0.006185\n",
      "[979/00025] train_loss: 0.006046\n",
      "[979/00075] train_loss: 0.006078\n",
      "[979/00125] train_loss: 0.006162\n",
      "[979/00175] train_loss: 0.006020\n",
      "[979/00225] train_loss: 0.006113\n",
      "[979/00275] train_loss: 0.006071\n",
      "[979/00325] train_loss: 0.006104\n",
      "[979/00375] train_loss: 0.006075\n",
      "[980/00019] train_loss: 0.006162\n",
      "[980/00069] train_loss: 0.006119\n",
      "[980/00119] train_loss: 0.006128\n",
      "[980/00169] train_loss: 0.005989\n",
      "[980/00219] train_loss: 0.006012\n",
      "[980/00269] train_loss: 0.006107\n",
      "[980/00319] train_loss: 0.006122\n",
      "[980/00369] train_loss: 0.006095\n",
      "[981/00013] train_loss: 0.005981\n",
      "[981/00063] train_loss: 0.006037\n",
      "[981/00113] train_loss: 0.006039\n",
      "[981/00163] train_loss: 0.006154\n",
      "[981/00213] train_loss: 0.006160\n",
      "[981/00263] train_loss: 0.006027\n",
      "[981/00313] train_loss: 0.006182\n",
      "[981/00363] train_loss: 0.006156\n",
      "[982/00007] train_loss: 0.006143\n",
      "[982/00057] train_loss: 0.006076\n",
      "[982/00107] train_loss: 0.006225\n",
      "[982/00157] train_loss: 0.006074\n",
      "[982/00207] train_loss: 0.006084\n",
      "[982/00257] train_loss: 0.006060\n",
      "[982/00307] train_loss: 0.006121\n",
      "[982/00357] train_loss: 0.006086\n",
      "[983/00001] train_loss: 0.006037\n",
      "[983/00051] train_loss: 0.006055\n",
      "[983/00101] train_loss: 0.006122\n",
      "[983/00151] train_loss: 0.006044\n",
      "[983/00201] train_loss: 0.006222\n",
      "[983/00251] train_loss: 0.006103\n",
      "[983/00301] train_loss: 0.006020\n",
      "[983/00351] train_loss: 0.006161\n",
      "[983/00401] train_loss: 0.006023\n",
      "[984/00045] train_loss: 0.006174\n",
      "[984/00095] train_loss: 0.006121\n",
      "[984/00145] train_loss: 0.006139\n",
      "[984/00195] train_loss: 0.005973\n",
      "[984/00245] train_loss: 0.006040\n",
      "[984/00295] train_loss: 0.006076\n",
      "[984/00345] train_loss: 0.006102\n",
      "[984/00395] train_loss: 0.006127\n",
      "[985/00039] train_loss: 0.006131\n",
      "[985/00089] train_loss: 0.006064\n",
      "[985/00139] train_loss: 0.006136\n",
      "[985/00189] train_loss: 0.006034\n",
      "[985/00239] train_loss: 0.006157\n",
      "[985/00289] train_loss: 0.006046\n",
      "[985/00339] train_loss: 0.006091\n",
      "[985/00389] train_loss: 0.006089\n",
      "[986/00033] train_loss: 0.006197\n",
      "[986/00083] train_loss: 0.005978\n",
      "[986/00133] train_loss: 0.006188\n",
      "[986/00183] train_loss: 0.006085\n",
      "[986/00233] train_loss: 0.006196\n",
      "[986/00283] train_loss: 0.006105\n",
      "[986/00333] train_loss: 0.006223\n",
      "[986/00383] train_loss: 0.006127\n",
      "[987/00027] train_loss: 0.006185\n",
      "[987/00077] train_loss: 0.006136\n",
      "[987/00127] train_loss: 0.006056\n",
      "[987/00177] train_loss: 0.006103\n",
      "[987/00227] train_loss: 0.006262\n",
      "[987/00277] train_loss: 0.006125\n",
      "[987/00327] train_loss: 0.006093\n",
      "[987/00377] train_loss: 0.006132\n",
      "[988/00021] train_loss: 0.006098\n",
      "[988/00071] train_loss: 0.006040\n",
      "[988/00121] train_loss: 0.006134\n",
      "[988/00171] train_loss: 0.006017\n",
      "[988/00221] train_loss: 0.006116\n",
      "[988/00271] train_loss: 0.006053\n",
      "[988/00321] train_loss: 0.006123\n",
      "[988/00371] train_loss: 0.006067\n",
      "[989/00015] train_loss: 0.006062\n",
      "[989/00065] train_loss: 0.006023\n",
      "[989/00115] train_loss: 0.006049\n",
      "[989/00165] train_loss: 0.006106\n",
      "[989/00215] train_loss: 0.006041\n",
      "[989/00265] train_loss: 0.006112\n",
      "[989/00315] train_loss: 0.006078\n",
      "[989/00365] train_loss: 0.006047\n",
      "[990/00009] train_loss: 0.006104\n",
      "[990/00059] train_loss: 0.006047\n",
      "[990/00109] train_loss: 0.006152\n",
      "[990/00159] train_loss: 0.006017\n",
      "[990/00209] train_loss: 0.006081\n",
      "[990/00259] train_loss: 0.006148\n",
      "[990/00309] train_loss: 0.006137\n",
      "[990/00359] train_loss: 0.006175\n",
      "[991/00003] train_loss: 0.006158\n",
      "[991/00053] train_loss: 0.006063\n",
      "[991/00103] train_loss: 0.006129\n",
      "[991/00153] train_loss: 0.006037\n",
      "[991/00203] train_loss: 0.006180\n",
      "[991/00253] train_loss: 0.006114\n",
      "[991/00303] train_loss: 0.006016\n",
      "[991/00353] train_loss: 0.006135\n",
      "[991/00403] train_loss: 0.006144\n",
      "[992/00047] train_loss: 0.006130\n",
      "[992/00097] train_loss: 0.006089\n",
      "[992/00147] train_loss: 0.006135\n",
      "[992/00197] train_loss: 0.006119\n",
      "[992/00247] train_loss: 0.006081\n",
      "[992/00297] train_loss: 0.006160\n",
      "[992/00347] train_loss: 0.006013\n",
      "[992/00397] train_loss: 0.006063\n",
      "[993/00041] train_loss: 0.006156\n",
      "[993/00091] train_loss: 0.006070\n",
      "[993/00141] train_loss: 0.006078\n",
      "[993/00191] train_loss: 0.006088\n",
      "[993/00241] train_loss: 0.006132\n",
      "[993/00291] train_loss: 0.006122\n",
      "[993/00341] train_loss: 0.006071\n",
      "[993/00391] train_loss: 0.006046\n",
      "[994/00035] train_loss: 0.006072\n",
      "[994/00085] train_loss: 0.006085\n",
      "[994/00135] train_loss: 0.006162\n",
      "[994/00185] train_loss: 0.006136\n",
      "[994/00235] train_loss: 0.006155\n",
      "[994/00285] train_loss: 0.006113\n",
      "[994/00335] train_loss: 0.006059\n",
      "[994/00385] train_loss: 0.006106\n",
      "[995/00029] train_loss: 0.005997\n",
      "[995/00079] train_loss: 0.006053\n",
      "[995/00129] train_loss: 0.006083\n",
      "[995/00179] train_loss: 0.006125\n",
      "[995/00229] train_loss: 0.006085\n",
      "[995/00279] train_loss: 0.006080\n",
      "[995/00329] train_loss: 0.006059\n",
      "[995/00379] train_loss: 0.006179\n",
      "[996/00023] train_loss: 0.006076\n",
      "[996/00073] train_loss: 0.006093\n",
      "[996/00123] train_loss: 0.006073\n",
      "[996/00173] train_loss: 0.006129\n",
      "[996/00223] train_loss: 0.006224\n",
      "[996/00273] train_loss: 0.006033\n",
      "[996/00323] train_loss: 0.006071\n",
      "[996/00373] train_loss: 0.006137\n",
      "[997/00017] train_loss: 0.006112\n",
      "[997/00067] train_loss: 0.006104\n",
      "[997/00117] train_loss: 0.006187\n",
      "[997/00167] train_loss: 0.006018\n",
      "[997/00217] train_loss: 0.006031\n",
      "[997/00267] train_loss: 0.005994\n",
      "[997/00317] train_loss: 0.006073\n",
      "[997/00367] train_loss: 0.005986\n",
      "[998/00011] train_loss: 0.006072\n",
      "[998/00061] train_loss: 0.006147\n",
      "[998/00111] train_loss: 0.006104\n",
      "[998/00161] train_loss: 0.006108\n",
      "[998/00211] train_loss: 0.006061\n",
      "[998/00261] train_loss: 0.006121\n",
      "[998/00311] train_loss: 0.006042\n",
      "[998/00361] train_loss: 0.006151\n",
      "[999/00005] train_loss: 0.006081\n",
      "[999/00055] train_loss: 0.006127\n",
      "[999/00105] train_loss: 0.006076\n",
      "[999/00155] train_loss: 0.006054\n",
      "[999/00205] train_loss: 0.006059\n",
      "[999/00255] train_loss: 0.006112\n",
      "[999/00305] train_loss: 0.006149\n",
      "[999/00355] train_loss: 0.006141\n",
      "[999/00405] train_loss: 0.006090\n"
     ]
    }
   ],
   "source": [
    "from ml43dg.training import train_deepsdf\n",
    "\n",
    "generalization_config = {\n",
    "    'experiment_name': '3_1_deepsdf_generalization',\n",
    "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
    "    'is_overfit': False,\n",
    "    'num_sample_points': 4096, # you can adjust this such that the model fits on your gpu\n",
    "    'latent_code_length': 256,\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.0005,\n",
    "    'learning_rate_code': 0.001,\n",
    "    'lambda_code_regularization': 0.0001,\n",
    "    'max_epochs': 1000, #2000,  # not necessary to run for 2000 epochs if you're short on time, at 500 epochs you should start to see reasonable results\n",
    "    'print_every_n': 50,\n",
    "    'visualize_every_n': 5000,\n",
    "}\n",
    "\n",
    "train_deepsdf.main(generalization_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Inference using the trained model on observed SDF values\n",
    "\n",
    "Fill in the inference script `exercise_3/inference/infer_deepsdf.py`. Note that it's not simply a forward pass, but an optimization of the latent code such that we have lowest error on observed SDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ml43dg.inference.infer_deepsdf import InferenceHandlerDeepSDF\n",
    "\n",
    "device = torch.device('cuda:0')  # change this to cpu if you're not using a gpu\n",
    "\n",
    "inference_handler = InferenceHandlerDeepSDF(256, \"exercise_3/runs/3_1_deepsdf_generalization\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try inference on a shape from validation set, for which we have a complete observation of sdf values. This is an easier problem as compared to shape completion,\n",
    "since we have all the information already in the input.\n",
    "\n",
    "Let's visualize the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get observed data\n",
    "points, sdf = Objaverse.get_all_sdf_samples(\"b351e06f5826444c19fb4103277a6b93\")\n",
    "\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()\n",
    "\n",
    "# visualize observed points; you'll observe that the observations are very complete\n",
    "print('Observations with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)\n",
    "print('Observations with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reconstruction on these observations with the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "vertices, faces = inference_handler.reconstruct(points, sdf, 800)\n",
    "# visualize\n",
    "visualize_mesh(vertices, faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try the shape completion task, i.e., inference on a shape from validation set, for which we do not have a complete observation of sdf values. The observed points are visualized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get observed data\n",
    "points, sdf = Objaverse.get_all_sdf_samples(\"b351e06f5826444c19fb4103277a6b93_incomplete\")\n",
    "\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()\n",
    "\n",
    "# visualize observed points; you'll observe that the observations are incomplete\n",
    "# making this is a shape completion task\n",
    "print('Observations with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)\n",
    "print('Observations with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape completion using the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "vertices, faces = inference_handler.reconstruct(points, sdf, 800)\n",
    "# visualize\n",
    "visualize_mesh(vertices, faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Latent space interpolation\n",
    "\n",
    "The latent space learned by DeepSDF is interpolatable, meaning that decoding latent codes from this space produced meaningful shapes. Given two latent codes, a linearly interpolatable latent space will decode\n",
    "each of the intermediate codes to some valid shape. Let's see if this holds for our trained model.\n",
    "\n",
    "We'll pick two shapes from the train set as visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml43dg.data.shape_implicit import ShapeImplicit\n",
    "from ml43dg.util.visualization import visualize_mesh\n",
    "\n",
    "mesh = Objaverse.get_mesh(\"494fe53da65650b8c358765b76c296\")\n",
    "print('GT Shape A')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)\n",
    "\n",
    "mesh = Objaverse.get_mesh(\"5ca1ef55ff5f68501921e7a85cf9da35\")\n",
    "print('GT Shape B')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement the missing parts in `exercise_3/inference/infer_deepsdf.py` such that it interpolates two given latent vectors, and run the code fragement below once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ml43dg.inference.infer_deepsdf import InferenceHandlerDeepSDF\n",
    "\n",
    "inference_handler = InferenceHandlerDeepSDF(256, \"exercise_3/runs/3_1_deepsdf_generalization\", torch.device('cuda:0'))\n",
    "# interpolate; also exports interpolated meshes to disk\n",
    "inference_handler.interpolate('494fe53da65650b8c358765b76c296', '5ca1ef55ff5f68501921e7a85cf9da35', 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the interpolation below. If everything works out correctly, you should see a smooth transformation between the shapes, with all intermediate shapes being valid sofas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ml43dg.util.mesh_collection_to_gif import  meshes_to_gif\n",
    "from ml43dg.util.misc import show_gif\n",
    "\n",
    "# create list of meshes (just exported) to be visualized\n",
    "mesh_paths = sorted([x for x in Path(\"exercise_3/runs/3_1_deepsdf_generalization/interpolation\").iterdir() if int(x.name.split('.')[0].split(\"_\")[1]) == 0], key=lambda x: int(x.name.split('.')[0].split(\"_\")[0]))\n",
    "mesh_paths = mesh_paths + mesh_paths[::-1]\n",
    "\n",
    "# create a visualization of the interpolation process\n",
    "meshes_to_gif(mesh_paths, \"exercise_3/runs/3_1_deepsdf_generalization/latent_interp.gif\", 20)\n",
    "show_gif(\"exercise_3/runs/3_1_deepsdf_generalization/latent_interp.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Submission\n",
    "\n",
    "This is the end of exercise 3 🙂. Please create a zip containing all files we provided, everything you modified, your visualization images/gif (no need to submit generated OBJs), including your checkpoints. Name it with your matriculation number(s) as described in exercise 1. Make sure this notebook can be run without problems. Then, submit via Moodle.\n",
    "\n",
    "**Note**: The maximum submission file size limit for Moodle is 100M. You do not need to submit your overfitting checkpoints; however, the generalization checkpoint will be >200M. The easiest way to still be able to submit that one is to split it with zip like this: `zip -s 100M model_best.ckpt.zip model_best.ckpt` which creates a `.zip` and a `.z01`. You can then submit both files alongside another zip containing all your code and outputs.\n",
    "\n",
    "**Submission Deadline**: 11.06.2024, 23:55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Park, Jeong Joon, et al. \"Deepsdf: Learning continuous signed distance functions for shape representation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
